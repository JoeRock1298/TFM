{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug SqueezeNet v1.3 (Simple Task) OpenCL implement with PyOpenCL and PyTorch\n",
    "Partial code are copied heavily from https://github.com/pytorch/vision/blob/master/torchvision/models/squeezenet.py  \n",
    "SqueezeNet Paper:https://arxiv.org/abs/1602.07360  \n",
    "SqueezeNet 1.1 model from https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1   \n",
    "SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters than SqueezeNet 1.0, without sacrificing accuracy.\n",
    "\n",
    "Tests con fire1 del bloque 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#some set up\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from PIL import Image\n",
    "import math\n",
    "import time\n",
    "from time import sleep, perf_counter as pc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aquí tenemos el medidor de pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En esta aproximacion tengo en cuenta el tiempo de definición de capas y la carga de pesos porque se supone que entre fire y fire estas operaciones tiene que hacerse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 83366.  75924.  89036. ...  95599.  84150.  82610.]\n",
      "   [ 83672.  97772. 105048. ...  96198.  96303.  84964.]\n",
      "   [106752.  99979.  88342. ...  97885.  88343.  96994.]\n",
      "   ...\n",
      "   [ 92932.  92356.  95920. ...  95031.  89895.  94754.]\n",
      "   [ 82698.  94954.  93167. ...  80386.  84900.  85957.]\n",
      "   [ 89330. 106703.  96674. ...  82985.  87512. 100036.]]\n",
      "\n",
      "  [[ 89821.  84177.  96709. ... 105773.  90519.  90222.]\n",
      "   [ 91565. 108163. 115013. ... 105223. 108018.  92988.]\n",
      "   [116581. 108232.  96220. ... 106616.  96809. 104665.]\n",
      "   ...\n",
      "   [101185. 100630. 103733. ... 101550.  98578. 105259.]\n",
      "   [ 90776. 101714. 102200. ...  88197.  92968.  93545.]\n",
      "   [ 98778. 114972. 105778. ...  91075.  94854. 109946.]]\n",
      "\n",
      "  [[ 76828.  73230.  84197. ...  91031.  77511.  78786.]\n",
      "   [ 80054.  90928.  99396. ...  90175.  92628.  80434.]\n",
      "   [101801.  96475.  85397. ...  92089.  84631.  92290.]\n",
      "   ...\n",
      "   [ 85150.  87191.  87686. ...  88792.  84294.  89808.]\n",
      "   [ 78234.  89438.  87918. ...  74400.  80156.  82021.]\n",
      "   [ 83027.  97980.  90384. ...  78630.  82407.  95675.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[333058. 528094. 531463. ... 538828. 532395. 339409.]\n",
      "   [540382. 812210. 803546. ... 821235. 797296. 523906.]\n",
      "   [545875. 821261. 827492. ... 822774. 804437. 527734.]\n",
      "   ...\n",
      "   [522567. 790302. 803799. ... 794015. 796315. 539877.]\n",
      "   [549409. 820194. 823375. ... 788451. 782454. 537926.]\n",
      "   [369929. 547749. 556384. ... 505467. 509301. 353171.]]\n",
      "\n",
      "  [[357851. 549029. 552036. ... 561503. 557675. 361110.]\n",
      "   [576606. 849829. 844435. ... 864741. 849474. 583825.]\n",
      "   [576941. 869582. 883049. ... 869493. 851019. 581625.]\n",
      "   ...\n",
      "   [554176. 840260. 844702. ... 832802. 841584. 601726.]\n",
      "   [581847. 867565. 865554. ... 829223. 822512. 592345.]\n",
      "   [376760. 593545. 608525. ... 556669. 553808. 411546.]]\n",
      "\n",
      "  [[362510. 569785. 571946. ... 584432. 577509. 367467.]\n",
      "   [576053. 857850. 845039. ... 862665. 847407. 547046.]\n",
      "   [580148. 866716. 867570. ... 867508. 853241. 545114.]\n",
      "   ...\n",
      "   [555052. 837628. 844232. ... 833555. 844794. 553583.]\n",
      "   [581187. 865651. 867838. ... 821700. 821654. 552521.]\n",
      "   [392942. 579147. 587809. ... 535617. 543232. 357118.]]]]\n",
      "tiempo en segundos con pytorch=  0.007269384130004255\n"
     ]
    }
   ],
   "source": [
    "canales_iniciales=64\n",
    "canales_contraidos=16\n",
    "canales_finales= np.int32(canales_iniciales+canales_iniciales)\n",
    "\n",
    "\n",
    "acumulado_pytorch=0\n",
    "acumulado_numpy=0\n",
    "idea=True\n",
    "\n",
    "count=100\n",
    "tamanyo=55\n",
    "\n",
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "for i in range(count):\n",
    "\n",
    "    imagen = np.random.randint(10,size=(1,canales_iniciales, tamanyo, tamanyo))\n",
    "    \n",
    "    weights1=np.random.randint(10,size=(canales_contraidos, canales_iniciales,1,1)).astype(np.float32)\n",
    "    bias1=np.random.randint(10,size=(canales_contraidos,)).astype(np.float32)\n",
    "    \n",
    "    weights2a=np.random.randint(10,size=(canales_finales, canales_contraidos,1,1)).astype(np.float32)  \n",
    "    bias2a=np.random.randint(10,size=(canales_finales,)).astype(np.float32)    \n",
    "    \n",
    "    weights2b=np.random.randint(10,size=(canales_finales, canales_contraidos,3,3)).astype(np.float32)    \n",
    "    bias2b=np.random.randint(10,size=(canales_finales,)).astype(np.float32)    \n",
    "    \n",
    "    tic=pc()\n",
    "    \n",
    "    squeeze1=nn.Conv2d(canales_iniciales, canales_contraidos, kernel_size=1, bias=False)\n",
    "    squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "    squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))    \n",
    "\n",
    "    squeeze2a=nn.Conv2d(canales_contraidos, canales_finales, kernel_size=1, bias=False)\n",
    "    squeeze2a.weight = nn.Parameter(torch.from_numpy(weights2a))\n",
    "    squeeze2a.bias = nn.Parameter(torch.from_numpy(bias2a))\n",
    "    \n",
    "    squeeze2b=nn.Conv2d(canales_contraidos, canales_finales, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze2b.weight = nn.Parameter(torch.from_numpy(weights2b))\n",
    "    squeeze2b.bias = nn.Parameter(torch.from_numpy(bias2b))    \n",
    "\n",
    "    imagen1  = torch.from_numpy(imagen).float()\n",
    "    \n",
    "    salida1=squeeze1(imagen1)\n",
    "    salida1_activation=squeeze_activation(salida1)\n",
    "    \n",
    "    salida2a=squeeze2a(salida1_activation)\n",
    "    salida2a_activation=squeeze_activation(salida2a)\n",
    "    salida2b=squeeze2b(salida1_activation)\n",
    "    salida2b_activation=squeeze_activation(salida2b)    \n",
    "    salida2_total=torch.cat([salida2a_activation,salida2b_activation], 1)\n",
    "    salida2_total_a_numpy=salida2_total.detach().numpy()\n",
    "    \n",
    "    toc=pc()\n",
    "    \n",
    "    acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "    \n",
    "    \n",
    "print(salida2_total_a_numpy)\n",
    "print (\"tiempo en segundos con pytorch= \", acumulado_pytorch/count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veamos ahora fire con opencl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OpenCL setup\n",
    "import pyopencl as cl\n",
    "import sys\n",
    "sys.path.append('../common')\n",
    "import deviceinfo\n",
    "from time import time\n",
    "\n",
    "#wksp = '../device/v1.3/squeezenet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step0-A: compilation for emulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aoc: OpenCL kernel compilation completed successfully.\n",
      "aoc: Linking Object files....\n",
      "aoc: Compiling for Emulation ....\n",
      "aoc: OpenCL kernel compilation completed successfully.\n",
      "aoc: Linking Object files....\n",
      "aoc: Compiling for Emulation ....\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "aoc -march=emulator ../device/v1.3/squeezenet/squeezenet_NDRange.cl -o ../device/v1.3/squeezenet/bin_em/squeezenet_NDRange.aocx\n",
    "aoc -march=emulator ../device/v1.3/squeezenet/squeezenet_ST.cl -o ../device/v1.3/squeezenet/bin_em/squeezenet_ST.aocx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step0-B: compilation for simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aoc: Environment checks completed successfully.\n",
      "Quartus location: /home/joerock/intelFPGA_pro/21.1/quartus/bin/quartus_sh\n",
      "aoc: Cached files in /var/tmp/aocl/joerock may be used to reduce compilation time\n",
      "aoc: Selected target board package /home/joerock/intelFPGA_pro/21.1/hld/board/a10_ref\n",
      "aoc: Selected target board a10gx\n",
      "aoc: Running OpenCL parser....\n",
      "aoc: OpenCL parser completed \n",
      "aoc: Linking Object files....\n",
      "aoc: Optimizing and doing static analysis of code...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiler Warning: device/v1.3/squeezenet/squeezenet_NDRange.cl:96: declaring global arguments 'input_im', 'filter_weight' and 'filter_bias' with no 'restrict' may lead to low performance for kernel 'conv2d1x1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aoc: Linking with IP library ...\n",
      "aoc: Checking if memory usage is larger than 100%...\n",
      "aoc: Memory usage is not above 100.\n",
      "aoc: First stage compilation completed successfully.\n",
      "aoc: Compiling for Simulator.\n",
      "Quartus location: /home/joerock/intelFPGA_pro/21.1/quartus/bin/quartus_sh\n",
      "Creating simulation system...\n",
      "Generating simulation system...\n",
      "Compiling simulation...\n",
      "aoc: Simulation generation done!\n",
      "Simulator flow is successful.\n",
      "To execute simulator, invoke host with \n",
      "\tenv CL_CONTEXT_MPSIM_DEVICE_INTELFPGA=1 <host_program>\n",
      "aoc: Environment checks completed successfully.\n",
      "Quartus location: /home/joerock/intelFPGA_pro/21.1/quartus/bin/quartus_sh\n",
      "aoc: Cached files in /var/tmp/aocl/joerock may be used to reduce compilation time\n",
      "aoc: Selected target board package /home/joerock/intelFPGA_pro/21.1/hld/board/a10_ref\n",
      "aoc: Selected target board a10gx\n",
      "aoc: Running OpenCL parser....\n",
      "aoc: OpenCL parser completed \n",
      "aoc: Linking Object files....\n",
      "aoc: Optimizing and doing static analysis of code...\n",
      "aoc: Linking with IP library ...\n",
      "aoc: Checking if memory usage is larger than 100%...\n",
      "aoc: Memory usage is not above 100.\n",
      "aoc: First stage compilation completed successfully.\n",
      "aoc: Compiling for Simulator.\n",
      "Quartus location: /home/joerock/intelFPGA_pro/21.1/quartus/bin/quartus_sh\n",
      "Creating simulation system...\n",
      "Generating simulation system...\n",
      "Compiling simulation...\n",
      "aoc: Simulation generation done!\n",
      "Simulator flow is successful.\n",
      "To execute simulator, invoke host with \n",
      "\tenv CL_CONTEXT_MPSIM_DEVICE_INTELFPGA=1 <host_program>\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "aoc -march=simulator -v -ghdl ../device/v1.3/squeezenet/squeezenet_NDRange.cl -o ../device/v1.3/squeezenet/bin_sim/squeezenet_NDRange.aocx -board=a10gx\n",
    "aoc -march=simulator -v -ghdl ../device/v1.3/squeezenet/squeezenet_ST.cl -o ../device/v1.3/squeezenet/bin_sim/squeezenet_ST.aocx -board=a10gx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step1: OpenCL preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl.Context at 0x4f6f748 on <pyopencl.Device '12th Gen Intel(R) Core(TM) i7-12650H' on 'Intel(R) OpenCL' at 0x4f7c4b8>>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platforms = cl.get_platforms()\n",
    "context = cl.Context(\n",
    "        dev_type=cl.device_type.ALL,\n",
    "        properties=[(cl.context_properties.PLATFORM, platforms[0])])\n",
    "queue = cl.CommandQueue(context)\n",
    "queue1 = cl.CommandQueue(context)\n",
    "\n",
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 2: creat kernels\n",
    "Creat & build program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joerock/anaconda3/envs/TFM/lib/python3.8/site-packages/pyopencl/__init__.py:270: CompilerWarning: Non-empty compiler output encountered. Set the environment variable PYOPENCL_COMPILER_OUTPUT=1 to see more.\n",
      "  warn(\"Non-empty compiler output encountered. Set the \"\n"
     ]
    }
   ],
   "source": [
    "wksp = '../device/v1.3/squeezenet/'\n",
    "\n",
    "file_dir = wksp + 'squeezenet_NDRange.cl'\n",
    "\n",
    "kernelSource = open(file_dir).read()\n",
    "program_NDR = cl.Program(context, kernelSource).build()\n",
    "\n",
    "file_dir = wksp + 'squeezenet_ST.cl'\n",
    "\n",
    "kernelSource = open(file_dir).read()\n",
    "program_ST = cl.Program(context, kernelSource).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creat kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv3x3_NDR = program_NDR.conv2d3x3\n",
    "conv3x3_NDR.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "maxpool_NDR = program_NDR.maxpool2d\n",
    "maxpool_NDR.set_scalar_arg_dtypes([np.int32, np.int32, None, None])\n",
    "\n",
    "conv1x1_NDR = program_NDR.conv2d1x1\n",
    "conv1x1_NDR.set_scalar_arg_dtypes([np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "avgpool_NDR = program_NDR.avgpool2d\n",
    "avgpool_NDR.set_scalar_arg_dtypes([None, None])\n",
    "\n",
    "conv3x3_ST = program_ST.conv2d3x3\n",
    "conv3x3_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "maxpool_ST = program_ST.maxpool2d\n",
    "maxpool_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, None, None])\n",
    "\n",
    "conv1x1_ST = program_ST.conv2d1x1\n",
    "conv1x1_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "avgpool_ST = program_ST.avgpool2d\n",
    "avgpool_ST.set_scalar_arg_dtypes([None, None])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### OpenCL kernel: squeezenet_NDRange.cl\n",
    "conv2d3x3: 2-D 3x3 convolution.  \n",
    "conv2d1x1: 2-D 1x1 convolution. kerner size 1, stride 1  \n",
    "maxpool2d: 2-D max pool. kerner size 3, stride 2  \n",
    "avgpool2d: 2-D average pool. kernel size 13\n",
    "```C\n",
    "//maxPool2d \n",
    "//kernel_size=3 stride=2\n",
    "//output one feature map per kernel\n",
    "__kernel void maxpool2d(\n",
    "\tconst int input_size,\n",
    "\tconst int output_size,\n",
    "\t__global const float* restrict input_im,\n",
    "    __global float* restrict output_im)\n",
    "{\n",
    "\tint channels = get_global_id(0);//get output channel index\n",
    "\t\n",
    "\tinput_im += channels * input_size * input_size;\n",
    "\toutput_im += channels * output_size * output_size;\n",
    "\n",
    "\t//loop over output feature map\n",
    "\tfor(int i = 0; i < output_size; i++)//row\n",
    "\t{\n",
    "\t\tfor(int j = 0; j < output_size; j++)//col\n",
    "\t\t{\n",
    "\t\t\t//find the max value in 3x3 reigon \n",
    "\t\t\t//to be one element in the output feature map\n",
    "\t\t\tfloat tmp = 0.0;\n",
    "\n",
    "\t\t\t#pragma unroll 1\n",
    "\t\t\tfor(int k = 0; k < 3; k++)//row\n",
    "\t\t\t{\n",
    "\t\t\t\t#pragma unroll 1\n",
    "\t\t\t\tfor(int l = 0; l < 3; l++)//col\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\tfloat value = input_im[(i * 2 + k) * input_size  + j * 2 + l ];\n",
    "\t\t\t\t\tif(value > tmp)\n",
    "\t\t\t\t\t\ttmp = value;\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t\t//store the result to output feature map\n",
    "\t\t\toutput_im[i * output_size + j] = tmp; \n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "//3x3 convolution layer\n",
    "//output one feature map per kernel\n",
    "__kernel void conv2d3x3(\n",
    "\tconst int input_channels, const int input_size,\n",
    "\tconst int pad, const int stride,\n",
    "\tconst int start_channel, //start_channel is for 1x1 feature map in fire layer\n",
    "\tconst int output_size,\n",
    "\t__global const float* restrict input_im,\n",
    "\t__global const float* restrict filter_weight,\n",
    "\t__global const float* restrict filter_bias,\n",
    "\t__global float *restrict output_im\n",
    "\t)\n",
    "{\n",
    "\tint filter_index = get_global_id(0); //get output channel index\n",
    "\tint i =  get_global_id(1);\n",
    "\n",
    "\tfilter_weight += filter_index * input_channels * 9;\n",
    "\tfloat bias = filter_bias[filter_index];\n",
    "\toutput_im += (start_channel + filter_index) * output_size * output_size;\n",
    "\t\n",
    "\t//loop over output feature map\n",
    "\t//for(int i = 0; i < output_size; i++)\n",
    "\t{\n",
    "\t\tfor(int j = 0; j < output_size; j++)\n",
    "\t\t{\n",
    "\t\t\t//compute one element in the output feature map\n",
    "\t\t\tfloat tmp = bias;\n",
    "\t\t\t\n",
    "\t\t\t//compute dot product of 2 input_channels x 3 x 3 matrix\n",
    "\t\t\tfor(int k = 0; k < input_channels; k++)\n",
    "\t\t\t{\n",
    "\t\t\t\t#pragma unroll\n",
    "\t\t\t\tfor(int l = 0; l < 3; l++)\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\tint h = i * stride + l - pad;\n",
    "\t\t\t\t\tfor(int m = 0; m < 3; m++)\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\tint w = j * stride + m - pad;\n",
    "\t\t\t\t\t\tif((h >= 0) && (h < input_size) && (w >= 0) && (w < input_size))\n",
    "\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\ttmp += input_im[k * input_size * input_size + h * input_size + w] \\\n",
    "                               * filter_weight[9 * k + 3 * l + m];\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\t//add relu activation after conv\n",
    "\t\t\toutput_im[i * output_size + j] = (tmp > 0.0) ? tmp : 0.0;\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "//1x1 convolution layer\n",
    "//output one feature map per kernel\n",
    "__kernel void conv2d1x1(\n",
    "\tconst int input_channels, const int input_size,\n",
    "\t__global float *input_im,\n",
    "\t__global const float4* filter_weight,\n",
    "\t__global const float* filter_bias,\n",
    "\t__global float *restrict output_im)\n",
    "{\n",
    "\tint filter_index = get_global_id(0); // 0 - (output_channels - 1)\n",
    "\tint i = get_global_id(1);\n",
    "\n",
    "\tfilter_weight += filter_index * input_channels;\n",
    "\n",
    "\tfloat bias = filter_bias[filter_index];\n",
    "\t\n",
    "\toutput_im += filter_index * input_size * input_size;//start_channel is for 1x1 feature map in fire layer\n",
    "\n",
    "\t//loop over output feature map\n",
    "\t//for(int i = 0; i < input_size; i++)\n",
    "\t{\n",
    "\t\tfor(int j = 0; j < input_size; j++)\n",
    "\t\t{\n",
    "\t\t\tfloat tmp = bias;\n",
    "\t\t\tint loc = i * input_size + j;\n",
    "\n",
    "\t\t\tfor(int k = 0; k < input_channels; k++)\n",
    "\t\t\t{\n",
    "\t\t\t\t//float8 weight = filter_weight[k];\n",
    "\t\t\t\t//float8 feature;\n",
    "\t\t\t\ttmp += input_im[((k << 2) + 0) * input_size * input_size + loc] * filter_weight[k].s0\n",
    "\t\t\t\t     + input_im[((k << 2) + 1) * input_size * input_size + loc] * filter_weight[k].s1\n",
    "\t\t\t\t\t + input_im[((k << 2) + 2) * input_size * input_size + loc] * filter_weight[k].s2\n",
    "\t\t\t\t\t + input_im[((k << 2) + 3) * input_size * input_size + loc] * filter_weight[k].s3;\n",
    "\t\t\t}\n",
    "\t\t\t//add relu after conv\n",
    "\t\t\toutput_im[i * input_size + j] = (tmp > 0.0) ? tmp : 0.0;\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "//last layer use a 13 x 13 avgPool layer as classifier\n",
    "//one class score per kernel\n",
    "__kernel void avgpool2d(\n",
    "\t__global const float* restrict input_im,\n",
    "\t__global float* restrict output_im)\n",
    "{\n",
    "\tint class_index = get_global_id(0);//get class score index\n",
    "\n",
    "\tinput_im += 169 * class_index;\n",
    "\t\n",
    "\tfloat tmp = 0.0f;\n",
    "\n",
    "\tfor(int i = 0; i < 169; i++)\n",
    "\t{\n",
    "\t\ttmp += input_im[i];\n",
    "\t}\n",
    "\n",
    "\toutput_im[class_index] = tmp / 169.0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### OpenCL kernel: squeezenet_ST.cl\n",
    "conv2d3x3: 2-D 3x3 convolution.  \n",
    "conv2d1x1: 2-D 1x1 convolution. kerner size 1, stride 1  \n",
    "maxpool2d: 2-D max pool. kerner size 3, stride 2  \n",
    "avgpool2d: 2-D average pool. kernel size 13\n",
    "```C\n",
    "//maxPool2d \n",
    "//kernel_size=3 stride=2\n",
    "//output one feature map per kernel\n",
    "__kernel void maxpool2d(\n",
    "\tconst int input_size,\n",
    "\tconst int output_size,\n",
    "    const int channel_size,\n",
    "\t__global const float* restrict input_im,\n",
    "    __global float* restrict output_im)\n",
    "{\n",
    "\n",
    "    for(int channel_index = 0; channel_index < channel_size; channel_index++)\n",
    "    {\n",
    "        //loop over output feature map\n",
    "        for(int i = 0; i < output_size; i++)//row\n",
    "        {\n",
    "            for(int j = 0; j < output_size; j++)//col\n",
    "            {\n",
    "                //find the max value in 3x3 reigon \n",
    "                //to be one element in the output feature map\n",
    "                float tmp = 0.0;\n",
    "\n",
    "                #pragma unroll 1\n",
    "                for(int k = 0; k < 3; k++)//row\n",
    "                {\n",
    "                    #pragma unroll 1\n",
    "                    for(int l = 0; l < 3; l++)//col\n",
    "                    {\n",
    "                        float value = input_im[(i * 2 + k) * input_size  + j * 2 + l ];\n",
    "                        if(value > tmp)\n",
    "                            tmp = value;\n",
    "                    }\n",
    "                }\n",
    "                //store the result to output feature map\n",
    "                output_im[i * output_size + j] = tmp;\n",
    "            }\n",
    "        }\n",
    "    \n",
    "        input_im += input_size * input_size;\n",
    "        output_im += output_size * output_size;\n",
    "    }\n",
    "}\n",
    "\n",
    "//3x3 convolution layer\n",
    "//output one feature map per kernel\n",
    "__kernel void conv2d3x3(\n",
    "\tconst int input_channels, const int input_size,\n",
    "\tconst int pad, const int stride,\n",
    "\tconst int start_channel, //start_channel is for 1x1 feature map in fire layer\n",
    "\tconst int output_size,\n",
    "    const int filter_size,\n",
    "\t__global const float* restrict input_im,\n",
    "\t__global const float* restrict filter_weight,\n",
    "\t__global const float* restrict filter_bias,\n",
    "\t__global float *restrict output_im\n",
    "\t)\n",
    "{\n",
    "\t\n",
    "\t//filter_weight += filter_index * input_channels * 9;\n",
    "\toutput_im += start_channel * output_size * output_size;\n",
    "\t\n",
    "\t//loop over output feature map\n",
    "\tfor(int filter_index = 0; filter_index < filter_size; filter_index++)\n",
    "\t{\n",
    "        float bias = filter_bias[filter_index];\n",
    "\n",
    "\t\tfor(int i = 0; i < output_size; i++)\n",
    "\t\t{\n",
    "            for(int j = 0; j < output_size; j++)\n",
    "            {\n",
    "                //compute one element in the output feature map\n",
    "                float tmp = bias;\n",
    "\n",
    "                //compute dot product of 2 input_channels x 3 x 3 matrix\n",
    "                for(int k = 0; k < input_channels; k++)\n",
    "                {\n",
    "                    #pragma unroll\n",
    "                    for(int l = 0; l < 3; l++)\n",
    "                    {\n",
    "                        int h = i * stride + l - pad;\n",
    "                        for(int m = 0; m < 3; m++)\n",
    "                        {\n",
    "                            int w = j * stride + m - pad;\n",
    "                            if((h >= 0) && (h < input_size) && (w >= 0) && (w < input_size))\n",
    "                            {\n",
    "                                tmp += input_im[k * input_size * input_size + h * input_size + w] \\\n",
    "                                   * filter_weight[9 * k + 3 * l + m];\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                //add relu activation after conv\n",
    "                output_im[i * output_size + j] = (tmp > 0.0) ? tmp : 0.0;                 \n",
    "            }\n",
    "\t\t}\n",
    "        \n",
    "        filter_weight += input_channels * 9;\n",
    "        output_im += output_size * output_size;\n",
    "\t}\n",
    "}\n",
    "\n",
    "//1x1 convolution layer as a single kernel (V5)\n",
    "//output one feature map per kernel\n",
    "\n",
    "__kernel void conv2d1x1(\n",
    "\tconst int input_channels, \n",
    "    const int input_size,\n",
    "    const int filter_size,\n",
    "\t__global const float* restrict input_im,\n",
    "\t__global const float* restrict filter_weight,\n",
    "\t__global const float* restrict filter_bias,\n",
    "\t__global float *restrict output_im)\n",
    "{\n",
    "\t// Adding restrict keyword\n",
    "    //loop over filters\n",
    "\tfor(int f_i = 0; f_i < filter_size; f_i++)\n",
    "\t{\n",
    "        //filter_weight += f_i * input_channels;\n",
    "\n",
    "        float bias = filter_bias[f_i];\n",
    "\t\t\n",
    "        // output_im += input_size * input_size;//start_channel is for 1x1 feature map in fire layer\n",
    "\t\n",
    "\t\tfor(int ij = 0; ij < (input_size * input_size); ij++)\n",
    "\t\t{\n",
    "\t\t\tfloat tmp = bias;\n",
    "\t\t\t// int loc = i * input_size + j; // this is equal to ij\n",
    "\n",
    "\t\t\tfor(int k = 0; k < input_channels; k++)\n",
    "\t\t\t{\n",
    "\t\t\t\t//float8 weight = filter_weight[k];\n",
    "\t\t\t\t//float8 feature;\n",
    "\t\t\t\ttmp += input_im[k * input_size * input_size + ij] * filter_weight[k + f_i * input_channels];\n",
    "\t\t\t}\n",
    "\t\t\t//add relu after conv\n",
    "\t\t\toutput_im[ij + (input_size * input_size * f_i)] = (tmp > 0.0) ? tmp : 0.0;\n",
    "            //output_im[ij] = (tmp > 0.0) ? tmp : 0.0;\n",
    "\t\t}\n",
    "        //filter_weight += input_channels;\t\n",
    "        //output_im += input_size * input_size;//start_channel is for 1x1 feature map in fire layer\n",
    "\t\n",
    "\t}\n",
    "}\n",
    "\n",
    "//last layer use a 13 x 13 avgPool layer as classifier\n",
    "//one class score per kernel\n",
    "__kernel void avgpool2d(\n",
    "\t__global const float* restrict input_im,\n",
    "\t__global float* restrict output_im)\n",
    "{\n",
    "\t// int class_index = get_global_id(0);//get class score index\n",
    "    \n",
    "    //Since it's the final layer, we know that there are only 1000 classes\n",
    "    \n",
    "\t//input_im += 169 * class_index;\n",
    "\n",
    "\tfor(int class_index = 0; class_index < 1000; class_index++)\n",
    "    {\n",
    "            \n",
    "        float tmp = 0.0f;\n",
    "\n",
    "        for(int i = 0; i < 169; i++)\n",
    "        {\n",
    "            tmp += input_im[class_index * 169 + i];\n",
    "        }\n",
    "\n",
    "        output_im[class_index] = tmp / 169.0;\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run OpenCL implement  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanyo=56 #input_size\n",
    "canales_iniciales=64 #input channels and \n",
    "canales_contraidos=16 #squeeze factor\n",
    "canales_expandidos=64#expand factor\n",
    "canales_finales= np.int32(canales_expandidos * 2)\n",
    "\n",
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "acumulado_pytorch = 0\n",
    "\n",
    "imagen = np.random.randint(10,size=(1,canales_iniciales, tamanyo, tamanyo))\n",
    "\n",
    "weights1=np.random.randint(10,size=(canales_contraidos, canales_iniciales,1,1)).astype(np.float32)\n",
    "bias1=np.random.randint(10,size=(canales_contraidos,)).astype(np.float32)\n",
    "weights2a=np.random.randint(10,size=(canales_expandidos, canales_contraidos,1,1)).astype(np.float32)  \n",
    "bias2a=np.random.randint(10,size=(canales_expandidos,)).astype(np.float32)    \n",
    "weights2b=np.random.randint(10,size=(canales_expandidos, canales_contraidos,3,3)).astype(np.float32)    \n",
    "bias2b=np.random.randint(10,size=(canales_expandidos,)).astype(np.float32)\n",
    "\n",
    "tic=pc()\n",
    "\n",
    "squeeze1=nn.Conv2d(canales_iniciales, canales_contraidos, kernel_size=1, bias=False)\n",
    "squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))\n",
    "\n",
    "squeeze2a=nn.Conv2d(canales_contraidos, canales_expandidos, kernel_size=1, bias=False)\n",
    "squeeze2a.weight = nn.Parameter(torch.from_numpy(weights2a))\n",
    "squeeze2a.bias = nn.Parameter(torch.from_numpy(bias2a))\n",
    "\n",
    "squeeze2b=nn.Conv2d(canales_contraidos, canales_expandidos, kernel_size=3, bias=False, padding=1)\n",
    "squeeze2b.weight = nn.Parameter(torch.from_numpy(weights2b))\n",
    "squeeze2b.bias = nn.Parameter(torch.from_numpy(bias2b))\n",
    "\n",
    "\n",
    "imagen1  = torch.from_numpy(imagen).float()\n",
    "\n",
    "salida1=squeeze1(imagen1)\n",
    "salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "salida2a=squeeze2a(salida1_activation)\n",
    "salida2a_activation=squeeze_activation(salida2a)\n",
    "\n",
    "salida2b=squeeze2b(salida1_activation)\n",
    "salida2b_activation=squeeze_activation(salida2b)\n",
    "\n",
    "salida2_total=torch.cat([salida2a_activation,salida2b_activation], 1)\n",
    "salida2_total_a_numpy=salida2_total.detach().numpy()\n",
    "\n",
    "toc=pc()\n",
    "acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "\n",
    "####### OPENCL COMPARISON #######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7051/1897510988.py:13: RuntimeWarning: overflow encountered in cast\n",
      "  h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n"
     ]
    }
   ],
   "source": [
    "# NDRANGE\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_squeeze_weight = weights1.reshape(-1)\n",
    "fire1_squeeze_bias = bias1\n",
    "fire1_expand1x1_weight = weights2a.reshape(-1)\n",
    "fire1_expand1x1_bias = bias2a\n",
    "fire1_expand3x3_weight =weights2b.reshape(-1)\n",
    "fire1_expand3x3_bias = bias2b\n",
    "\n",
    "h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire1_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "d_fire1_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_weight)\n",
    "d_fire1_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_bias)\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "\n",
    "tic2 = pc()\n",
    "\n",
    "conv1x1_NDR(queue,(canales_contraidos, tamanyo), None, np.int32(canales_iniciales/4), tamanyo, d_sample, d_fire1_squeeze_weight, d_fire1_squeeze_bias, d_result_fire1_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_NDR(queue1,(canales_expandidos, tamanyo), None, np.int32(canales_contraidos/4), tamanyo, d_result_fire1_squeeze, d_fire1_expand1x1_weight, d_fire1_expand1x1_bias, d_result_fire1_expand)\n",
    "conv3x3_NDR(queue,(canales_expandidos, tamanyo), None, canales_contraidos, tamanyo, 1, 1, canales_expandidos, tamanyo, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire1_expand, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos = h_result_fire1_expand.reshape(-1,tamanyo,tamanyo)\n",
    "\n",
    "rtime = pc() - tic2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7051/1029732790.py:13: RuntimeWarning: overflow encountered in cast\n",
      "  h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n"
     ]
    }
   ],
   "source": [
    "# Simple task\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_squeeze_weight = weights1.reshape(-1)\n",
    "fire1_squeeze_bias = bias1\n",
    "fire1_expand1x1_weight = weights2a.reshape(-1)\n",
    "fire1_expand1x1_bias = bias2a\n",
    "fire1_expand3x3_weight =weights2b.reshape(-1)\n",
    "fire1_expand3x3_bias = bias2b\n",
    "\n",
    "h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire1_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "d_fire1_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_weight)\n",
    "d_fire1_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_bias)\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "\n",
    "tic3 = pc()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, canales_iniciales, tamanyo, canales_contraidos, d_sample, d_fire1_squeeze_weight, d_fire1_squeeze_bias, d_result_fire1_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, canales_contraidos, tamanyo, canales_expandidos, d_result_fire1_squeeze, d_fire1_expand1x1_weight, d_fire1_expand1x1_bias, d_result_fire1_expand)\n",
    "conv3x3_ST(queue1,(1,), None, canales_contraidos, tamanyo, 1, 1, canales_expandidos, tamanyo, canales_expandidos, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire1_expand, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos1 = h_result_fire1_expand.reshape(-1,tamanyo,tamanyo)\n",
    "\n",
    "rtime1 = pc() - tic3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo en segundos con pytorch=  0.0043442879996291595\n",
      "tiempo en segundos con opencl (NDRANGE)= 0.013322005999725661\n",
      "tiempo en segundos con opencl (Simple Task)= 0.023072717000104603\n",
      "comparativa (pytorch == NDRange):  True\n",
      "comparativa (pytorch == Simple Task):  True\n",
      "comparativa (NDRange == Simple Task):  True\n"
     ]
    }
   ],
   "source": [
    "print (\"tiempo en segundos con pytorch= \", toc-tic)\n",
    "print (\"tiempo en segundos con opencl (NDRANGE)=\",rtime)\n",
    "print (\"tiempo en segundos con opencl (Simple Task)=\",rtime1)\n",
    "\n",
    "comparativa1=np.allclose(salida2_total_a_numpy.reshape(-1,tamanyo,tamanyo), veamos,rtol=1e-01, atol=1e-01)\n",
    "comparativa2=np.allclose(salida2_total_a_numpy.reshape(-1,tamanyo,tamanyo), veamos1,rtol=1e-01, atol=1e-01)\n",
    "comparativa3=np.allclose(veamos, veamos1,rtol=1e-01, atol=1e-01)\n",
    "\n",
    "print(\"comparativa (pytorch == NDRange): \",comparativa1)\n",
    "print(\"comparativa (pytorch == Simple Task): \",comparativa2)\n",
    "print(\"comparativa (NDRange == Simple Task): \",comparativa3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(canales_finales):\n",
    "    for j in range(tamanyo):\n",
    "        for k in range(tamanyo):\n",
    "            if (abs(salida2_total_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k] - veamos1[i][j][k])) > 1e-01:\n",
    "                print(\"i:\", i, \"j:\", j, \"k:\", k, salida2_total_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k], veamos1[i][j][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 3: emulation\n",
    "Creat & build program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl.Context at 0x6eebff8 on <pyopencl.Device 'Intel(R) FPGA Emulation Device' on 'Intel(R) FPGA Emulation Platform for OpenCL(TM)' at 0x4f871f8>>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platforms = cl.get_platforms()\n",
    "context = cl.Context(\n",
    "        dev_type=cl.device_type.ALL,\n",
    "        properties=[(cl.context_properties.PLATFORM, platforms[1])])\n",
    "device = platforms[1].get_devices()\n",
    "\n",
    "queue = cl.CommandQueue(context)\n",
    "queue1 = cl.CommandQueue(context)\n",
    "\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wksp = '../device/v1.3/squeezenet/bin_em/'\n",
    "\n",
    "file_dir = wksp + 'squeezenet_NDRange.aocx'\n",
    "\n",
    "kernelSource = open(file_dir, mode='rb').read()\n",
    "program_NDR = cl.Program(context, device, [kernelSource]).build()\n",
    "\n",
    "file_dir = wksp + 'squeezenet_ST.aocx'\n",
    "\n",
    "kernelSource = open(file_dir, mode='rb').read()\n",
    "program_ST = cl.Program(context, device, [kernelSource]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv3x3_NDR = program_NDR.conv2d3x3\n",
    "conv3x3_NDR.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "maxpool_NDR = program_NDR.maxpool2d\n",
    "maxpool_NDR.set_scalar_arg_dtypes([np.int32, np.int32, None, None])\n",
    "\n",
    "conv1x1_NDR = program_NDR.conv2d1x1\n",
    "conv1x1_NDR.set_scalar_arg_dtypes([np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "avgpool_NDR = program_NDR.avgpool2d\n",
    "avgpool_NDR.set_scalar_arg_dtypes([None, None])\n",
    "\n",
    "conv3x3_ST = program_ST.conv2d3x3\n",
    "conv3x3_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "maxpool_ST = program_ST.maxpool2d\n",
    "maxpool_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, None, None])\n",
    "\n",
    "conv1x1_ST = program_ST.conv2d1x1\n",
    "conv1x1_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "avgpool_ST = program_ST.avgpool2d\n",
    "avgpool_ST.set_scalar_arg_dtypes([None, None])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run OpenCL implement  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanyo=56 #input_size\n",
    "canales_iniciales=64 #input channels and \n",
    "canales_contraidos=16 #squeeze factor\n",
    "canales_expandidos=64#expand factor\n",
    "canales_finales= np.int32(canales_expandidos * 2)\n",
    "\n",
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "acumulado_pytorch = 0\n",
    "\n",
    "imagen = np.random.randint(10,size=(1,canales_iniciales, tamanyo, tamanyo))\n",
    "\n",
    "weights1=np.random.randint(10,size=(canales_contraidos, canales_iniciales,1,1)).astype(np.float32)\n",
    "bias1=np.random.randint(10,size=(canales_contraidos,)).astype(np.float32)\n",
    "weights2a=np.random.randint(10,size=(canales_expandidos, canales_contraidos,1,1)).astype(np.float32)  \n",
    "bias2a=np.random.randint(10,size=(canales_expandidos,)).astype(np.float32)    \n",
    "weights2b=np.random.randint(10,size=(canales_expandidos, canales_contraidos,3,3)).astype(np.float32)    \n",
    "bias2b=np.random.randint(10,size=(canales_expandidos,)).astype(np.float32)\n",
    "\n",
    "tic=pc()\n",
    "\n",
    "squeeze1=nn.Conv2d(canales_iniciales, canales_contraidos, kernel_size=1, bias=False)\n",
    "squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))\n",
    "\n",
    "squeeze2a=nn.Conv2d(canales_contraidos, canales_expandidos, kernel_size=1, bias=False)\n",
    "squeeze2a.weight = nn.Parameter(torch.from_numpy(weights2a))\n",
    "squeeze2a.bias = nn.Parameter(torch.from_numpy(bias2a))\n",
    "\n",
    "squeeze2b=nn.Conv2d(canales_contraidos, canales_expandidos, kernel_size=3, bias=False, padding=1)\n",
    "squeeze2b.weight = nn.Parameter(torch.from_numpy(weights2b))\n",
    "squeeze2b.bias = nn.Parameter(torch.from_numpy(bias2b))\n",
    "\n",
    "\n",
    "imagen1  = torch.from_numpy(imagen).float()\n",
    "\n",
    "salida1=squeeze1(imagen1)\n",
    "salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "salida2a=squeeze2a(salida1_activation)\n",
    "salida2a_activation=squeeze_activation(salida2a)\n",
    "\n",
    "salida2b=squeeze2b(salida1_activation)\n",
    "salida2b_activation=squeeze_activation(salida2b)\n",
    "\n",
    "salida2_total=torch.cat([salida2a_activation,salida2b_activation], 1)\n",
    "salida2_total_a_numpy=salida2_total.detach().numpy()\n",
    "\n",
    "toc=pc()\n",
    "acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "\n",
    "####### OPENCL COMPARISON #######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NDRANGE\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_squeeze_weight = weights1.reshape(-1)\n",
    "fire1_squeeze_bias = bias1\n",
    "fire1_expand1x1_weight = weights2a.reshape(-1)\n",
    "fire1_expand1x1_bias = bias2a\n",
    "fire1_expand3x3_weight =weights2b.reshape(-1)\n",
    "fire1_expand3x3_bias = bias2b\n",
    "\n",
    "h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire1_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "d_fire1_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_weight)\n",
    "d_fire1_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_bias)\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "\n",
    "tic2 = pc()\n",
    "\n",
    "conv1x1_NDR(queue,(canales_contraidos, tamanyo), None, np.int32(canales_iniciales/4), tamanyo, d_sample, d_fire1_squeeze_weight, d_fire1_squeeze_bias, d_result_fire1_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_NDR(queue1,(canales_expandidos, tamanyo), None, np.int32(canales_contraidos/4), tamanyo, d_result_fire1_squeeze, d_fire1_expand1x1_weight, d_fire1_expand1x1_bias, d_result_fire1_expand)\n",
    "conv3x3_NDR(queue,(canales_expandidos, tamanyo), None, canales_contraidos, tamanyo, 1, 1, canales_expandidos, tamanyo, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire1_expand, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos = h_result_fire1_expand.reshape(-1,tamanyo,tamanyo)\n",
    "\n",
    "rtime = pc() - tic2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple task\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_squeeze_weight = weights1.reshape(-1)\n",
    "fire1_squeeze_bias = bias1\n",
    "fire1_expand1x1_weight = weights2a.reshape(-1)\n",
    "fire1_expand1x1_bias = bias2a\n",
    "fire1_expand3x3_weight =weights2b.reshape(-1)\n",
    "fire1_expand3x3_bias = bias2b\n",
    "\n",
    "h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire1_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "d_fire1_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_weight)\n",
    "d_fire1_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_bias)\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "\n",
    "tic3 = pc()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, canales_iniciales, tamanyo, canales_contraidos, d_sample, d_fire1_squeeze_weight, d_fire1_squeeze_bias, d_result_fire1_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, canales_contraidos, tamanyo, canales_expandidos, d_result_fire1_squeeze, d_fire1_expand1x1_weight, d_fire1_expand1x1_bias, d_result_fire1_expand)\n",
    "conv3x3_ST(queue1,(1,), None, canales_contraidos, tamanyo, 1, 1, canales_expandidos, tamanyo, canales_expandidos, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire1_expand, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos1 = h_result_fire1_expand.reshape(-1,tamanyo,tamanyo)\n",
    "\n",
    "rtime1 = pc() - tic3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo en segundos con pytorch=  0.004821141999855172\n",
      "tiempo en segundos con opencl (NDRANGE)= 0.027683909000188578\n",
      "tiempo en segundos con opencl (Simple Task)= 0.031077208000169776\n",
      "comparativa (pytorch == NDRange):  True\n",
      "comparativa (pytorch == Simple Task):  True\n",
      "comparativa (NDRange == Simple Task):  True\n"
     ]
    }
   ],
   "source": [
    "print (\"tiempo en segundos con pytorch= \", toc-tic)\n",
    "print (\"tiempo en segundos con opencl (NDRANGE)=\",rtime)\n",
    "print (\"tiempo en segundos con opencl (Simple Task)=\",rtime1)\n",
    "\n",
    "comparativa1=np.allclose(salida2_total_a_numpy.reshape(-1,tamanyo,tamanyo), veamos,rtol=1e-01, atol=1e-01)\n",
    "comparativa2=np.allclose(salida2_total_a_numpy.reshape(-1,tamanyo,tamanyo), veamos1,rtol=1e-01, atol=1e-01)\n",
    "comparativa3=np.allclose(veamos, veamos1,rtol=1e-01, atol=1e-01)\n",
    "\n",
    "print(\"comparativa (pytorch == NDRange): \",comparativa1)\n",
    "print(\"comparativa (pytorch == Simple Task): \",comparativa2)\n",
    "print(\"comparativa (NDRange == Simple Task): \",comparativa3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(canales_finales):\n",
    "    for j in range(tamanyo):\n",
    "        for k in range(tamanyo):\n",
    "            if (abs(salida2_total_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k] - veamos1[i][j][k])) > 1e-01:\n",
    "                print(\"i:\", i, \"j:\", j, \"k:\", k, salida2_total_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k], veamos1[i][j][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 4: simulación\n",
    "Creat & build program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl.Context at 0x6ef5f60 on <pyopencl.Device 'SimulatorDevice : Multi-process Simulator (aclmsim0)' on 'Intel(R) FPGA SDK for OpenCL(TM)' at 0x7fd26047a0d8>>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platforms = cl.get_platforms()\n",
    "context = cl.Context(\n",
    "        dev_type=cl.device_type.ALL,\n",
    "        properties=[(cl.context_properties.PLATFORM, platforms[2])])\n",
    "device = platforms[2].get_devices()\n",
    "\n",
    "queue = cl.CommandQueue(context)\n",
    "queue1 = cl.CommandQueue(context)\n",
    "\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joerock/anaconda3/envs/TFM/lib/python3.8/site-packages/pyopencl/__init__.py:270: CompilerWarning: Non-empty compiler output encountered. Set the environment variable PYOPENCL_COMPILER_OUTPUT=1 to see more.\n",
      "  warn(\"Non-empty compiler output encountered. Set the \"\n"
     ]
    }
   ],
   "source": [
    "wksp = '../device/v1.3/squeezenet/bin_sim/'\n",
    "\n",
    "file_dir = wksp + 'squeezenet_NDRange.aocx'\n",
    "\n",
    "kernelSource = open(file_dir, mode='rb').read()\n",
    "program_NDR = cl.Program(context, device, [kernelSource]).build()\n",
    "\n",
    "file_dir = wksp + 'squeezenet_ST.aocx'\n",
    "\n",
    "kernelSource = open(file_dir, mode='rb').read()\n",
    "program_ST = cl.Program(context, device, [kernelSource]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv3x3_NDR = program_NDR.conv2d3x3\n",
    "conv3x3_NDR.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "maxpool_NDR = program_NDR.maxpool2d\n",
    "maxpool_NDR.set_scalar_arg_dtypes([np.int32, np.int32, None, None])\n",
    "\n",
    "conv1x1_NDR = program_NDR.conv2d1x1\n",
    "conv1x1_NDR.set_scalar_arg_dtypes([np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "avgpool_NDR = program_NDR.avgpool2d\n",
    "avgpool_NDR.set_scalar_arg_dtypes([None, None])\n",
    "\n",
    "conv3x3_ST = program_ST.conv2d3x3\n",
    "conv3x3_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "maxpool_ST = program_ST.maxpool2d\n",
    "maxpool_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, None, None])\n",
    "\n",
    "conv1x1_ST = program_ST.conv2d1x1\n",
    "conv1x1_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "avgpool_ST = program_ST.avgpool2d\n",
    "avgpool_ST.set_scalar_arg_dtypes([None, None])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run OpenCL implement  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanyo=5 #input_size\n",
    "canales_iniciales=8 #input channels and \n",
    "canales_contraidos=4 #squeeze factor\n",
    "canales_expandidos=4#expand factor\n",
    "canales_finales= np.int32(canales_expandidos * 2)\n",
    "\n",
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "acumulado_pytorch = 0\n",
    "\n",
    "imagen = np.random.randint(10,size=(1,canales_iniciales, tamanyo, tamanyo))\n",
    "\n",
    "weights1=np.random.randint(10,size=(canales_contraidos, canales_iniciales,1,1)).astype(np.float32)\n",
    "bias1=np.random.randint(10,size=(canales_contraidos,)).astype(np.float32)\n",
    "weights2a=np.random.randint(10,size=(canales_expandidos, canales_contraidos,1,1)).astype(np.float32)  \n",
    "bias2a=np.random.randint(10,size=(canales_expandidos,)).astype(np.float32)    \n",
    "weights2b=np.random.randint(10,size=(canales_expandidos, canales_contraidos,3,3)).astype(np.float32)    \n",
    "bias2b=np.random.randint(10,size=(canales_expandidos,)).astype(np.float32)\n",
    "\n",
    "tic=pc()\n",
    "\n",
    "squeeze1=nn.Conv2d(canales_iniciales, canales_contraidos, kernel_size=1, bias=False)\n",
    "squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))\n",
    "\n",
    "squeeze2a=nn.Conv2d(canales_contraidos, canales_expandidos, kernel_size=1, bias=False)\n",
    "squeeze2a.weight = nn.Parameter(torch.from_numpy(weights2a))\n",
    "squeeze2a.bias = nn.Parameter(torch.from_numpy(bias2a))\n",
    "\n",
    "squeeze2b=nn.Conv2d(canales_contraidos, canales_expandidos, kernel_size=3, bias=False, padding=1)\n",
    "squeeze2b.weight = nn.Parameter(torch.from_numpy(weights2b))\n",
    "squeeze2b.bias = nn.Parameter(torch.from_numpy(bias2b))\n",
    "\n",
    "\n",
    "imagen1  = torch.from_numpy(imagen).float()\n",
    "\n",
    "salida1=squeeze1(imagen1)\n",
    "salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "salida2a=squeeze2a(salida1_activation)\n",
    "salida2a_activation=squeeze_activation(salida2a)\n",
    "\n",
    "salida2b=squeeze2b(salida1_activation)\n",
    "salida2b_activation=squeeze_activation(salida2b)\n",
    "\n",
    "salida2_total=torch.cat([salida2a_activation,salida2b_activation], 1)\n",
    "salida2_total_a_numpy=salida2_total.detach().numpy()\n",
    "\n",
    "toc=pc()\n",
    "acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "\n",
    "####### OPENCL COMPARISON #######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7051/1897510988.py:14: RuntimeWarning: overflow encountered in cast\n",
      "  h_result_fire1_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n"
     ]
    }
   ],
   "source": [
    "# NDRANGE\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_squeeze_weight = weights1.reshape(-1)\n",
    "fire1_squeeze_bias = bias1\n",
    "fire1_expand1x1_weight = weights2a.reshape(-1)\n",
    "fire1_expand1x1_bias = bias2a\n",
    "fire1_expand3x3_weight =weights2b.reshape(-1)\n",
    "fire1_expand3x3_bias = bias2b\n",
    "\n",
    "h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire1_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "d_fire1_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_weight)\n",
    "d_fire1_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_bias)\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "\n",
    "tic2 = pc()\n",
    "\n",
    "conv1x1_NDR(queue,(canales_contraidos, tamanyo), None, np.int32(canales_iniciales/4), tamanyo, d_sample, d_fire1_squeeze_weight, d_fire1_squeeze_bias, d_result_fire1_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_NDR(queue1,(canales_expandidos, tamanyo), None, np.int32(canales_contraidos/4), tamanyo, d_result_fire1_squeeze, d_fire1_expand1x1_weight, d_fire1_expand1x1_bias, d_result_fire1_expand)\n",
    "conv3x3_NDR(queue,(canales_expandidos, tamanyo), None, canales_contraidos, tamanyo, 1, 1, canales_expandidos, tamanyo, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire1_expand, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos = h_result_fire1_expand.reshape(-1,tamanyo,tamanyo)\n",
    "\n",
    "rtime = pc() - tic2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7051/1029732790.py:14: RuntimeWarning: overflow encountered in cast\n",
      "  h_result_fire1_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n"
     ]
    }
   ],
   "source": [
    "# Simple task\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_squeeze_weight = weights1.reshape(-1)\n",
    "fire1_squeeze_bias = bias1\n",
    "fire1_expand1x1_weight = weights2a.reshape(-1)\n",
    "fire1_expand1x1_bias = bias2a\n",
    "fire1_expand3x3_weight =weights2b.reshape(-1)\n",
    "fire1_expand3x3_bias = bias2b\n",
    "\n",
    "h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire1_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "d_fire1_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_weight)\n",
    "d_fire1_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_bias)\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "\n",
    "tic3 = pc()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, canales_iniciales, tamanyo, canales_contraidos, d_sample, d_fire1_squeeze_weight, d_fire1_squeeze_bias, d_result_fire1_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, canales_contraidos, tamanyo, canales_expandidos, d_result_fire1_squeeze, d_fire1_expand1x1_weight, d_fire1_expand1x1_bias, d_result_fire1_expand)\n",
    "conv3x3_ST(queue1,(1,), None, canales_contraidos, tamanyo, 1, 1, canales_expandidos, tamanyo, canales_expandidos, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire1_expand, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos1 = h_result_fire1_expand.reshape(-1,tamanyo,tamanyo)\n",
    "\n",
    "rtime1 = pc() - tic3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo en segundos con pytorch=  0.20604586599984032\n",
      "tiempo en segundos con opencl (NDRANGE)= 124.8048321590004\n",
      "tiempo en segundos con opencl (Simple Task)= 470.6451553429997\n",
      "comparativa (pytorch == NDRange):  True\n",
      "comparativa (pytorch == Simple Task):  True\n",
      "comparativa (NDRange == Simple Task):  True\n"
     ]
    }
   ],
   "source": [
    "print (\"tiempo en segundos con pytorch= \", toc-tic)\n",
    "print (\"tiempo en segundos con opencl (NDRANGE)=\",rtime)\n",
    "print (\"tiempo en segundos con opencl (Simple Task)=\",rtime1)\n",
    "\n",
    "comparativa1=np.allclose(salida2_total_a_numpy.reshape(-1,tamanyo,tamanyo), veamos,rtol=1e-01, atol=1e-01)\n",
    "comparativa2=np.allclose(salida2_total_a_numpy.reshape(-1,tamanyo,tamanyo), veamos1,rtol=1e-01, atol=1e-01)\n",
    "comparativa3=np.allclose(veamos, veamos1,rtol=1e-01, atol=1e-01)\n",
    "\n",
    "print(\"comparativa (pytorch == NDRange): \",comparativa1)\n",
    "print(\"comparativa (pytorch == Simple Task): \",comparativa2)\n",
    "print(\"comparativa (NDRange == Simple Task): \",comparativa3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch (2, 5, 5) [123. 151. 184. 152. 138.]\n",
      "NDRange [123. 151. 184. 152. 138.]\n",
      "Simple task [ 77.  71. 126. 184. 132.]\n",
      "(1, 8, 5, 5) False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"pytorch\", veamos.shape, salida1_a_numpy.reshape(-1,tamanyo,tamanyo)[0][0])\n",
    "print(\"NDRange\", veamos[0][0])\n",
    "print(\"Simple task\", veamos1[0][0])\n",
    "print(imagen.shape, np.allclose(imagen, np.ones((1,canales_iniciales, tamanyo, tamanyo)).astype(np.float32), rtol=1e-01, atol=1e-01))\n",
    "#print(weights1[6])\n",
    "# print(fire1_squeeze_weight)\n",
    "#print(bias1[6])\n",
    "# print(imagen1_obtenida)\n",
    "# print(veamos2)\n",
    "print(np.allclose(salida1_a_numpy, veamos1,rtol=1e-01, atol=1e-01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(canales_finales):\n",
    "    for j in range(tamanyo):\n",
    "        for k in range(tamanyo):\n",
    "            if (abs(salida2_total_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k] - veamos1[i][j][k])) > 1e-01:\n",
    "                print(\"i:\", i, \"j:\", j, \"k:\", k, salida2_total_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k], veamos1[i][j][k])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
