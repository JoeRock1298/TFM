{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug SqueezeNet v1.3 (Simple Task) OpenCL implement with PyOpenCL and PyTorch\n",
    "Partial code are copied heavily from https://github.com/pytorch/vision/blob/master/torchvision/models/squeezenet.py  \n",
    "SqueezeNet Paper:https://arxiv.org/abs/1602.07360  \n",
    "SqueezeNet 1.1 model from https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1   \n",
    "SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters than SqueezeNet 1.0, without sacrificing accuracy.\n",
    "\n",
    "TEST DE IMPLEMENTACIÃ“N CONV3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#some set up\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from PIL import Image\n",
    "import math\n",
    "import time\n",
    "from time import sleep, perf_counter as pc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OpenCL setup\n",
    "import pyopencl as cl\n",
    "import sys\n",
    "sys.path.append('../common')\n",
    "import deviceinfo\n",
    "from time import time\n",
    "\n",
    "#wksp = '../device/v1.3/conv3x3'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veamos ahora solo conv3x3 con opencl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step1: OpenCL preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl.Context at 0x687a4a8 on <pyopencl.Device '12th Gen Intel(R) Core(TM) i7-12650H' on 'Intel(R) OpenCL' at 0x4f7fab8>>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platforms = cl.get_platforms()\n",
    "context = cl.Context(\n",
    "        dev_type=cl.device_type.ALL,\n",
    "        properties=[(cl.context_properties.PLATFORM, platforms[0])])\n",
    "queue = cl.CommandQueue(context)\n",
    "\n",
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 2: creat kernels\n",
    "Creat & build program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "wksp = ''\n",
    "\n",
    "file_dir = wksp + 'conv3x3_NDRange.aocx'\n",
    "\n",
    "kernelSource = open(file_dir, mode='rb').read()\n",
    "program_NDR = cl.Program(context, device, [kernelSource]).build()\n",
    "\n",
    "file_dir = wksp + 'conv3x3_ST.aocx'\n",
    "\n",
    "kernelSource = open(file_dir, mode='rb').read()\n",
    "program_ST = cl.Program(context, device, [kernelSource]).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creat kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv3x3_NDR = program_NDR.conv2d3x3\n",
    "conv3x3_NDR.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "conv3x3_ST = program_ST.conv2d3x3\n",
    "conv3x3_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### OpenCL kernel: conv3x3_NDRange.cl\n",
    "\n",
    "conv2d3x3: 2-D 3x3 convolution.  \n",
    "\n",
    "```C\n",
    "//3x3 convolution layer\n",
    "//output one feature map per kernel\n",
    "__kernel void conv2d3x3(\n",
    "\tconst int input_channels, const int input_size,\n",
    "\tconst int pad, const int stride,\n",
    "\tconst int start_channel, //start_channel is for 1x1 feature map in fire layer\n",
    "\tconst int output_size,\n",
    "\t__global float* input_im,\n",
    "\t__global const float* filter_weight,\n",
    "\t__global const float* filter_bias,\n",
    "\t__global float *restrict output_im\n",
    "\t)\n",
    "{\n",
    "\tint filter_index = get_global_id(0); //get output channel index\n",
    "\tint i =  get_global_id(1);\n",
    "\n",
    "\tfilter_weight += filter_index * input_channels * 9;\n",
    "\tfloat bias = filter_bias[filter_index];\n",
    "\toutput_im += (start_channel + filter_index) * output_size * output_size;\n",
    "\t\n",
    "\t//loop over output feature map\n",
    "\t//for(int i = 0; i < output_size; i++)\n",
    "\t{\n",
    "\t\tfor(int j = 0; j < output_size; j++)\n",
    "\t\t{\n",
    "\t\t\t//compute one element in the output feature map\n",
    "\t\t\tfloat tmp = bias;\n",
    "\t\t\t\n",
    "\t\t\t//compute dot product of 2 input_channels x 3 x 3 matrix\n",
    "\t\t\tfor(int k = 0; k < input_channels; k++)\n",
    "\t\t\t{\n",
    "\t\t\t\t#pragma unroll\n",
    "\t\t\t\tfor(int l = 0; l < 3; l++)\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\tint h = i * stride + l - pad;\n",
    "\t\t\t\t\tfor(int m = 0; m < 3; m++)\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\tint w = j * stride + m - pad;\n",
    "\t\t\t\t\t\tif((h >= 0) && (h < input_size) && (w >= 0) && (w < input_size))\n",
    "\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\ttmp += input_im[k * input_size * input_size + h * input_size + w] \\\n",
    "                               * filter_weight[9 * k + 3 * l + m];\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\t//add relu activation after conv\n",
    "\t\t\toutput_im[i * output_size + j] = (tmp > 0.0) ? tmp : 0.0;\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "```\n",
    "#### OpenCL kernel: conv3x3_ST.cl\n",
    "\n",
    "conv2d3x3: 2-D 3x3 convolution. \n",
    "\n",
    "```C\n",
    "//3x3 convolution layer\n",
    "//output one feature map per kernel\n",
    "__kernel void conv2d3x3(\n",
    "\tconst int input_channels, const int input_size,\n",
    "\tconst int pad, const int stride,\n",
    "\tconst int start_channel, //start_channel is for 1x1 feature map in fire layer\n",
    "\tconst int output_size,\n",
    "    const int filter_size,\n",
    "\t__global float* input_im,\n",
    "\t__global const float* filter_weight,\n",
    "\t__global const float* filter_bias,\n",
    "\t__global float *restrict output_im\n",
    "\t)\n",
    "{\n",
    "\t\n",
    "\t//filter_weight += filter_index * input_channels * 9;\n",
    "\toutput_im += start_channel * output_size * output_size;\n",
    "\t\n",
    "\t//loop over output feature map\n",
    "\tfor(int filter_index = 0; filter_index < filter_size; filter_index++)\n",
    "\t{\n",
    "        float bias = filter_bias[filter_index];\n",
    "\n",
    "\t\tfor(int i = 0; i < output_size; i++)\n",
    "\t\t{\n",
    "            for(int j = 0; j < output_size; j++)\n",
    "            {\n",
    "                //compute one element in the output feature map\n",
    "                float tmp = bias;\n",
    "\n",
    "                //compute dot product of 2 input_channels x 3 x 3 matrix\n",
    "                for(int k = 0; k < input_channels; k++)\n",
    "                {\n",
    "                    #pragma unroll\n",
    "                    for(int l = 0; l < 3; l++)\n",
    "                    {\n",
    "                        int h = i * stride + l - pad;\n",
    "                        for(int m = 0; m < 3; m++)\n",
    "                        {\n",
    "                            int w = j * stride + m - pad;\n",
    "                            if((h >= 0) && (h < input_size) && (w >= 0) && (w < input_size))\n",
    "                            {\n",
    "                                tmp += input_im[k * input_size * input_size + h * input_size + w] \\\n",
    "                                   * filter_weight[9 * k + 3 * l + m];\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                //add relu activation after conv\n",
    "                output_im[i * output_size + j] = (tmp > 0.0) ? tmp : 0.0;                 \n",
    "            }\n",
    "\t\t}\n",
    "        \n",
    "        filter_weight += input_channels * 9;\n",
    "        output_im += output_size * output_size;\n",
    "\t}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run OpenCL implement  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanyo=56 #input_size\n",
    "canales_iniciales=64 #input_channels\n",
    "canales_contraidos=16 #filter_size\n",
    "canales_finales = 128\n",
    "\n",
    "acumulado_pytorch=0\n",
    "\n",
    "imagen = np.random.randint(10,size=(1,canales_contraidos, tamanyo, tamanyo)).astype(np.float32)\n",
    "#imagen = np.ones((1,canales_contraidos, tamanyo, tamanyo)).astype(np.float32)\n",
    "\n",
    "weights1=np.random.randint(10,size=(canales_iniciales, canales_contraidos, 3, 3)).astype(np.float32)\n",
    "bias1=np.random.randint(10,size=(canales_iniciales,)).astype(np.float32)\n",
    "\n",
    "#weights1=np.ones((canales_iniciales, canales_contraidos, 3, 3)).astype(np.float32)\n",
    "#bias1=np.ones((canales_iniciales,)).astype(np.float32)\n",
    "\n",
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "tic=pc()\n",
    "squeeze1=nn.Conv2d(canales_iniciales, canales_contraidos, kernel_size=3, bias=False, padding=1)\n",
    "squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))\n",
    "\n",
    "imagen1  = torch.from_numpy(imagen).float()\n",
    "\n",
    "salida1=squeeze1(imagen1)\n",
    "salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "salida1_a_numpy=salida1_activation.detach().numpy()\n",
    "\n",
    "toc=pc()\n",
    "acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "\n",
    "####### OPENCL COMPARISON #######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NDRANGE\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_expand3x3_weight = weights1.reshape(-1)\n",
    "fire1_expand3x3_bias = bias1\n",
    "\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "h_result_fire1_expand = np.empty(1 * canales_iniciales * tamanyo * tamanyo).astype(np.float32) # we wil only check 3x3 convolituional performance\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "\n",
    "#offset = np.int32(canales_iniciales)\n",
    "offset = np.int32(0)\n",
    "\n",
    "tic2 = pc()\n",
    "\n",
    "conv3x3_NDR(queue,(canales_iniciales, tamanyo), None, canales_contraidos, tamanyo, 1, 1, offset, tamanyo, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire1_expand, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos = h_result_fire1_expand.reshape(-1,tamanyo,tamanyo)\n",
    "\n",
    "rtime = pc() - tic2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple task\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_expand3x3_weight = weights1.reshape(-1)\n",
    "fire1_expand3x3_bias = bias1\n",
    "\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "h_result_fire1_expand = np.empty(1 * canales_iniciales * tamanyo * tamanyo).astype(np.float32) # we wil only check 3x3 convolituional performance\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "\n",
    "#offset = np.int32(canales_iniciales)\n",
    "offset = np.int32(0)\n",
    "\n",
    "tic3 = pc()\n",
    "\n",
    "conv3x3_ST(queue,(1,), None, np.int32(canales_contraidos), tamanyo, 1, 1, offset, tamanyo, canales_iniciales, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire1_expand, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos1 = h_result_fire1_expand.reshape(-1,tamanyo,tamanyo)\n",
    "\n",
    "rtime1 = pc() - tic3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo en segundos con pytorch=  0.0030234180003390065\n",
      "tiempo en segundos con opencl (NDRANGE)= 0.03991814599976351\n",
      "tiempo en segundos con opencl (Simple Task)= 0.04235464699922886\n",
      "comparativa (pytorch == NDRange):  True\n",
      "comparativa (pytorch == Simple Task):  True\n",
      "comparativa (NDRange == Simple Task):  True\n"
     ]
    }
   ],
   "source": [
    "print (\"tiempo en segundos con pytorch= \", toc-tic)\n",
    "print (\"tiempo en segundos con opencl (NDRANGE)=\",rtime)\n",
    "print (\"tiempo en segundos con opencl (Simple Task)=\",rtime1)\n",
    "\n",
    "comparativa1=np.allclose(salida1_a_numpy, veamos,rtol=1e-01, atol=1e-01)\n",
    "comparativa2=np.allclose(salida1_a_numpy, veamos1,rtol=1e-01, atol=1e-01)\n",
    "comparativa3=np.allclose(veamos, veamos1,rtol=1e-01, atol=1e-01)\n",
    "\n",
    "print(\"comparativa (pytorch == NDRange): \",comparativa1)\n",
    "print(\"comparativa (pytorch == Simple Task): \",comparativa2)\n",
    "print(\"comparativa (NDRange == Simple Task): \",comparativa3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(canales_contraidos):\n",
    "    for j in range(tamanyo):\n",
    "        for k in range(tamanyo):\n",
    "            if (abs(salida1_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k] - veamos1[i][j][k])) > 1e-01:\n",
    "                print(\"i:\", i, \"j:\", j, \"k:\", k, salida1_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k], veamos1[i][j][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(canales_contraidos):\n",
    "    for j in range(tamanyo):\n",
    "        for k in range(tamanyo):\n",
    "            if (abs(salida1_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k] - veamos1[i][j][k])) > 1e-01:\n",
    "                print(\"i:\", i, \"j:\", j, \"k:\", k, salida1_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k], veamos1[i][j][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
