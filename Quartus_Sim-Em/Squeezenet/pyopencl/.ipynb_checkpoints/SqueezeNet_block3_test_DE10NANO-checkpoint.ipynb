{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug SqueezeNet v1.3 (Simple Task) OpenCL implement with PyOpenCL and PyTorch\n",
    "Partial code are copied heavily from https://github.com/pytorch/vision/blob/master/torchvision/models/squeezenet.py  \n",
    "SqueezeNet Paper:https://arxiv.org/abs/1602.07360  \n",
    "SqueezeNet 1.1 model from https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1   \n",
    "SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters than SqueezeNet 1.0, without sacrificing accuracy.\n",
    "\n",
    "TTests con bloque 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#some set up\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from PIL import Image\n",
    "import math\n",
    "import time\n",
    "from time import sleep, perf_counter as pc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OpenCL setup\n",
    "import pyopencl as cl\n",
    "import sys\n",
    "sys.path.append('../python_common')\n",
    "import deviceinfo\n",
    "from time import time\n",
    "\n",
    "#wksp = '../device/v1.3/squeezenet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veamos ahora fire con opencl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step1: OpenCL preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl.Context at 0x687a4a8 on <pyopencl.Device '12th Gen Intel(R) Core(TM) i7-12650H' on 'Intel(R) OpenCL' at 0x4f7fab8>>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Devices and compute context\n",
    "platforms = cl.get_platforms()\n",
    "context = cl.Context(\n",
    "        dev_type=cl.device_type.ALL,\n",
    "        properties=[(cl.context_properties.PLATFORM, platforms[0])])\n",
    "device = platforms[0].get_devices()\n",
    "\n",
    "# Create a command queue\n",
    "queue = cl.CommandQueue(context)\n",
    "queue1 = cl.CommandQueue(context)\n",
    "\n",
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 2: creat kernels\n",
    "Creat & build program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "wksp = ''\n",
    "\n",
    "file_dir = wksp + 'maxpool_NDRange.aocx'\n",
    "\n",
    "file_dir = wksp + 'squeezenet_NDRange.aocx'\n",
    "\n",
    "kernelSource = open(file_dir, mode='rb').read()\n",
    "program_NDR = cl.Program(context, device, [kernelSource]).build()\n",
    "\n",
    "file_dir = wksp + 'squeezenet_ST.aocx'\n",
    "\n",
    "kernelSource = open(file_dir, mode='rb').read()\n",
    "program_ST = cl.Program(context, device, [kernelSource]).build()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creat kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv3x3_NDR = program_NDR.conv2d3x3\n",
    "conv3x3_NDR.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "maxpool_NDR = program_NDR.maxpool2d\n",
    "maxpool_NDR.set_scalar_arg_dtypes([np.int32, np.int32, None, None])\n",
    "\n",
    "conv1x1_NDR = program_NDR.conv2d1x1\n",
    "conv1x1_NDR.set_scalar_arg_dtypes([np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "avgpool_NDR = program_NDR.avgpool2d\n",
    "avgpool_NDR.set_scalar_arg_dtypes([None, None])\n",
    "\n",
    "conv3x3_ST = program_ST.conv2d3x3\n",
    "conv3x3_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "maxpool_ST = program_ST.maxpool2d\n",
    "maxpool_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, None, None])\n",
    "\n",
    "conv1x1_ST = program_ST.conv2d1x1\n",
    "conv1x1_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "avgpool_ST = program_ST.avgpool2d\n",
    "avgpool_ST.set_scalar_arg_dtypes([None, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### OpenCL kernel: squeezenet_NDRange.cl\n",
    "conv2d3x3: 2-D 3x3 convolution.  \n",
    "conv2d1x1: 2-D 1x1 convolution. kerner size 1, stride 1  \n",
    "maxpool2d: 2-D max pool. kerner size 3, stride 2  \n",
    "avgpool2d: 2-D average pool. kernel size 13\n",
    "```C\n",
    "//maxPool2d \n",
    "//kernel_size=3 stride=2\n",
    "//output one feature map per kernel\n",
    "__kernel void maxpool2d(\n",
    "\tconst int input_size,\n",
    "\tconst int output_size,\n",
    "\t__global const float* restrict input_im,\n",
    "    __global float* restrict output_im)\n",
    "{\n",
    "\tint channels = get_global_id(0);//get output channel index\n",
    "\t\n",
    "\tinput_im += channels * input_size * input_size;\n",
    "\toutput_im += channels * output_size * output_size;\n",
    "\n",
    "\t//loop over output feature map\n",
    "\tfor(int i = 0; i < output_size; i++)//row\n",
    "\t{\n",
    "\t\tfor(int j = 0; j < output_size; j++)//col\n",
    "\t\t{\n",
    "\t\t\t//find the max value in 3x3 reigon \n",
    "\t\t\t//to be one element in the output feature map\n",
    "\t\t\tfloat tmp = 0.0;\n",
    "\n",
    "\t\t\t#pragma unroll 1\n",
    "\t\t\tfor(int k = 0; k < 3; k++)//row\n",
    "\t\t\t{\n",
    "\t\t\t\t#pragma unroll 1\n",
    "\t\t\t\tfor(int l = 0; l < 3; l++)//col\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\tfloat value = input_im[(i * 2 + k) * input_size  + j * 2 + l ];\n",
    "\t\t\t\t\tif(value > tmp)\n",
    "\t\t\t\t\t\ttmp = value;\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t\t//store the result to output feature map\n",
    "\t\t\toutput_im[i * output_size + j] = tmp; \n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "//3x3 convolution layer\n",
    "//output one feature map per kernel\n",
    "__kernel void conv2d3x3(\n",
    "\tconst int input_channels, const int input_size,\n",
    "\tconst int pad, const int stride,\n",
    "\tconst int start_channel, //start_channel is for 1x1 feature map in fire layer\n",
    "\tconst int output_size,\n",
    "\t__global const float* restrict input_im,\n",
    "\t__global const float* restrict filter_weight,\n",
    "\t__global const float* restrict filter_bias,\n",
    "\t__global float *restrict output_im\n",
    "\t)\n",
    "{\n",
    "\tint filter_index = get_global_id(0); //get output channel index\n",
    "\tint i =  get_global_id(1);\n",
    "\n",
    "\tfilter_weight += filter_index * input_channels * 9;\n",
    "\tfloat bias = filter_bias[filter_index];\n",
    "\toutput_im += (start_channel + filter_index) * output_size * output_size;\n",
    "\t\n",
    "\t//loop over output feature map\n",
    "\t//for(int i = 0; i < output_size; i++)\n",
    "\t{\n",
    "\t\tfor(int j = 0; j < output_size; j++)\n",
    "\t\t{\n",
    "\t\t\t//compute one element in the output feature map\n",
    "\t\t\tfloat tmp = bias;\n",
    "\t\t\t\n",
    "\t\t\t//compute dot product of 2 input_channels x 3 x 3 matrix\n",
    "\t\t\tfor(int k = 0; k < input_channels; k++)\n",
    "\t\t\t{\n",
    "\t\t\t\t#pragma unroll\n",
    "\t\t\t\tfor(int l = 0; l < 3; l++)\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\tint h = i * stride + l - pad;\n",
    "\t\t\t\t\tfor(int m = 0; m < 3; m++)\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\tint w = j * stride + m - pad;\n",
    "\t\t\t\t\t\tif((h >= 0) && (h < input_size) && (w >= 0) && (w < input_size))\n",
    "\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\ttmp += input_im[k * input_size * input_size + h * input_size + w] \\\n",
    "                               * filter_weight[9 * k + 3 * l + m];\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\t//add relu activation after conv\n",
    "\t\t\toutput_im[i * output_size + j] = (tmp > 0.0) ? tmp : 0.0;\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "//1x1 convolution layer\n",
    "//output one feature map per kernel\n",
    "__kernel void conv2d1x1(\n",
    "\tconst int input_channels, const int input_size,\n",
    "\t__global float *input_im,\n",
    "\t__global const float4* filter_weight,\n",
    "\t__global const float* filter_bias,\n",
    "\t__global float *restrict output_im)\n",
    "{\n",
    "\tint filter_index = get_global_id(0); // 0 - (output_channels - 1)\n",
    "\tint i = get_global_id(1);\n",
    "\n",
    "\tfilter_weight += filter_index * input_channels;\n",
    "\n",
    "\tfloat bias = filter_bias[filter_index];\n",
    "\t\n",
    "\toutput_im += filter_index * input_size * input_size;//start_channel is for 1x1 feature map in fire layer\n",
    "\n",
    "\t//loop over output feature map\n",
    "\t//for(int i = 0; i < input_size; i++)\n",
    "\t{\n",
    "\t\tfor(int j = 0; j < input_size; j++)\n",
    "\t\t{\n",
    "\t\t\tfloat tmp = bias;\n",
    "\t\t\tint loc = i * input_size + j;\n",
    "\n",
    "\t\t\tfor(int k = 0; k < input_channels; k++)\n",
    "\t\t\t{\n",
    "\t\t\t\t//float8 weight = filter_weight[k];\n",
    "\t\t\t\t//float8 feature;\n",
    "\t\t\t\ttmp += input_im[((k << 2) + 0) * input_size * input_size + loc] * filter_weight[k].s0\n",
    "\t\t\t\t     + input_im[((k << 2) + 1) * input_size * input_size + loc] * filter_weight[k].s1\n",
    "\t\t\t\t\t + input_im[((k << 2) + 2) * input_size * input_size + loc] * filter_weight[k].s2\n",
    "\t\t\t\t\t + input_im[((k << 2) + 3) * input_size * input_size + loc] * filter_weight[k].s3;\n",
    "\t\t\t}\n",
    "\t\t\t//add relu after conv\n",
    "\t\t\toutput_im[i * input_size + j] = (tmp > 0.0) ? tmp : 0.0;\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "//last layer use a 13 x 13 avgPool layer as classifier\n",
    "//one class score per kernel\n",
    "__kernel void avgpool2d(\n",
    "\t__global const float* restrict input_im,\n",
    "\t__global float* restrict output_im)\n",
    "{\n",
    "\tint class_index = get_global_id(0);//get class score index\n",
    "\n",
    "\tinput_im += 169 * class_index;\n",
    "\t\n",
    "\tfloat tmp = 0.0f;\n",
    "\n",
    "\tfor(int i = 0; i < 169; i++)\n",
    "\t{\n",
    "\t\ttmp += input_im[i];\n",
    "\t}\n",
    "\n",
    "\toutput_im[class_index] = tmp / 169.0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### OpenCL kernel: squeezenet_ST.cl\n",
    "conv2d3x3: 2-D 3x3 convolution.  \n",
    "conv2d1x1: 2-D 1x1 convolution. kerner size 1, stride 1  \n",
    "maxpool2d: 2-D max pool. kerner size 3, stride 2  \n",
    "avgpool2d: 2-D average pool. kernel size 13\n",
    "```C\n",
    "//maxPool2d \n",
    "//kernel_size=3 stride=2\n",
    "//output one feature map per kernel\n",
    "__kernel void maxpool2d(\n",
    "\tconst int input_size,\n",
    "\tconst int output_size,\n",
    "    const int channel_size,\n",
    "\t__global const float* restrict input_im,\n",
    "    __global float* restrict output_im)\n",
    "{\n",
    "\n",
    "    for(int channel_index = 0; channel_index < channel_size; channel_index++)\n",
    "    {\n",
    "        //loop over output feature map\n",
    "        for(int i = 0; i < output_size; i++)//row\n",
    "        {\n",
    "            for(int j = 0; j < output_size; j++)//col\n",
    "            {\n",
    "                //find the max value in 3x3 reigon \n",
    "                //to be one element in the output feature map\n",
    "                float tmp = 0.0;\n",
    "\n",
    "                #pragma unroll 1\n",
    "                for(int k = 0; k < 3; k++)//row\n",
    "                {\n",
    "                    #pragma unroll 1\n",
    "                    for(int l = 0; l < 3; l++)//col\n",
    "                    {\n",
    "                        float value = input_im[(i * 2 + k) * input_size  + j * 2 + l ];\n",
    "                        if(value > tmp)\n",
    "                            tmp = value;\n",
    "                    }\n",
    "                }\n",
    "                //store the result to output feature map\n",
    "                output_im[i * output_size + j] = tmp;\n",
    "            }\n",
    "        }\n",
    "    \n",
    "        input_im += input_size * input_size;\n",
    "        output_im += output_size * output_size;\n",
    "    }\n",
    "}\n",
    "\n",
    "//3x3 convolution layer\n",
    "//output one feature map per kernel\n",
    "__kernel void conv2d3x3(\n",
    "\tconst int input_channels, const int input_size,\n",
    "\tconst int pad, const int stride,\n",
    "\tconst int start_channel, //start_channel is for 1x1 feature map in fire layer\n",
    "\tconst int output_size,\n",
    "    const int filter_size,\n",
    "\t__global const float* restrict input_im,\n",
    "\t__global const float* restrict filter_weight,\n",
    "\t__global const float* restrict filter_bias,\n",
    "\t__global float *restrict output_im\n",
    "\t)\n",
    "{\n",
    "\t\n",
    "\t//filter_weight += filter_index * input_channels * 9;\n",
    "\toutput_im += start_channel * output_size * output_size;\n",
    "\t\n",
    "\t//loop over output feature map\n",
    "\tfor(int filter_index = 0; filter_index < filter_size; filter_index++)\n",
    "\t{\n",
    "        float bias = filter_bias[filter_index];\n",
    "\n",
    "\t\tfor(int i = 0; i < output_size; i++)\n",
    "\t\t{\n",
    "            for(int j = 0; j < output_size; j++)\n",
    "            {\n",
    "                //compute one element in the output feature map\n",
    "                float tmp = bias;\n",
    "\n",
    "                //compute dot product of 2 input_channels x 3 x 3 matrix\n",
    "                for(int k = 0; k < input_channels; k++)\n",
    "                {\n",
    "                    #pragma unroll\n",
    "                    for(int l = 0; l < 3; l++)\n",
    "                    {\n",
    "                        int h = i * stride + l - pad;\n",
    "                        for(int m = 0; m < 3; m++)\n",
    "                        {\n",
    "                            int w = j * stride + m - pad;\n",
    "                            if((h >= 0) && (h < input_size) && (w >= 0) && (w < input_size))\n",
    "                            {\n",
    "                                tmp += input_im[k * input_size * input_size + h * input_size + w] \\\n",
    "                                   * filter_weight[9 * k + 3 * l + m];\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                //add relu activation after conv\n",
    "                output_im[i * output_size + j] = (tmp > 0.0) ? tmp : 0.0;                 \n",
    "            }\n",
    "\t\t}\n",
    "        \n",
    "        filter_weight += input_channels * 9;\n",
    "        output_im += output_size * output_size;\n",
    "\t}\n",
    "}\n",
    "\n",
    "//1x1 convolution layer as a single kernel (V5)\n",
    "//output one feature map per kernel\n",
    "\n",
    "__kernel void conv2d1x1(\n",
    "\tconst int input_channels, \n",
    "    const int input_size,\n",
    "    const int filter_size,\n",
    "\t__global const float* restrict input_im,\n",
    "\t__global const float* restrict filter_weight,\n",
    "\t__global const float* restrict filter_bias,\n",
    "\t__global float *restrict output_im)\n",
    "{\n",
    "\t// Adding restrict keyword\n",
    "    //loop over filters\n",
    "\tfor(int f_i = 0; f_i < filter_size; f_i++)\n",
    "\t{\n",
    "        //filter_weight += f_i * input_channels;\n",
    "\n",
    "        float bias = filter_bias[f_i];\n",
    "\t\t\n",
    "        // output_im += input_size * input_size;//start_channel is for 1x1 feature map in fire layer\n",
    "\t\n",
    "\t\tfor(int ij = 0; ij < (input_size * input_size); ij++)\n",
    "\t\t{\n",
    "\t\t\tfloat tmp = bias;\n",
    "\t\t\t// int loc = i * input_size + j; // this is equal to ij\n",
    "\n",
    "\t\t\tfor(int k = 0; k < input_channels; k++)\n",
    "\t\t\t{\n",
    "\t\t\t\t//float8 weight = filter_weight[k];\n",
    "\t\t\t\t//float8 feature;\n",
    "\t\t\t\ttmp += input_im[k * input_size * input_size + ij] * filter_weight[k + f_i * input_channels];\n",
    "\t\t\t}\n",
    "\t\t\t//add relu after conv\n",
    "\t\t\toutput_im[ij + (input_size * input_size * f_i)] = (tmp > 0.0) ? tmp : 0.0;\n",
    "            //output_im[ij] = (tmp > 0.0) ? tmp : 0.0;\n",
    "\t\t}\n",
    "        //filter_weight += input_channels;\t\n",
    "        //output_im += input_size * input_size;//start_channel is for 1x1 feature map in fire layer\n",
    "\t\n",
    "\t}\n",
    "}\n",
    "\n",
    "//last layer use a 13 x 13 avgPool layer as classifier\n",
    "//one class score per kernel\n",
    "__kernel void avgpool2d(\n",
    "\t__global const float* restrict input_im,\n",
    "\t__global float* restrict output_im)\n",
    "{\n",
    "\t// int class_index = get_global_id(0);//get class score index\n",
    "    \n",
    "    //Since it's the final layer, we know that there are only 1000 classes\n",
    "    \n",
    "\t//input_im += 169 * class_index;\n",
    "\n",
    "\tfor(int class_index = 0; class_index < 1000; class_index++)\n",
    "    {\n",
    "            \n",
    "        float tmp = 0.0f;\n",
    "\n",
    "        for(int i = 0; i < 169; i++)\n",
    "        {\n",
    "            tmp += input_im[class_index * 169 + i];\n",
    "        }\n",
    "\n",
    "        output_im[class_index] = tmp / 169.0;\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run OpenCL implement  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## BLOCK 3 ########\n",
    "tamanyo=14 #input_size\n",
    "canales_iniciales=256 #input channels and \n",
    "squeeze_factor_a = 48\n",
    "squeeze_factor_b = 64\n",
    "expand_factor_a = 192\n",
    "expand_factor_b = 256\n",
    "\n",
    "################\n",
    "\n",
    "tamanyo_final = tamanyo # En el último bloque no hay maxpool layer\n",
    "\n",
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "acumulado_pytorch = 0\n",
    "\n",
    "imagen = np.random.randint(1,size=(1,canales_iniciales, tamanyo, tamanyo))\n",
    "\n",
    "#### FIRE 6 ####\n",
    "weights1=np.random.randint(1,size=(squeeze_factor_a, canales_iniciales,1,1)).astype(np.float32)\n",
    "bias1=np.random.randint(1,size=(squeeze_factor_a,)).astype(np.float32)\n",
    "\n",
    "weights2a=np.random.randint(1,size=(expand_factor_a, squeeze_factor_a,1,1)).astype(np.float32)  \n",
    "bias2a=np.random.randint(1,size=(expand_factor_a,)).astype(np.float32)    \n",
    "\n",
    "weights2b=np.random.randint(1,size=(expand_factor_a, squeeze_factor_a,3,3)).astype(np.float32)    \n",
    "bias2b=np.random.randint(1,size=(expand_factor_a,)).astype(np.float32)\n",
    "\n",
    "#### FIRE 7 ####\n",
    "weights3=np.random.randint(1,size=(squeeze_factor_a, expand_factor_a * 2,1,1)).astype(np.float32)\n",
    "bias3=np.random.randint(1,size=(squeeze_factor_a,)).astype(np.float32)\n",
    "\n",
    "weights4a=np.random.randint(1,size=(expand_factor_a, squeeze_factor_a,1,1)).astype(np.float32)  \n",
    "bias4a=np.random.randint(1,size=(expand_factor_a,)).astype(np.float32)    \n",
    "\n",
    "weights4b=np.random.randint(1,size=(expand_factor_a, squeeze_factor_a,3,3)).astype(np.float32)    \n",
    "bias4b=np.random.randint(1,size=(expand_factor_a,)).astype(np.float32)\n",
    "\n",
    "#### FIRE 8 ####\n",
    "weights5=np.random.randint(1,size=(squeeze_factor_b, expand_factor_a * 2,1,1)).astype(np.float32)\n",
    "bias5=np.random.randint(1,size=(squeeze_factor_b,)).astype(np.float32)\n",
    "\n",
    "weights6a=np.random.randint(1,size=(expand_factor_b, squeeze_factor_b,1,1)).astype(np.float32)  \n",
    "bias6a=np.random.randint(1,size=(expand_factor_b,)).astype(np.float32)    \n",
    "\n",
    "weights6b=np.random.randint(1,size=(expand_factor_b, squeeze_factor_b,3,3)).astype(np.float32)    \n",
    "bias6b=np.random.randint(1,size=(expand_factor_b,)).astype(np.float32)\n",
    "\n",
    "#### FIRE 9 ####\n",
    "weights7=np.random.randint(1,size=(squeeze_factor_b, expand_factor_b*2,1,1)).astype(np.float32)\n",
    "bias7=np.random.randint(1,size=(squeeze_factor_b,)).astype(np.float32)\n",
    "\n",
    "weights8a=np.random.randint(1,size=(expand_factor_b, squeeze_factor_b,1,1)).astype(np.float32)  \n",
    "bias8a=np.random.randint(1,size=(expand_factor_b,)).astype(np.float32)    \n",
    "\n",
    "weights8b=np.random.randint(1,size=(expand_factor_b, squeeze_factor_b,3,3)).astype(np.float32)    \n",
    "bias8b=np.random.randint(1,size=(expand_factor_b,)).astype(np.float32)\n",
    "\n",
    "#####################################################\n",
    "imagen = np.ones((1,canales_iniciales, tamanyo, tamanyo))\n",
    "\n",
    "#### FIRE 6 ####\n",
    "weights1=np.ones((squeeze_factor_a, canales_iniciales,1,1)).astype(np.float32)\n",
    "bias1=np.ones((squeeze_factor_a,)).astype(np.float32)\n",
    "\n",
    "weights2a=np.ones((expand_factor_a, squeeze_factor_a,1,1)).astype(np.float32)  \n",
    "bias2a=np.ones((expand_factor_a,)).astype(np.float32)    \n",
    "\n",
    "weights2b=np.ones((expand_factor_a, squeeze_factor_a,3,3)).astype(np.float32)    \n",
    "bias2b=np.ones((expand_factor_a,)).astype(np.float32)\n",
    "\n",
    "#### FIRE 7 ####\n",
    "weights3=np.ones((squeeze_factor_a, expand_factor_a * 2,1,1)).astype(np.float32)\n",
    "bias3=np.ones((squeeze_factor_a,)).astype(np.float32)\n",
    "\n",
    "weights4a=np.ones((expand_factor_a, squeeze_factor_a,1,1)).astype(np.float32)  \n",
    "bias4a=np.ones((expand_factor_a,)).astype(np.float32)    \n",
    "\n",
    "weights4b=np.ones((expand_factor_a, squeeze_factor_a,3,3)).astype(np.float32)    \n",
    "bias4b=np.ones((expand_factor_a,)).astype(np.float32)\n",
    "\n",
    "#### FIRE 8 ####\n",
    "weights5=np.ones((squeeze_factor_b, expand_factor_a * 2,1,1)).astype(np.float32)\n",
    "bias5=np.ones((squeeze_factor_b,)).astype(np.float32)\n",
    "\n",
    "weights6a=np.ones((expand_factor_b, squeeze_factor_b,1,1)).astype(np.float32)  \n",
    "bias6a=np.ones((expand_factor_b,)).astype(np.float32)    \n",
    "\n",
    "weights6b=np.ones((expand_factor_b, squeeze_factor_b,3,3)).astype(np.float32)    \n",
    "bias6b=np.ones((expand_factor_b,)).astype(np.float32)\n",
    "\n",
    "#### FIRE 9 ####\n",
    "weights7=np.ones((squeeze_factor_b, expand_factor_b*2,1,1)).astype(np.float32)\n",
    "bias7=np.ones((squeeze_factor_b,)).astype(np.float32)\n",
    "\n",
    "weights8a=np.ones((expand_factor_b, squeeze_factor_b,1,1)).astype(np.float32)  \n",
    "bias8a=np.ones((expand_factor_b,)).astype(np.float32)    \n",
    "\n",
    "weights8b=np.ones((expand_factor_b, squeeze_factor_b,3,3)).astype(np.float32)    \n",
    "bias8b=np.ones((expand_factor_b,)).astype(np.float32)\n",
    "\n",
    "#####################################################\n",
    "imagen = np.random.randint(239,size=(1,canales_iniciales, tamanyo, tamanyo))\n",
    "params = torch.load('squeezenet1_1.pth')\n",
    "\n",
    "######## BLOCK 3 ########\n",
    "#fire - fire - fire - fire block 3\n",
    "#### FIRE 6 ####\n",
    "weights1 = params['features.9.squeeze.weight'].numpy()\n",
    "bias1 = params['features.9.squeeze.bias'].numpy()\n",
    "\n",
    "weights2a = params['features.9.expand1x1.weight'].numpy()\n",
    "bias2a = params['features.9.expand1x1.bias'].numpy()\n",
    "\n",
    "weights2b = params['features.9.expand3x3.weight'].numpy()\n",
    "bias2b = params['features.9.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 7 ####\n",
    "weights3 = params['features.10.squeeze.weight'].numpy()\n",
    "bias3 = params['features.10.squeeze.bias'].numpy()\n",
    "\n",
    "weights4a = params['features.10.expand1x1.weight'].numpy()\n",
    "bias4a = params['features.10.expand1x1.bias'].numpy()\n",
    "\n",
    "weights4b = params['features.10.expand3x3.weight'].numpy()\n",
    "bias4b = params['features.10.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 8 ####\n",
    "weights5 = params['features.11.squeeze.weight'].numpy()\n",
    "bias5 = params['features.11.squeeze.bias'].numpy()\n",
    "\n",
    "weights6a = params['features.11.expand1x1.weight'].numpy()\n",
    "bias6a = params['features.11.expand1x1.bias'].numpy()\n",
    "\n",
    "weights6b = params['features.11.expand3x3.weight'].numpy()\n",
    "bias6b = params['features.11.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 9 ####\n",
    "weights7 = params['features.12.squeeze.weight'].numpy()\n",
    "bias7 = params['features.12.squeeze.bias'].numpy()\n",
    "\n",
    "weights8a = params['features.12.expand1x1.weight'].numpy()\n",
    "bias8a = params['features.12.expand1x1.bias'].numpy()\n",
    "\n",
    "weights8b = params['features.12.expand3x3.weight'].numpy()\n",
    "bias8b = params['features.12.expand3x3.bias'].numpy()\n",
    "\n",
    "tic=pc()\n",
    "\n",
    "squeeze1=nn.Conv2d(canales_iniciales, squeeze_factor_a, kernel_size=1, bias=False)\n",
    "squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))    \n",
    "\n",
    "squeeze2a=nn.Conv2d(squeeze_factor_a, expand_factor_a, kernel_size=1, bias=False)\n",
    "squeeze2a.weight = nn.Parameter(torch.from_numpy(weights2a))\n",
    "squeeze2a.bias = nn.Parameter(torch.from_numpy(bias2a))\n",
    "\n",
    "squeeze2b=nn.Conv2d(squeeze_factor_a, expand_factor_a, kernel_size=3, bias=False, padding=1)\n",
    "squeeze2b.weight = nn.Parameter(torch.from_numpy(weights2b))\n",
    "squeeze2b.bias = nn.Parameter(torch.from_numpy(bias2b))\n",
    "\n",
    "squeeze3=nn.Conv2d(expand_factor_a * 2, squeeze_factor_a, kernel_size=1, bias=False)\n",
    "squeeze3.weight = nn.Parameter(torch.from_numpy(weights3))\n",
    "squeeze3.bias = nn.Parameter(torch.from_numpy(bias3))    \n",
    "\n",
    "squeeze4a=nn.Conv2d(squeeze_factor_a, expand_factor_a, kernel_size=1, bias=False)\n",
    "squeeze4a.weight = nn.Parameter(torch.from_numpy(weights4a))\n",
    "squeeze4a.bias = nn.Parameter(torch.from_numpy(bias4a))\n",
    "\n",
    "squeeze4b=nn.Conv2d(squeeze_factor_a, expand_factor_a, kernel_size=3, bias=False, padding=1)\n",
    "squeeze4b.weight = nn.Parameter(torch.from_numpy(weights4b))\n",
    "squeeze4b.bias = nn.Parameter(torch.from_numpy(bias4b))\n",
    "\n",
    "squeeze5=nn.Conv2d(expand_factor_a * 2, squeeze_factor_b, kernel_size=1, bias=False)\n",
    "squeeze5.weight = nn.Parameter(torch.from_numpy(weights5))\n",
    "squeeze5.bias = nn.Parameter(torch.from_numpy(bias5))    \n",
    "\n",
    "squeeze6a=nn.Conv2d(squeeze_factor_b, expand_factor_b, kernel_size=1, bias=False)\n",
    "squeeze6a.weight = nn.Parameter(torch.from_numpy(weights6a))\n",
    "squeeze6a.bias = nn.Parameter(torch.from_numpy(bias6a))\n",
    "\n",
    "squeeze6b=nn.Conv2d(squeeze_factor_b, expand_factor_b, kernel_size=3, bias=False, padding=1)\n",
    "squeeze6b.weight = nn.Parameter(torch.from_numpy(weights6b))\n",
    "squeeze6b.bias = nn.Parameter(torch.from_numpy(bias6b))\n",
    "\n",
    "squeeze7=nn.Conv2d(expand_factor_b * 2, squeeze_factor_b, kernel_size=1, bias=False)\n",
    "squeeze7.weight = nn.Parameter(torch.from_numpy(weights7))\n",
    "squeeze7.bias = nn.Parameter(torch.from_numpy(bias7))    \n",
    "\n",
    "squeeze8a=nn.Conv2d(squeeze_factor_b, expand_factor_b, kernel_size=1, bias=False)\n",
    "squeeze8a.weight = nn.Parameter(torch.from_numpy(weights8a))\n",
    "squeeze8a.bias = nn.Parameter(torch.from_numpy(bias8a))\n",
    "\n",
    "squeeze8b=nn.Conv2d(squeeze_factor_b, expand_factor_b, kernel_size=3, bias=False, padding=1)\n",
    "squeeze8b.weight = nn.Parameter(torch.from_numpy(weights8b))\n",
    "squeeze8b.bias = nn.Parameter(torch.from_numpy(bias8b))\n",
    "\n",
    "imagen1  = torch.from_numpy(imagen).float()\n",
    "\n",
    "salida1=squeeze1(imagen1)\n",
    "salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "salida2a=squeeze2a(salida1_activation)\n",
    "salida2a_activation=squeeze_activation(salida2a)\n",
    "salida2b=squeeze2b(salida1_activation)\n",
    "salida2b_activation=squeeze_activation(salida2b)    \n",
    "salida2_total=torch.cat([salida2a_activation,salida2b_activation], 1)\n",
    "\n",
    "salida3=squeeze3(salida2_total)\n",
    "salida3_activation=squeeze_activation(salida3)\n",
    "\n",
    "salida4a=squeeze4a(salida3_activation)\n",
    "salida4a_activation=squeeze_activation(salida4a)\n",
    "salida4b=squeeze4b(salida3_activation)\n",
    "salida4b_activation=squeeze_activation(salida4b)    \n",
    "salida4_total=torch.cat([salida4a_activation,salida4b_activation], 1)\n",
    "\n",
    "salida5=squeeze5(salida4_total)\n",
    "salida5_activation=squeeze_activation(salida5)\n",
    "\n",
    "salida6a=squeeze6a(salida5_activation)\n",
    "salida6a_activation=squeeze_activation(salida6a)\n",
    "salida6b=squeeze6b(salida5_activation)\n",
    "salida6b_activation=squeeze_activation(salida6b)    \n",
    "salida6_total=torch.cat([salida6a_activation,salida6b_activation], 1)\n",
    "\n",
    "salida7=squeeze7(salida6_total)\n",
    "salida7_activation=squeeze_activation(salida7)\n",
    "\n",
    "salida8a=squeeze8a(salida7_activation)\n",
    "salida8a_activation=squeeze_activation(salida8a)\n",
    "salida8b=squeeze8b(salida7_activation)\n",
    "salida8b_activation=squeeze_activation(salida8b)    \n",
    "salida8_total=torch.cat([salida8a_activation,salida8b_activation], 1)\n",
    "\n",
    "salida8_total_a_numpy=salida8_total.detach().numpy()\n",
    "\n",
    "toc=pc()\n",
    "\n",
    "acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "\n",
    "####### OPENCL COMPARISON #######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NDRANGE\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire6_squeeze_weight = weights1.reshape(-1)\n",
    "fire6_squeeze_bias = bias1\n",
    "fire6_expand1x1_weight = weights2a.reshape(-1)\n",
    "fire6_expand1x1_bias = bias2a\n",
    "fire6_expand3x3_weight =weights2b.reshape(-1)\n",
    "fire6_expand3x3_bias = bias2b\n",
    "\n",
    "fire7_squeeze_weight = weights3.reshape(-1)\n",
    "fire7_squeeze_bias = bias3\n",
    "fire7_expand1x1_weight = weights4a.reshape(-1)\n",
    "fire7_expand1x1_bias = bias4a\n",
    "fire7_expand3x3_weight =weights4b.reshape(-1)\n",
    "fire7_expand3x3_bias = bias4b\n",
    "\n",
    "fire8_squeeze_weight = weights5.reshape(-1)\n",
    "fire8_squeeze_bias = bias5\n",
    "fire8_expand1x1_weight = weights6a.reshape(-1)\n",
    "fire8_expand1x1_bias = bias6a\n",
    "fire8_expand3x3_weight =weights6b.reshape(-1)\n",
    "fire8_expand3x3_bias = bias6b\n",
    "\n",
    "fire9_squeeze_weight = weights7.reshape(-1)\n",
    "fire9_squeeze_bias = bias7\n",
    "fire9_expand1x1_weight = weights8a.reshape(-1)\n",
    "fire9_expand1x1_bias = bias8a\n",
    "fire9_expand3x3_weight =weights8b.reshape(-1)\n",
    "fire9_expand3x3_bias = bias8b\n",
    "\n",
    "h_result_fire6_squeeze = np.empty(1 * squeeze_factor_a * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire6_expand = np.empty(1 * expand_factor_a * 2 * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "h_result_fire7_squeeze = np.empty(1 * squeeze_factor_a * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire7_expand = np.empty(1 * expand_factor_a * 2 * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "h_result_fire8_squeeze = np.empty(1 * squeeze_factor_b * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire8_expand = np.empty(1 * expand_factor_b * 2 * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "h_result_fire9_squeeze = np.empty(1 * squeeze_factor_b * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire9_expand = np.empty(1 * expand_factor_b * 2 * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "d_fire6_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_squeeze_weight)\n",
    "d_fire6_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_squeeze_bias)\n",
    "d_fire6_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand1x1_weight)\n",
    "d_fire6_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand1x1_bias)\n",
    "d_fire6_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand3x3_weight)\n",
    "d_fire6_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand3x3_bias)\n",
    "\n",
    "d_fire7_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_squeeze_weight)\n",
    "d_fire7_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_squeeze_bias)\n",
    "d_fire7_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand1x1_weight)\n",
    "d_fire7_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand1x1_bias)\n",
    "d_fire7_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand3x3_weight)\n",
    "d_fire7_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand3x3_bias)\n",
    "\n",
    "d_fire8_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_squeeze_weight)\n",
    "d_fire8_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_squeeze_bias)\n",
    "d_fire8_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand1x1_weight)\n",
    "d_fire8_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand1x1_bias)\n",
    "d_fire8_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand3x3_weight)\n",
    "d_fire8_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand3x3_bias)\n",
    "\n",
    "d_fire9_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_squeeze_weight)\n",
    "d_fire9_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_squeeze_bias)\n",
    "d_fire9_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_expand1x1_weight)\n",
    "d_fire9_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_expand1x1_bias)\n",
    "d_fire9_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_expand3x3_weight)\n",
    "d_fire9_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_expand3x3_bias)\n",
    "\n",
    "d_result_fire6_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire6_squeeze.nbytes)\n",
    "d_result_fire6_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire6_expand.nbytes)\n",
    "\n",
    "d_result_fire7_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire7_squeeze.nbytes)\n",
    "d_result_fire7_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire7_expand.nbytes)\n",
    "\n",
    "d_result_fire8_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire8_squeeze.nbytes)\n",
    "d_result_fire8_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire8_expand.nbytes)\n",
    "\n",
    "d_result_fire9_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire9_squeeze.nbytes)\n",
    "d_result_fire9_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire9_expand.nbytes)\n",
    "\n",
    "tic2 = pc()\n",
    "\n",
    "conv1x1_NDR(queue,(squeeze_factor_a, tamanyo), None, np.int32(canales_iniciales/4), tamanyo, d_sample, d_fire6_squeeze_weight, d_fire6_squeeze_bias, d_result_fire6_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_NDR(queue1,(expand_factor_a, tamanyo), None, np.int32(squeeze_factor_a/4), tamanyo, d_result_fire6_squeeze, d_fire6_expand1x1_weight, d_fire6_expand1x1_bias, d_result_fire6_expand)\n",
    "conv3x3_NDR(queue,(expand_factor_a, tamanyo), None, squeeze_factor_a, tamanyo, 1, 1, expand_factor_a, tamanyo, d_result_fire6_squeeze, d_fire6_expand3x3_weight, d_fire6_expand3x3_bias, d_result_fire6_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "conv1x1_NDR(queue,(squeeze_factor_a, tamanyo), None, np.int32(expand_factor_a*2/4), tamanyo, d_result_fire6_expand, d_fire7_squeeze_weight, d_fire7_squeeze_bias, d_result_fire7_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_NDR(queue1,(expand_factor_a, tamanyo), None, np.int32(squeeze_factor_a/4), tamanyo, d_result_fire7_squeeze, d_fire7_expand1x1_weight, d_fire7_expand1x1_bias, d_result_fire7_expand)\n",
    "conv3x3_NDR(queue,(expand_factor_a, tamanyo), None, squeeze_factor_a, tamanyo, 1, 1, expand_factor_a, tamanyo, d_result_fire7_squeeze, d_fire7_expand3x3_weight, d_fire7_expand3x3_bias, d_result_fire7_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "conv1x1_NDR(queue,(squeeze_factor_b, tamanyo), None, np.int32(expand_factor_a*2/4), tamanyo, d_result_fire7_expand, d_fire8_squeeze_weight, d_fire8_squeeze_bias, d_result_fire8_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_NDR(queue1,(expand_factor_b, tamanyo), None, np.int32(squeeze_factor_b/4), tamanyo, d_result_fire8_squeeze, d_fire8_expand1x1_weight, d_fire8_expand1x1_bias, d_result_fire8_expand)\n",
    "conv3x3_NDR(queue,(expand_factor_b, tamanyo), None, squeeze_factor_b, tamanyo, 1, 1, expand_factor_b, tamanyo, d_result_fire8_squeeze, d_fire8_expand3x3_weight, d_fire8_expand3x3_bias, d_result_fire8_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "conv1x1_NDR(queue,(squeeze_factor_b, tamanyo), None, np.int32(expand_factor_b*2/4), tamanyo, d_result_fire8_expand, d_fire9_squeeze_weight, d_fire9_squeeze_bias, d_result_fire9_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_NDR(queue1,(expand_factor_b, tamanyo), None, np.int32(squeeze_factor_b/4), tamanyo, d_result_fire9_squeeze, d_fire9_expand1x1_weight, d_fire9_expand1x1_bias, d_result_fire9_expand)\n",
    "conv3x3_NDR(queue,(expand_factor_b, tamanyo), None, squeeze_factor_b, tamanyo, 1, 1, expand_factor_b, tamanyo, d_result_fire9_squeeze, d_fire9_expand3x3_weight, d_fire9_expand3x3_bias, d_result_fire9_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire9_expand, d_result_fire9_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos = h_result_fire9_expand.reshape(-1,tamanyo,tamanyo)\n",
    "\n",
    "rtime = pc() - tic2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple task\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire6_squeeze_weight = weights1.reshape(-1)\n",
    "fire6_squeeze_bias = bias1\n",
    "fire6_expand1x1_weight = weights2a.reshape(-1)\n",
    "fire6_expand1x1_bias = bias2a\n",
    "fire6_expand3x3_weight =weights2b.reshape(-1)\n",
    "fire6_expand3x3_bias = bias2b\n",
    "\n",
    "fire7_squeeze_weight = weights3.reshape(-1)\n",
    "fire7_squeeze_bias = bias3\n",
    "fire7_expand1x1_weight = weights4a.reshape(-1)\n",
    "fire7_expand1x1_bias = bias4a\n",
    "fire7_expand3x3_weight =weights4b.reshape(-1)\n",
    "fire7_expand3x3_bias = bias4b\n",
    "\n",
    "fire8_squeeze_weight = weights5.reshape(-1)\n",
    "fire8_squeeze_bias = bias5\n",
    "fire8_expand1x1_weight = weights6a.reshape(-1)\n",
    "fire8_expand1x1_bias = bias6a\n",
    "fire8_expand3x3_weight =weights6b.reshape(-1)\n",
    "fire8_expand3x3_bias = bias6b\n",
    "\n",
    "fire9_squeeze_weight = weights7.reshape(-1)\n",
    "fire9_squeeze_bias = bias7\n",
    "fire9_expand1x1_weight = weights8a.reshape(-1)\n",
    "fire9_expand1x1_bias = bias8a\n",
    "fire9_expand3x3_weight =weights8b.reshape(-1)\n",
    "fire9_expand3x3_bias = bias8b\n",
    "\n",
    "h_result_fire6_squeeze = np.empty(1 * squeeze_factor_a * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire6_expand = np.empty(1 * expand_factor_a * 2 * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "h_result_fire7_squeeze = np.empty(1 * squeeze_factor_a * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire7_expand = np.empty(1 * expand_factor_a * 2 * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "h_result_fire8_squeeze = np.empty(1 * squeeze_factor_b * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire8_expand = np.empty(1 * expand_factor_b * 2 * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "h_result_fire9_squeeze = np.empty(1 * squeeze_factor_b * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire9_expand = np.empty(1 * expand_factor_b * 2 * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "d_fire6_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_squeeze_weight)\n",
    "d_fire6_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_squeeze_bias)\n",
    "d_fire6_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand1x1_weight)\n",
    "d_fire6_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand1x1_bias)\n",
    "d_fire6_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand3x3_weight)\n",
    "d_fire6_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand3x3_bias)\n",
    "\n",
    "d_fire7_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_squeeze_weight)\n",
    "d_fire7_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_squeeze_bias)\n",
    "d_fire7_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand1x1_weight)\n",
    "d_fire7_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand1x1_bias)\n",
    "d_fire7_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand3x3_weight)\n",
    "d_fire7_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand3x3_bias)\n",
    "\n",
    "d_fire8_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_squeeze_weight)\n",
    "d_fire8_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_squeeze_bias)\n",
    "d_fire8_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand1x1_weight)\n",
    "d_fire8_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand1x1_bias)\n",
    "d_fire8_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand3x3_weight)\n",
    "d_fire8_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand3x3_bias)\n",
    "\n",
    "d_fire9_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_squeeze_weight)\n",
    "d_fire9_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_squeeze_bias)\n",
    "d_fire9_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_expand1x1_weight)\n",
    "d_fire9_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_expand1x1_bias)\n",
    "d_fire9_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_expand3x3_weight)\n",
    "d_fire9_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_expand3x3_bias)\n",
    "\n",
    "d_result_fire6_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire6_squeeze.nbytes)\n",
    "d_result_fire6_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire6_expand.nbytes)\n",
    "\n",
    "d_result_fire7_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire7_squeeze.nbytes)\n",
    "d_result_fire7_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire7_expand.nbytes)\n",
    "\n",
    "d_result_fire8_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire8_squeeze.nbytes)\n",
    "d_result_fire8_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire8_expand.nbytes)\n",
    "\n",
    "d_result_fire9_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire9_squeeze.nbytes)\n",
    "d_result_fire9_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire9_expand.nbytes)\n",
    "\n",
    "tic3 = pc()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, canales_iniciales, tamanyo, squeeze_factor_a, d_sample, d_fire6_squeeze_weight, d_fire6_squeeze_bias, d_result_fire6_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_ST(queue1,(1,), None, squeeze_factor_a, tamanyo, expand_factor_a, d_result_fire6_squeeze, d_fire6_expand1x1_weight, d_fire6_expand1x1_bias, d_result_fire6_expand)\n",
    "conv3x3_ST(queue,(1,), None, squeeze_factor_a, tamanyo, 1, 1, expand_factor_a, tamanyo, expand_factor_a, d_result_fire6_squeeze, d_fire6_expand3x3_weight, d_fire6_expand3x3_bias, d_result_fire6_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, np.int32(expand_factor_a * 2), tamanyo, squeeze_factor_a, d_result_fire6_expand, d_fire7_squeeze_weight, d_fire7_squeeze_bias, d_result_fire7_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_ST(queue1,(1,), None, squeeze_factor_a, tamanyo, expand_factor_a, d_result_fire7_squeeze, d_fire7_expand1x1_weight, d_fire7_expand1x1_bias, d_result_fire7_expand)\n",
    "conv3x3_ST(queue,(1,), None, squeeze_factor_a, tamanyo, 1, 1, expand_factor_a, tamanyo, expand_factor_a, d_result_fire7_squeeze, d_fire7_expand3x3_weight, d_fire7_expand3x3_bias, d_result_fire7_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, np.int32(expand_factor_a * 2), tamanyo, squeeze_factor_b, d_result_fire7_expand, d_fire8_squeeze_weight, d_fire8_squeeze_bias, d_result_fire8_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_ST(queue1,(1,), None, squeeze_factor_b, tamanyo, expand_factor_b, d_result_fire8_squeeze, d_fire8_expand1x1_weight, d_fire8_expand1x1_bias, d_result_fire8_expand)\n",
    "conv3x3_ST(queue,(1,), None, squeeze_factor_b, tamanyo, 1, 1, expand_factor_b, tamanyo, expand_factor_b, d_result_fire8_squeeze, d_fire8_expand3x3_weight, d_fire8_expand3x3_bias, d_result_fire8_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, np.int32(expand_factor_b * 2), tamanyo, squeeze_factor_b, d_result_fire8_expand, d_fire9_squeeze_weight, d_fire9_squeeze_bias, d_result_fire9_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_ST(queue1,(1,), None, squeeze_factor_b, tamanyo, expand_factor_b, d_result_fire9_squeeze, d_fire9_expand1x1_weight, d_fire9_expand1x1_bias, d_result_fire9_expand)\n",
    "conv3x3_ST(queue,(1,), None, squeeze_factor_b, tamanyo, 1, 1, expand_factor_b, tamanyo, expand_factor_b, d_result_fire9_squeeze, d_fire9_expand3x3_weight, d_fire9_expand3x3_bias, d_result_fire9_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire9_expand, d_result_fire9_expand)\n",
    "\n",
    "veamos1 = h_result_fire9_expand.reshape(-1,tamanyo,tamanyo)\n",
    "\n",
    "rtime1 = pc() - tic3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo en segundos con pytorch=  0.0030234180003390065\n",
      "tiempo en segundos con opencl (NDRANGE)= 0.03991814599976351\n",
      "tiempo en segundos con opencl (Simple Task)= 0.04235464699922886\n",
      "comparativa (pytorch == NDRange):  True\n",
      "comparativa (pytorch == Simple Task):  True\n",
      "comparativa (NDRange == Simple Task):  True\n"
     ]
    }
   ],
   "source": [
    "print (\"tiempo en segundos con pytorch= \", toc-tic)\n",
    "print (\"tiempo en segundos con opencl (NDRANGE)=\",rtime)\n",
    "print (\"tiempo en segundos con opencl (Simple Task)=\",rtime1)\n",
    "\n",
    "comparativa1=np.allclose(salida8_total_a_numpy.reshape(-1,tamanyo,tamanyo), veamos,rtol=1e-01, atol=1e-01)\n",
    "comparativa2=np.allclose(salida8_total_a_numpy.reshape(-1,tamanyo,tamanyo), veamos1,rtol=1e-01, atol=1e-01)\n",
    "comparativa3=np.allclose(veamos, veamos1,rtol=1e-01, atol=1e-01)\n",
    "\n",
    "print(\"comparativa (pytorch == NDRange): \",comparativa1)\n",
    "print(\"comparativa (pytorch == Simple Task): \",comparativa2)\n",
    "print(\"comparativa (NDRange == Simple Task): \",comparativa3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(expand_factor_b * 2):\n",
    "    for j in range(tamanyo):\n",
    "        for k in range(tamanyo):\n",
    "            if (abs(salida8_total_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k] - veamos1[i][j][k])) > 1e-01:\n",
    "                print(\"i:\", i, \"j:\", j, \"k:\", k, salida8_total_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k], veamos1[i][j][k])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo en segundos con pytorch=  0.05108882825000819\n",
      "tiempo en segundos con opencl (Simple Task)= 0.028037996070006555\n",
      "comparativa (pytorch == Simple Task):  True\n"
     ]
    }
   ],
   "source": [
    "######## BLOCK 3 ########\n",
    "tamanyo=14 #input_size\n",
    "canales_iniciales=256 #input channels and \n",
    "squeeze_factor_a = 48\n",
    "squeeze_factor_b = 64\n",
    "expand_factor_a = 192\n",
    "expand_factor_b = 256\n",
    "\n",
    "################\n",
    "\n",
    "tamanyo_final = tamanyo # En el último bloque no hay maxpool layer\n",
    "\n",
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "count = 100\n",
    "acumulado_pytorch=0\n",
    "acumulado_kernel=0\n",
    "comparativa = True\n",
    "\n",
    "params = torch.load('squeezenet1_1.pth')\n",
    "\n",
    "######## BLOCK 3 ########\n",
    "#fire - fire - fire - fire block 3\n",
    "#### FIRE 6 ####\n",
    "weights1 = params['features.9.squeeze.weight'].numpy()\n",
    "bias1 = params['features.9.squeeze.bias'].numpy()\n",
    "\n",
    "weights2a = params['features.9.expand1x1.weight'].numpy()\n",
    "bias2a = params['features.9.expand1x1.bias'].numpy()\n",
    "\n",
    "weights2b = params['features.9.expand3x3.weight'].numpy()\n",
    "bias2b = params['features.9.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 7 ####\n",
    "weights3 = params['features.10.squeeze.weight'].numpy()\n",
    "bias3 = params['features.10.squeeze.bias'].numpy()\n",
    "\n",
    "weights4a = params['features.10.expand1x1.weight'].numpy()\n",
    "bias4a = params['features.10.expand1x1.bias'].numpy()\n",
    "\n",
    "weights4b = params['features.10.expand3x3.weight'].numpy()\n",
    "bias4b = params['features.10.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 8 ####\n",
    "weights5 = params['features.11.squeeze.weight'].numpy()\n",
    "bias5 = params['features.11.squeeze.bias'].numpy()\n",
    "\n",
    "weights6a = params['features.11.expand1x1.weight'].numpy()\n",
    "bias6a = params['features.11.expand1x1.bias'].numpy()\n",
    "\n",
    "weights6b = params['features.11.expand3x3.weight'].numpy()\n",
    "bias6b = params['features.11.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 9 ####\n",
    "weights7 = params['features.12.squeeze.weight'].numpy()\n",
    "bias7 = params['features.12.squeeze.bias'].numpy()\n",
    "\n",
    "weights8a = params['features.12.expand1x1.weight'].numpy()\n",
    "bias8a = params['features.12.expand1x1.bias'].numpy()\n",
    "\n",
    "weights8b = params['features.12.expand3x3.weight'].numpy()\n",
    "bias8b = params['features.12.expand3x3.bias'].numpy()\n",
    "\n",
    "for i in range(count):\n",
    "   \n",
    "\n",
    "    imagen = np.random.randint(239,size=(1,canales_iniciales, tamanyo, tamanyo))\n",
    "\n",
    "    tic=pc()\n",
    "\n",
    "    squeeze1=nn.Conv2d(canales_iniciales, squeeze_factor_a, kernel_size=1, bias=False)\n",
    "    squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "    squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))    \n",
    "\n",
    "    squeeze2a=nn.Conv2d(squeeze_factor_a, expand_factor_a, kernel_size=1, bias=False)\n",
    "    squeeze2a.weight = nn.Parameter(torch.from_numpy(weights2a))\n",
    "    squeeze2a.bias = nn.Parameter(torch.from_numpy(bias2a))\n",
    "\n",
    "    squeeze2b=nn.Conv2d(squeeze_factor_a, expand_factor_a, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze2b.weight = nn.Parameter(torch.from_numpy(weights2b))\n",
    "    squeeze2b.bias = nn.Parameter(torch.from_numpy(bias2b))\n",
    "\n",
    "    squeeze3=nn.Conv2d(expand_factor_a * 2, squeeze_factor_a, kernel_size=1, bias=False)\n",
    "    squeeze3.weight = nn.Parameter(torch.from_numpy(weights3))\n",
    "    squeeze3.bias = nn.Parameter(torch.from_numpy(bias3))    \n",
    "\n",
    "    squeeze4a=nn.Conv2d(squeeze_factor_a, expand_factor_a, kernel_size=1, bias=False)\n",
    "    squeeze4a.weight = nn.Parameter(torch.from_numpy(weights4a))\n",
    "    squeeze4a.bias = nn.Parameter(torch.from_numpy(bias4a))\n",
    "\n",
    "    squeeze4b=nn.Conv2d(squeeze_factor_a, expand_factor_a, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze4b.weight = nn.Parameter(torch.from_numpy(weights4b))\n",
    "    squeeze4b.bias = nn.Parameter(torch.from_numpy(bias4b))\n",
    "\n",
    "    squeeze5=nn.Conv2d(expand_factor_a * 2, squeeze_factor_b, kernel_size=1, bias=False)\n",
    "    squeeze5.weight = nn.Parameter(torch.from_numpy(weights5))\n",
    "    squeeze5.bias = nn.Parameter(torch.from_numpy(bias5))    \n",
    "\n",
    "    squeeze6a=nn.Conv2d(squeeze_factor_b, expand_factor_b, kernel_size=1, bias=False)\n",
    "    squeeze6a.weight = nn.Parameter(torch.from_numpy(weights6a))\n",
    "    squeeze6a.bias = nn.Parameter(torch.from_numpy(bias6a))\n",
    "\n",
    "    squeeze6b=nn.Conv2d(squeeze_factor_b, expand_factor_b, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze6b.weight = nn.Parameter(torch.from_numpy(weights6b))\n",
    "    squeeze6b.bias = nn.Parameter(torch.from_numpy(bias6b))\n",
    "\n",
    "    squeeze7=nn.Conv2d(expand_factor_b * 2, squeeze_factor_b, kernel_size=1, bias=False)\n",
    "    squeeze7.weight = nn.Parameter(torch.from_numpy(weights7))\n",
    "    squeeze7.bias = nn.Parameter(torch.from_numpy(bias7))    \n",
    "\n",
    "    squeeze8a=nn.Conv2d(squeeze_factor_b, expand_factor_b, kernel_size=1, bias=False)\n",
    "    squeeze8a.weight = nn.Parameter(torch.from_numpy(weights8a))\n",
    "    squeeze8a.bias = nn.Parameter(torch.from_numpy(bias8a))\n",
    "\n",
    "    squeeze8b=nn.Conv2d(squeeze_factor_b, expand_factor_b, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze8b.weight = nn.Parameter(torch.from_numpy(weights8b))\n",
    "    squeeze8b.bias = nn.Parameter(torch.from_numpy(bias8b))\n",
    "\n",
    "    imagen1  = torch.from_numpy(imagen).float()\n",
    "\n",
    "    salida1=squeeze1(imagen1)\n",
    "    salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "    salida2a=squeeze2a(salida1_activation)\n",
    "    salida2a_activation=squeeze_activation(salida2a)\n",
    "    salida2b=squeeze2b(salida1_activation)\n",
    "    salida2b_activation=squeeze_activation(salida2b)    \n",
    "    salida2_total=torch.cat([salida2a_activation,salida2b_activation], 1)\n",
    "\n",
    "    salida3=squeeze3(salida2_total)\n",
    "    salida3_activation=squeeze_activation(salida3)\n",
    "\n",
    "    salida4a=squeeze4a(salida3_activation)\n",
    "    salida4a_activation=squeeze_activation(salida4a)\n",
    "    salida4b=squeeze4b(salida3_activation)\n",
    "    salida4b_activation=squeeze_activation(salida4b)    \n",
    "    salida4_total=torch.cat([salida4a_activation,salida4b_activation], 1)\n",
    "\n",
    "    salida5=squeeze5(salida4_total)\n",
    "    salida5_activation=squeeze_activation(salida5)\n",
    "\n",
    "    salida6a=squeeze6a(salida5_activation)\n",
    "    salida6a_activation=squeeze_activation(salida6a)\n",
    "    salida6b=squeeze6b(salida5_activation)\n",
    "    salida6b_activation=squeeze_activation(salida6b)    \n",
    "    salida6_total=torch.cat([salida6a_activation,salida6b_activation], 1)\n",
    "\n",
    "    salida7=squeeze7(salida6_total)\n",
    "    salida7_activation=squeeze_activation(salida7)\n",
    "\n",
    "    salida8a=squeeze8a(salida7_activation)\n",
    "    salida8a_activation=squeeze_activation(salida8a)\n",
    "    salida8b=squeeze8b(salida7_activation)\n",
    "    salida8b_activation=squeeze_activation(salida8b)    \n",
    "    salida8_total=torch.cat([salida8a_activation,salida8b_activation], 1)\n",
    "\n",
    "    salida8_total_a_numpy=salida8_total.detach().numpy()\n",
    "\n",
    "    toc=pc()\n",
    "\n",
    "    acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "\n",
    "    ####### OPENCL COMPARISON #######\n",
    "                               \n",
    "    # NDRANGE\n",
    "    h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "    d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "    fire6_squeeze_weight = weights1.reshape(-1)\n",
    "    fire6_squeeze_bias = bias1\n",
    "    fire6_expand1x1_weight = weights2a.reshape(-1)\n",
    "    fire6_expand1x1_bias = bias2a\n",
    "    fire6_expand3x3_weight =weights2b.reshape(-1)\n",
    "    fire6_expand3x3_bias = bias2b\n",
    "\n",
    "    fire7_squeeze_weight = weights3.reshape(-1)\n",
    "    fire7_squeeze_bias = bias3\n",
    "    fire7_expand1x1_weight = weights4a.reshape(-1)\n",
    "    fire7_expand1x1_bias = bias4a\n",
    "    fire7_expand3x3_weight =weights4b.reshape(-1)\n",
    "    fire7_expand3x3_bias = bias4b\n",
    "\n",
    "    fire8_squeeze_weight = weights5.reshape(-1)\n",
    "    fire8_squeeze_bias = bias5\n",
    "    fire8_expand1x1_weight = weights6a.reshape(-1)\n",
    "    fire8_expand1x1_bias = bias6a\n",
    "    fire8_expand3x3_weight =weights6b.reshape(-1)\n",
    "    fire8_expand3x3_bias = bias6b\n",
    "\n",
    "    fire9_squeeze_weight = weights7.reshape(-1)\n",
    "    fire9_squeeze_bias = bias7\n",
    "    fire9_expand1x1_weight = weights8a.reshape(-1)\n",
    "    fire9_expand1x1_bias = bias8a\n",
    "    fire9_expand3x3_weight =weights8b.reshape(-1)\n",
    "    fire9_expand3x3_bias = bias8b\n",
    "\n",
    "    h_result_fire6_squeeze = np.empty(1 * squeeze_factor_a * tamanyo * tamanyo).astype(np.float32)\n",
    "    h_result_fire6_expand = np.empty(1 * expand_factor_a * 2 * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "    h_result_fire7_squeeze = np.empty(1 * squeeze_factor_a * tamanyo * tamanyo).astype(np.float32)\n",
    "    h_result_fire7_expand = np.empty(1 * expand_factor_a * 2 * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "    h_result_fire8_squeeze = np.empty(1 * squeeze_factor_b * tamanyo * tamanyo).astype(np.float32)\n",
    "    h_result_fire8_expand = np.empty(1 * expand_factor_b * 2 * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "    h_result_fire9_squeeze = np.empty(1 * squeeze_factor_b * tamanyo * tamanyo).astype(np.float32)\n",
    "    h_result_fire9_expand = np.empty(1 * expand_factor_b * 2 * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "    d_fire6_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_squeeze_weight)\n",
    "    d_fire6_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_squeeze_bias)\n",
    "    d_fire6_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand1x1_weight)\n",
    "    d_fire6_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand1x1_bias)\n",
    "    d_fire6_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand3x3_weight)\n",
    "    d_fire6_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand3x3_bias)\n",
    "\n",
    "    d_fire7_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_squeeze_weight)\n",
    "    d_fire7_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_squeeze_bias)\n",
    "    d_fire7_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand1x1_weight)\n",
    "    d_fire7_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand1x1_bias)\n",
    "    d_fire7_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand3x3_weight)\n",
    "    d_fire7_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand3x3_bias)\n",
    "\n",
    "    d_fire8_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_squeeze_weight)\n",
    "    d_fire8_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_squeeze_bias)\n",
    "    d_fire8_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand1x1_weight)\n",
    "    d_fire8_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand1x1_bias)\n",
    "    d_fire8_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand3x3_weight)\n",
    "    d_fire8_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand3x3_bias)\n",
    "\n",
    "    d_fire9_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_squeeze_weight)\n",
    "    d_fire9_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_squeeze_bias)\n",
    "    d_fire9_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_expand1x1_weight)\n",
    "    d_fire9_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_expand1x1_bias)\n",
    "    d_fire9_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_expand3x3_weight)\n",
    "    d_fire9_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_expand3x3_bias)\n",
    "\n",
    "    d_result_fire6_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire6_squeeze.nbytes)\n",
    "    d_result_fire6_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire6_expand.nbytes)\n",
    "\n",
    "    d_result_fire7_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire7_squeeze.nbytes)\n",
    "    d_result_fire7_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire7_expand.nbytes)\n",
    "\n",
    "    d_result_fire8_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire8_squeeze.nbytes)\n",
    "    d_result_fire8_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire8_expand.nbytes)\n",
    "\n",
    "    d_result_fire9_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire9_squeeze.nbytes)\n",
    "    d_result_fire9_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire9_expand.nbytes)\n",
    "\n",
    "    tic5 = pc()\n",
    "\n",
    "    conv1x1_NDR(queue,(squeeze_factor_a, tamanyo), None, np.int32(canales_iniciales/4), tamanyo, d_sample, d_fire6_squeeze_weight, d_fire6_squeeze_bias, d_result_fire6_squeeze)\n",
    "\n",
    "    queue.finish()\n",
    "\n",
    "    conv1x1_NDR(queue1,(expand_factor_a, tamanyo), None, np.int32(squeeze_factor_a/4), tamanyo, d_result_fire6_squeeze, d_fire6_expand1x1_weight, d_fire6_expand1x1_bias, d_result_fire6_expand)\n",
    "    conv3x3_NDR(queue,(expand_factor_a, tamanyo), None, squeeze_factor_a, tamanyo, 1, 1, expand_factor_a, tamanyo, d_result_fire6_squeeze, d_fire6_expand3x3_weight, d_fire6_expand3x3_bias, d_result_fire6_expand)\n",
    "\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    conv1x1_NDR(queue,(squeeze_factor_a, tamanyo), None, np.int32(expand_factor_a*2/4), tamanyo, d_result_fire6_expand, d_fire7_squeeze_weight, d_fire7_squeeze_bias, d_result_fire7_squeeze)\n",
    "\n",
    "    queue.finish()\n",
    "\n",
    "    conv1x1_NDR(queue1,(expand_factor_a, tamanyo), None, np.int32(squeeze_factor_a/4), tamanyo, d_result_fire7_squeeze, d_fire7_expand1x1_weight, d_fire7_expand1x1_bias, d_result_fire7_expand)\n",
    "    conv3x3_NDR(queue,(expand_factor_a, tamanyo), None, squeeze_factor_a, tamanyo, 1, 1, expand_factor_a, tamanyo, d_result_fire7_squeeze, d_fire7_expand3x3_weight, d_fire7_expand3x3_bias, d_result_fire7_expand)\n",
    "\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    conv1x1_NDR(queue,(squeeze_factor_b, tamanyo), None, np.int32(expand_factor_a*2/4), tamanyo, d_result_fire7_expand, d_fire8_squeeze_weight, d_fire8_squeeze_bias, d_result_fire8_squeeze)\n",
    "\n",
    "    queue.finish()\n",
    "\n",
    "    conv1x1_NDR(queue1,(expand_factor_b, tamanyo), None, np.int32(squeeze_factor_b/4), tamanyo, d_result_fire8_squeeze, d_fire8_expand1x1_weight, d_fire8_expand1x1_bias, d_result_fire8_expand)\n",
    "    conv3x3_NDR(queue,(expand_factor_b, tamanyo), None, squeeze_factor_b, tamanyo, 1, 1, expand_factor_b, tamanyo, d_result_fire8_squeeze, d_fire8_expand3x3_weight, d_fire8_expand3x3_bias, d_result_fire8_expand)\n",
    "\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    conv1x1_NDR(queue,(squeeze_factor_b, tamanyo), None, np.int32(expand_factor_b*2/4), tamanyo, d_result_fire8_expand, d_fire9_squeeze_weight, d_fire9_squeeze_bias, d_result_fire9_squeeze)\n",
    "\n",
    "    queue.finish()\n",
    "\n",
    "    conv1x1_NDR(queue1,(expand_factor_b, tamanyo), None, np.int32(squeeze_factor_b/4), tamanyo, d_result_fire9_squeeze, d_fire9_expand1x1_weight, d_fire9_expand1x1_bias, d_result_fire9_expand)\n",
    "    conv3x3_NDR(queue,(expand_factor_b, tamanyo), None, squeeze_factor_b, tamanyo, 1, 1, expand_factor_b, tamanyo, d_result_fire9_squeeze, d_fire9_expand3x3_weight, d_fire9_expand3x3_bias, d_result_fire9_expand)\n",
    "\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    cl.enqueue_copy(queue, h_result_fire9_expand, d_result_fire9_expand)\n",
    "\n",
    "    queue.finish()\n",
    "\n",
    "    veamos3 = h_result_fire9_expand.reshape(-1,tamanyo,tamanyo)\n",
    "    \n",
    "    toc5 = pc()\n",
    "\n",
    "    acumulado_kernel = toc5 - tic5 + acumulado_kernel\n",
    "    \n",
    "    comparativa &= np.allclose(salida8_total_a_numpy, veamos3,rtol=1e-01, atol=1e-01)\n",
    "    \n",
    "print (\"tiempo en segundos con pytorch= \", acumulado_pytorch/count)\n",
    "print (\"tiempo en segundos con opencl (NDRange)=\",acumulado_kernel/count)\n",
    "print(\"comparativa (pytorch == NDRange): \",comparativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (675052290.py, line 72)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 72\u001b[0;36m\u001b[0m\n\u001b[0;31m    tic=pc()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "######## BLOCK 3 ########\n",
    "tamanyo=14 #input_size\n",
    "canales_iniciales=256 #input channels and \n",
    "squeeze_factor_a = 48\n",
    "squeeze_factor_b = 64\n",
    "expand_factor_a = 192\n",
    "expand_factor_b = 256\n",
    "\n",
    "################\n",
    "\n",
    "tamanyo_final = tamanyo # En el último bloque no hay maxpool layer\n",
    "\n",
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "count = 100\n",
    "acumulado_pytorch=0\n",
    "acumulado_kernel=0\n",
    "comparativa = True\n",
    "\n",
    "params = torch.load('squeezenet1_1.pth')\n",
    "\n",
    "######## BLOCK 3 ########\n",
    "#fire - fire - fire - fire block 3\n",
    "#### FIRE 6 ####\n",
    "weights1 = params['features.9.squeeze.weight'].numpy()\n",
    "bias1 = params['features.9.squeeze.bias'].numpy()\n",
    "\n",
    "weights2a = params['features.9.expand1x1.weight'].numpy()\n",
    "bias2a = params['features.9.expand1x1.bias'].numpy()\n",
    "\n",
    "weights2b = params['features.9.expand3x3.weight'].numpy()\n",
    "bias2b = params['features.9.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 7 ####\n",
    "weights3 = params['features.10.squeeze.weight'].numpy()\n",
    "bias3 = params['features.10.squeeze.bias'].numpy()\n",
    "\n",
    "weights4a = params['features.10.expand1x1.weight'].numpy()\n",
    "bias4a = params['features.10.expand1x1.bias'].numpy()\n",
    "\n",
    "weights4b = params['features.10.expand3x3.weight'].numpy()\n",
    "bias4b = params['features.10.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 8 ####\n",
    "weights5 = params['features.11.squeeze.weight'].numpy()\n",
    "bias5 = params['features.11.squeeze.bias'].numpy()\n",
    "\n",
    "weights6a = params['features.11.expand1x1.weight'].numpy()\n",
    "bias6a = params['features.11.expand1x1.bias'].numpy()\n",
    "\n",
    "weights6b = params['features.11.expand3x3.weight'].numpy()\n",
    "bias6b = params['features.11.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 9 ####\n",
    "weights7 = params['features.12.squeeze.weight'].numpy()\n",
    "bias7 = params['features.12.squeeze.bias'].numpy()\n",
    "\n",
    "weights8a = params['features.12.expand1x1.weight'].numpy()\n",
    "bias8a = params['features.12.expand1x1.bias'].numpy()\n",
    "\n",
    "weights8b = params['features.12.expand3x3.weight'].numpy()\n",
    "bias8b = params['features.12.expand3x3.bias'].numpy()\n",
    "\n",
    "for i in range(count):\n",
    "   \n",
    "\n",
    "    imagen = np.random.randint(239,size=(1,canales_iniciales, tamanyo, tamanyo))\n",
    "\n",
    "    tic=pc()\n",
    "\n",
    "    squeeze1=nn.Conv2d(canales_iniciales, squeeze_factor_a, kernel_size=1, bias=False)\n",
    "    squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "    squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))    \n",
    "\n",
    "    squeeze2a=nn.Conv2d(squeeze_factor_a, expand_factor_a, kernel_size=1, bias=False)\n",
    "    squeeze2a.weight = nn.Parameter(torch.from_numpy(weights2a))\n",
    "    squeeze2a.bias = nn.Parameter(torch.from_numpy(bias2a))\n",
    "\n",
    "    squeeze2b=nn.Conv2d(squeeze_factor_a, expand_factor_a, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze2b.weight = nn.Parameter(torch.from_numpy(weights2b))\n",
    "    squeeze2b.bias = nn.Parameter(torch.from_numpy(bias2b))\n",
    "\n",
    "    squeeze3=nn.Conv2d(expand_factor_a * 2, squeeze_factor_a, kernel_size=1, bias=False)\n",
    "    squeeze3.weight = nn.Parameter(torch.from_numpy(weights3))\n",
    "    squeeze3.bias = nn.Parameter(torch.from_numpy(bias3))    \n",
    "\n",
    "    squeeze4a=nn.Conv2d(squeeze_factor_a, expand_factor_a, kernel_size=1, bias=False)\n",
    "    squeeze4a.weight = nn.Parameter(torch.from_numpy(weights4a))\n",
    "    squeeze4a.bias = nn.Parameter(torch.from_numpy(bias4a))\n",
    "\n",
    "    squeeze4b=nn.Conv2d(squeeze_factor_a, expand_factor_a, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze4b.weight = nn.Parameter(torch.from_numpy(weights4b))\n",
    "    squeeze4b.bias = nn.Parameter(torch.from_numpy(bias4b))\n",
    "\n",
    "    squeeze5=nn.Conv2d(expand_factor_a * 2, squeeze_factor_b, kernel_size=1, bias=False)\n",
    "    squeeze5.weight = nn.Parameter(torch.from_numpy(weights5))\n",
    "    squeeze5.bias = nn.Parameter(torch.from_numpy(bias5))    \n",
    "\n",
    "    squeeze6a=nn.Conv2d(squeeze_factor_b, expand_factor_b, kernel_size=1, bias=False)\n",
    "    squeeze6a.weight = nn.Parameter(torch.from_numpy(weights6a))\n",
    "    squeeze6a.bias = nn.Parameter(torch.from_numpy(bias6a))\n",
    "\n",
    "    squeeze6b=nn.Conv2d(squeeze_factor_b, expand_factor_b, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze6b.weight = nn.Parameter(torch.from_numpy(weights6b))\n",
    "    squeeze6b.bias = nn.Parameter(torch.from_numpy(bias6b))\n",
    "\n",
    "    squeeze7=nn.Conv2d(expand_factor_b * 2, squeeze_factor_b, kernel_size=1, bias=False)\n",
    "    squeeze7.weight = nn.Parameter(torch.from_numpy(weights7))\n",
    "    squeeze7.bias = nn.Parameter(torch.from_numpy(bias7))    \n",
    "\n",
    "    squeeze8a=nn.Conv2d(squeeze_factor_b, expand_factor_b, kernel_size=1, bias=False)\n",
    "    squeeze8a.weight = nn.Parameter(torch.from_numpy(weights8a))\n",
    "    squeeze8a.bias = nn.Parameter(torch.from_numpy(bias8a))\n",
    "\n",
    "    squeeze8b=nn.Conv2d(squeeze_factor_b, expand_factor_b, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze8b.weight = nn.Parameter(torch.from_numpy(weights8b))\n",
    "    squeeze8b.bias = nn.Parameter(torch.from_numpy(bias8b))\n",
    "\n",
    "    imagen1  = torch.from_numpy(imagen).float()\n",
    "\n",
    "    salida1=squeeze1(imagen1)\n",
    "    salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "    salida2a=squeeze2a(salida1_activation)\n",
    "    salida2a_activation=squeeze_activation(salida2a)\n",
    "    salida2b=squeeze2b(salida1_activation)\n",
    "    salida2b_activation=squeeze_activation(salida2b)    \n",
    "    salida2_total=torch.cat([salida2a_activation,salida2b_activation], 1)\n",
    "\n",
    "    salida3=squeeze3(salida2_total)\n",
    "    salida3_activation=squeeze_activation(salida3)\n",
    "\n",
    "    salida4a=squeeze4a(salida3_activation)\n",
    "    salida4a_activation=squeeze_activation(salida4a)\n",
    "    salida4b=squeeze4b(salida3_activation)\n",
    "    salida4b_activation=squeeze_activation(salida4b)    \n",
    "    salida4_total=torch.cat([salida4a_activation,salida4b_activation], 1)\n",
    "\n",
    "    salida5=squeeze5(salida4_total)\n",
    "    salida5_activation=squeeze_activation(salida5)\n",
    "\n",
    "    salida6a=squeeze6a(salida5_activation)\n",
    "    salida6a_activation=squeeze_activation(salida6a)\n",
    "    salida6b=squeeze6b(salida5_activation)\n",
    "    salida6b_activation=squeeze_activation(salida6b)    \n",
    "    salida6_total=torch.cat([salida6a_activation,salida6b_activation], 1)\n",
    "\n",
    "    salida7=squeeze7(salida6_total)\n",
    "    salida7_activation=squeeze_activation(salida7)\n",
    "\n",
    "    salida8a=squeeze8a(salida7_activation)\n",
    "    salida8a_activation=squeeze_activation(salida8a)\n",
    "    salida8b=squeeze8b(salida7_activation)\n",
    "    salida8b_activation=squeeze_activation(salida8b)    \n",
    "    salida8_total=torch.cat([salida8a_activation,salida8b_activation], 1)\n",
    "\n",
    "    salida8_total_a_numpy=salida8_total.detach().numpy()\n",
    "\n",
    "    toc=pc()\n",
    "\n",
    "    acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "\n",
    "    ####### OPENCL COMPARISON #######\n",
    "    \n",
    "    # Simple Task\n",
    "    h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "    d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "    fire6_squeeze_weight = weights1.reshape(-1)\n",
    "    fire6_squeeze_bias = bias1\n",
    "    fire6_expand1x1_weight = weights2a.reshape(-1)\n",
    "    fire6_expand1x1_bias = bias2a\n",
    "    fire6_expand3x3_weight =weights2b.reshape(-1)\n",
    "    fire6_expand3x3_bias = bias2b\n",
    "\n",
    "    fire7_squeeze_weight = weights3.reshape(-1)\n",
    "    fire7_squeeze_bias = bias3\n",
    "    fire7_expand1x1_weight = weights4a.reshape(-1)\n",
    "    fire7_expand1x1_bias = bias4a\n",
    "    fire7_expand3x3_weight =weights4b.reshape(-1)\n",
    "    fire7_expand3x3_bias = bias4b\n",
    "\n",
    "    fire8_squeeze_weight = weights5.reshape(-1)\n",
    "    fire8_squeeze_bias = bias5\n",
    "    fire8_expand1x1_weight = weights6a.reshape(-1)\n",
    "    fire8_expand1x1_bias = bias6a\n",
    "    fire8_expand3x3_weight =weights6b.reshape(-1)\n",
    "    fire8_expand3x3_bias = bias6b\n",
    "\n",
    "    fire9_squeeze_weight = weights7.reshape(-1)\n",
    "    fire9_squeeze_bias = bias7\n",
    "    fire9_expand1x1_weight = weights8a.reshape(-1)\n",
    "    fire9_expand1x1_bias = bias8a\n",
    "    fire9_expand3x3_weight =weights8b.reshape(-1)\n",
    "    fire9_expand3x3_bias = bias8b\n",
    "\n",
    "    h_result_fire6_squeeze = np.empty(1 * squeeze_factor_a * tamanyo * tamanyo).astype(np.float32)\n",
    "    h_result_fire6_expand = np.empty(1 * expand_factor_a * 2 * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "    h_result_fire7_squeeze = np.empty(1 * squeeze_factor_a * tamanyo * tamanyo).astype(np.float32)\n",
    "    h_result_fire7_expand = np.empty(1 * expand_factor_a * 2 * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "    h_result_fire8_squeeze = np.empty(1 * squeeze_factor_b * tamanyo * tamanyo).astype(np.float32)\n",
    "    h_result_fire8_expand = np.empty(1 * expand_factor_b * 2 * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "    h_result_fire9_squeeze = np.empty(1 * squeeze_factor_b * tamanyo * tamanyo).astype(np.float32)\n",
    "    h_result_fire9_expand = np.empty(1 * expand_factor_b * 2 * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "    d_fire6_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_squeeze_weight)\n",
    "    d_fire6_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_squeeze_bias)\n",
    "    d_fire6_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand1x1_weight)\n",
    "    d_fire6_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand1x1_bias)\n",
    "    d_fire6_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand3x3_weight)\n",
    "    d_fire6_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand3x3_bias)\n",
    "\n",
    "    d_fire7_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_squeeze_weight)\n",
    "    d_fire7_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_squeeze_bias)\n",
    "    d_fire7_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand1x1_weight)\n",
    "    d_fire7_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand1x1_bias)\n",
    "    d_fire7_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand3x3_weight)\n",
    "    d_fire7_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand3x3_bias)\n",
    "\n",
    "    d_fire8_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_squeeze_weight)\n",
    "    d_fire8_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_squeeze_bias)\n",
    "    d_fire8_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand1x1_weight)\n",
    "    d_fire8_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand1x1_bias)\n",
    "    d_fire8_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand3x3_weight)\n",
    "    d_fire8_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand3x3_bias)\n",
    "\n",
    "    d_fire9_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_squeeze_weight)\n",
    "    d_fire9_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_squeeze_bias)\n",
    "    d_fire9_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_expand1x1_weight)\n",
    "    d_fire9_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_expand1x1_bias)\n",
    "    d_fire9_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_expand3x3_weight)\n",
    "    d_fire9_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire9_expand3x3_bias)\n",
    "\n",
    "    d_result_fire6_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire6_squeeze.nbytes)\n",
    "    d_result_fire6_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire6_expand.nbytes)\n",
    "\n",
    "    d_result_fire7_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire7_squeeze.nbytes)\n",
    "    d_result_fire7_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire7_expand.nbytes)\n",
    "\n",
    "    d_result_fire8_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire8_squeeze.nbytes)\n",
    "    d_result_fire8_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire8_expand.nbytes)\n",
    "\n",
    "    d_result_fire9_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire9_squeeze.nbytes)\n",
    "    d_result_fire9_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire9_expand.nbytes)\n",
    "\n",
    "    tic5 = pc()\n",
    "\n",
    "    conv1x1_ST(queue,(1,), None, canales_iniciales, tamanyo, squeeze_factor_a, d_sample, d_fire6_squeeze_weight, d_fire6_squeeze_bias, d_result_fire6_squeeze)\n",
    "\n",
    "    queue.finish()\n",
    "\n",
    "    conv1x1_ST(queue1,(1,), None, squeeze_factor_a, tamanyo, expand_factor_a, d_result_fire6_squeeze, d_fire6_expand1x1_weight, d_fire6_expand1x1_bias, d_result_fire6_expand)\n",
    "    conv3x3_ST(queue,(1,), None, squeeze_factor_a, tamanyo, 1, 1, expand_factor_a, tamanyo, expand_factor_a, d_result_fire6_squeeze, d_fire6_expand3x3_weight, d_fire6_expand3x3_bias, d_result_fire6_expand)\n",
    "\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    conv1x1_ST(queue,(1,), None, np.int32(expand_factor_a * 2), tamanyo, squeeze_factor_a, d_result_fire6_expand, d_fire7_squeeze_weight, d_fire7_squeeze_bias, d_result_fire7_squeeze)\n",
    "\n",
    "    queue.finish()\n",
    "\n",
    "    conv1x1_ST(queue1,(1,), None, squeeze_factor_a, tamanyo, expand_factor_a, d_result_fire7_squeeze, d_fire7_expand1x1_weight, d_fire7_expand1x1_bias, d_result_fire7_expand)\n",
    "    conv3x3_ST(queue,(1,), None, squeeze_factor_a, tamanyo, 1, 1, expand_factor_a, tamanyo, expand_factor_a, d_result_fire7_squeeze, d_fire7_expand3x3_weight, d_fire7_expand3x3_bias, d_result_fire7_expand)\n",
    "\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    conv1x1_ST(queue,(1,), None, np.int32(expand_factor_a * 2), tamanyo, squeeze_factor_b, d_result_fire7_expand, d_fire8_squeeze_weight, d_fire8_squeeze_bias, d_result_fire8_squeeze)\n",
    "\n",
    "    queue.finish()\n",
    "\n",
    "    conv1x1_ST(queue1,(1,), None, squeeze_factor_b, tamanyo, expand_factor_b, d_result_fire8_squeeze, d_fire8_expand1x1_weight, d_fire8_expand1x1_bias, d_result_fire8_expand)\n",
    "    conv3x3_ST(queue,(1,), None, squeeze_factor_b, tamanyo, 1, 1, expand_factor_b, tamanyo, expand_factor_b, d_result_fire8_squeeze, d_fire8_expand3x3_weight, d_fire8_expand3x3_bias, d_result_fire8_expand)\n",
    "\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    conv1x1_ST(queue,(1,), None, np.int32(expand_factor_b * 2), tamanyo, squeeze_factor_b, d_result_fire8_expand, d_fire9_squeeze_weight, d_fire9_squeeze_bias, d_result_fire9_squeeze)\n",
    "\n",
    "    queue.finish()\n",
    "\n",
    "    conv1x1_ST(queue1,(1,), None, squeeze_factor_b, tamanyo, expand_factor_b, d_result_fire9_squeeze, d_fire9_expand1x1_weight, d_fire9_expand1x1_bias, d_result_fire9_expand)\n",
    "    conv3x3_ST(queue,(1,), None, squeeze_factor_b, tamanyo, 1, 1, expand_factor_b, tamanyo, expand_factor_b, d_result_fire9_squeeze, d_fire9_expand3x3_weight, d_fire9_expand3x3_bias, d_result_fire9_expand)\n",
    "\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    cl.enqueue_copy(queue, h_result_fire9_expand, d_result_fire9_expand)\n",
    "\n",
    "    veamos3 = h_result_fire9_expand.reshape(-1,tamanyo,tamanyo)\n",
    "    \n",
    "    toc5 = pc()\n",
    "\n",
    "    acumulado_kernel = toc5 - tic5 + acumulado_kernel\n",
    "    \n",
    "    comparativa &= np.allclose(salida8_total_a_numpy, veamos3,rtol=1e-01, atol=1e-01)\n",
    "    \n",
    "print (\"tiempo en segundos con pytorch= \", acumulado_pytorch/count)\n",
    "print (\"tiempo en segundos con opencl (Simple Task)=\",acumulado_kernel/count)\n",
    "print(\"comparativa (pytorch == Simple Task): \",comparativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
