{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug SqueezeNet v1.3 (Simple Task) OpenCL implement with PyOpenCL and PyTorch\n",
    "Partial code are copied heavily from https://github.com/pytorch/vision/blob/master/torchvision/models/squeezenet.py  \n",
    "SqueezeNet Paper:https://arxiv.org/abs/1602.07360  \n",
    "SqueezeNet 1.1 model from https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1   \n",
    "SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters than SqueezeNet 1.0, without sacrificing accuracy.\n",
    "\n",
    "Tests arquitecura completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#some set up\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from PIL import Image\n",
    "import math\n",
    "import time\n",
    "from time import sleep, perf_counter as pc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OpenCL setup\n",
    "import pyopencl as cl\n",
    "import sys\n",
    "sys.path.append('../python_common')\n",
    "import deviceinfo\n",
    "from time import time\n",
    "\n",
    "#wksp = '../device/v1.3/squeezenet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veamos ahora fire con opencl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step1: OpenCL preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl.Context at 0x687a4a8 on <pyopencl.Device '12th Gen Intel(R) Core(TM) i7-12650H' on 'Intel(R) OpenCL' at 0x4f7fab8>>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Devices and compute context\n",
    "platforms = cl.get_platforms()\n",
    "context = cl.Context(\n",
    "        dev_type=cl.device_type.ALL,\n",
    "        properties=[(cl.context_properties.PLATFORM, platforms[0])])\n",
    "device = platforms[0].get_devices()\n",
    "\n",
    "# Create a command queue\n",
    "queue = cl.CommandQueue(context)\n",
    "queue1 = cl.CommandQueue(context)\n",
    "\n",
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 2: creat kernels\n",
    "Creat & build program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "wksp = ''\n",
    "\n",
    "file_dir = wksp + 'maxpool_NDRange.aocx'\n",
    "\n",
    "file_dir = wksp + 'squeezenet_NDRange.aocx'\n",
    "\n",
    "kernelSource = open(file_dir, mode='rb').read()\n",
    "program_NDR = cl.Program(context, device, [kernelSource]).build()\n",
    "\n",
    "file_dir = wksp + 'squeezenet_ST.aocx'\n",
    "\n",
    "kernelSource = open(file_dir, mode='rb').read()\n",
    "program_ST = cl.Program(context, device, [kernelSource]).build()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creat kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv3x3_NDR = program_NDR.conv2d3x3\n",
    "conv3x3_NDR.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "maxpool_NDR = program_NDR.maxpool2d\n",
    "maxpool_NDR.set_scalar_arg_dtypes([np.int32, np.int32, None, None])\n",
    "\n",
    "conv1x1_NDR = program_NDR.conv2d1x1\n",
    "conv1x1_NDR.set_scalar_arg_dtypes([np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "avgpool_NDR = program_NDR.avgpool2d\n",
    "avgpool_NDR.set_scalar_arg_dtypes([None, None])\n",
    "\n",
    "conv3x3_ST = program_ST.conv2d3x3\n",
    "conv3x3_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "maxpool_ST = program_ST.maxpool2d\n",
    "maxpool_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, None, None])\n",
    "\n",
    "conv1x1_ST = program_ST.conv2d1x1\n",
    "conv1x1_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "avgpool_ST = program_ST.avgpool2d\n",
    "avgpool_ST.set_scalar_arg_dtypes([None, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### OpenCL kernel: squeezenet_NDRange.cl\n",
    "conv2d3x3: 2-D 3x3 convolution.  \n",
    "conv2d1x1: 2-D 1x1 convolution. kerner size 1, stride 1  \n",
    "maxpool2d: 2-D max pool. kerner size 3, stride 2  \n",
    "avgpool2d: 2-D average pool. kernel size 13\n",
    "```C\n",
    "//maxPool2d \n",
    "//kernel_size=3 stride=2\n",
    "//output one feature map per kernel\n",
    "__kernel void maxpool2d(\n",
    "\tconst int input_size,\n",
    "\tconst int output_size,\n",
    "\t__global const float* restrict input_im,\n",
    "    __global float* restrict output_im)\n",
    "{\n",
    "\tint channels = get_global_id(0);//get output channel index\n",
    "\t\n",
    "\tinput_im += channels * input_size * input_size;\n",
    "\toutput_im += channels * output_size * output_size;\n",
    "\n",
    "\t//loop over output feature map\n",
    "\tfor(int i = 0; i < output_size; i++)//row\n",
    "\t{\n",
    "\t\tfor(int j = 0; j < output_size; j++)//col\n",
    "\t\t{\n",
    "\t\t\t//find the max value in 3x3 reigon \n",
    "\t\t\t//to be one element in the output feature map\n",
    "\t\t\tfloat tmp = 0.0;\n",
    "\n",
    "\t\t\t#pragma unroll 1\n",
    "\t\t\tfor(int k = 0; k < 3; k++)//row\n",
    "\t\t\t{\n",
    "\t\t\t\t#pragma unroll 1\n",
    "\t\t\t\tfor(int l = 0; l < 3; l++)//col\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\tfloat value = input_im[(i * 2 + k) * input_size  + j * 2 + l ];\n",
    "\t\t\t\t\tif(value > tmp)\n",
    "\t\t\t\t\t\ttmp = value;\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t\t//store the result to output feature map\n",
    "\t\t\toutput_im[i * output_size + j] = tmp; \n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "//3x3 convolution layer\n",
    "//output one feature map per kernel\n",
    "__kernel void conv2d3x3(\n",
    "\tconst int input_channels, const int input_size,\n",
    "\tconst int pad, const int stride,\n",
    "\tconst int start_channel, //start_channel is for 1x1 feature map in fire layer\n",
    "\tconst int output_size,\n",
    "\t__global const float* restrict input_im,\n",
    "\t__global const float* restrict filter_weight,\n",
    "\t__global const float* restrict filter_bias,\n",
    "\t__global float *restrict output_im\n",
    "\t)\n",
    "{\n",
    "\tint filter_index = get_global_id(0); //get output channel index\n",
    "\tint i =  get_global_id(1);\n",
    "\n",
    "\tfilter_weight += filter_index * input_channels * 9;\n",
    "\tfloat bias = filter_bias[filter_index];\n",
    "\toutput_im += (start_channel + filter_index) * output_size * output_size;\n",
    "\t\n",
    "\t//loop over output feature map\n",
    "\t//for(int i = 0; i < output_size; i++)\n",
    "\t{\n",
    "\t\tfor(int j = 0; j < output_size; j++)\n",
    "\t\t{\n",
    "\t\t\t//compute one element in the output feature map\n",
    "\t\t\tfloat tmp = bias;\n",
    "\t\t\t\n",
    "\t\t\t//compute dot product of 2 input_channels x 3 x 3 matrix\n",
    "\t\t\tfor(int k = 0; k < input_channels; k++)\n",
    "\t\t\t{\n",
    "\t\t\t\t#pragma unroll\n",
    "\t\t\t\tfor(int l = 0; l < 3; l++)\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\tint h = i * stride + l - pad;\n",
    "\t\t\t\t\tfor(int m = 0; m < 3; m++)\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\tint w = j * stride + m - pad;\n",
    "\t\t\t\t\t\tif((h >= 0) && (h < input_size) && (w >= 0) && (w < input_size))\n",
    "\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\ttmp += input_im[k * input_size * input_size + h * input_size + w] \\\n",
    "                               * filter_weight[9 * k + 3 * l + m];\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\t//add relu activation after conv\n",
    "\t\t\toutput_im[i * output_size + j] = (tmp > 0.0) ? tmp : 0.0;\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "//1x1 convolution layer\n",
    "//output one feature map per kernel\n",
    "__kernel void conv2d1x1(\n",
    "\tconst int input_channels, const int input_size,\n",
    "\t__global float *input_im,\n",
    "\t__global const float4* filter_weight,\n",
    "\t__global const float* filter_bias,\n",
    "\t__global float *restrict output_im)\n",
    "{\n",
    "\tint filter_index = get_global_id(0); // 0 - (output_channels - 1)\n",
    "\tint i = get_global_id(1);\n",
    "\n",
    "\tfilter_weight += filter_index * input_channels;\n",
    "\n",
    "\tfloat bias = filter_bias[filter_index];\n",
    "\t\n",
    "\toutput_im += filter_index * input_size * input_size;//start_channel is for 1x1 feature map in fire layer\n",
    "\n",
    "\t//loop over output feature map\n",
    "\t//for(int i = 0; i < input_size; i++)\n",
    "\t{\n",
    "\t\tfor(int j = 0; j < input_size; j++)\n",
    "\t\t{\n",
    "\t\t\tfloat tmp = bias;\n",
    "\t\t\tint loc = i * input_size + j;\n",
    "\n",
    "\t\t\tfor(int k = 0; k < input_channels; k++)\n",
    "\t\t\t{\n",
    "\t\t\t\t//float8 weight = filter_weight[k];\n",
    "\t\t\t\t//float8 feature;\n",
    "\t\t\t\ttmp += input_im[((k << 2) + 0) * input_size * input_size + loc] * filter_weight[k].s0\n",
    "\t\t\t\t     + input_im[((k << 2) + 1) * input_size * input_size + loc] * filter_weight[k].s1\n",
    "\t\t\t\t\t + input_im[((k << 2) + 2) * input_size * input_size + loc] * filter_weight[k].s2\n",
    "\t\t\t\t\t + input_im[((k << 2) + 3) * input_size * input_size + loc] * filter_weight[k].s3;\n",
    "\t\t\t}\n",
    "\t\t\t//add relu after conv\n",
    "\t\t\toutput_im[i * input_size + j] = (tmp > 0.0) ? tmp : 0.0;\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "//last layer use a 13 x 13 avgPool layer as classifier\n",
    "//one class score per kernel\n",
    "__kernel void avgpool2d(\n",
    "\t__global const float* restrict input_im,\n",
    "\t__global float* restrict output_im)\n",
    "{\n",
    "\tint class_index = get_global_id(0);//get class score index\n",
    "\n",
    "\tinput_im += 169 * class_index;\n",
    "\t\n",
    "\tfloat tmp = 0.0f;\n",
    "\n",
    "\tfor(int i = 0; i < 169; i++)\n",
    "\t{\n",
    "\t\ttmp += input_im[i];\n",
    "\t}\n",
    "\n",
    "\toutput_im[class_index] = tmp / 169.0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### OpenCL kernel: squeezenet_ST.cl\n",
    "conv2d3x3: 2-D 3x3 convolution.  \n",
    "conv2d1x1: 2-D 1x1 convolution. kerner size 1, stride 1  \n",
    "maxpool2d: 2-D max pool. kerner size 3, stride 2  \n",
    "avgpool2d: 2-D average pool. kernel size 13\n",
    "```C\n",
    "//maxPool2d \n",
    "//kernel_size=3 stride=2\n",
    "//output one feature map per kernel\n",
    "__kernel void maxpool2d(\n",
    "\tconst int input_size,\n",
    "\tconst int output_size,\n",
    "    const int channel_size,\n",
    "\t__global const float* restrict input_im,\n",
    "    __global float* restrict output_im)\n",
    "{\n",
    "\n",
    "    for(int channel_index = 0; channel_index < channel_size; channel_index++)\n",
    "    {\n",
    "        //loop over output feature map\n",
    "        for(int i = 0; i < output_size; i++)//row\n",
    "        {\n",
    "            for(int j = 0; j < output_size; j++)//col\n",
    "            {\n",
    "                //find the max value in 3x3 reigon \n",
    "                //to be one element in the output feature map\n",
    "                float tmp = 0.0;\n",
    "\n",
    "                #pragma unroll 1\n",
    "                for(int k = 0; k < 3; k++)//row\n",
    "                {\n",
    "                    #pragma unroll 1\n",
    "                    for(int l = 0; l < 3; l++)//col\n",
    "                    {\n",
    "                        float value = input_im[(i * 2 + k) * input_size  + j * 2 + l ];\n",
    "                        if(value > tmp)\n",
    "                            tmp = value;\n",
    "                    }\n",
    "                }\n",
    "                //store the result to output feature map\n",
    "                output_im[i * output_size + j] = tmp;\n",
    "            }\n",
    "        }\n",
    "    \n",
    "        input_im += input_size * input_size;\n",
    "        output_im += output_size * output_size;\n",
    "    }\n",
    "}\n",
    "\n",
    "//3x3 convolution layer\n",
    "//output one feature map per kernel\n",
    "__kernel void conv2d3x3(\n",
    "\tconst int input_channels, const int input_size,\n",
    "\tconst int pad, const int stride,\n",
    "\tconst int start_channel, //start_channel is for 1x1 feature map in fire layer\n",
    "\tconst int output_size,\n",
    "    const int filter_size,\n",
    "\t__global const float* restrict input_im,\n",
    "\t__global const float* restrict filter_weight,\n",
    "\t__global const float* restrict filter_bias,\n",
    "\t__global float *restrict output_im\n",
    "\t)\n",
    "{\n",
    "\t\n",
    "\t//filter_weight += filter_index * input_channels * 9;\n",
    "\toutput_im += start_channel * output_size * output_size;\n",
    "\t\n",
    "\t//loop over output feature map\n",
    "\tfor(int filter_index = 0; filter_index < filter_size; filter_index++)\n",
    "\t{\n",
    "        float bias = filter_bias[filter_index];\n",
    "\n",
    "\t\tfor(int i = 0; i < output_size; i++)\n",
    "\t\t{\n",
    "            for(int j = 0; j < output_size; j++)\n",
    "            {\n",
    "                //compute one element in the output feature map\n",
    "                float tmp = bias;\n",
    "\n",
    "                //compute dot product of 2 input_channels x 3 x 3 matrix\n",
    "                for(int k = 0; k < input_channels; k++)\n",
    "                {\n",
    "                    #pragma unroll\n",
    "                    for(int l = 0; l < 3; l++)\n",
    "                    {\n",
    "                        int h = i * stride + l - pad;\n",
    "                        for(int m = 0; m < 3; m++)\n",
    "                        {\n",
    "                            int w = j * stride + m - pad;\n",
    "                            if((h >= 0) && (h < input_size) && (w >= 0) && (w < input_size))\n",
    "                            {\n",
    "                                tmp += input_im[k * input_size * input_size + h * input_size + w] \\\n",
    "                                   * filter_weight[9 * k + 3 * l + m];\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                //add relu activation after conv\n",
    "                output_im[i * output_size + j] = (tmp > 0.0) ? tmp : 0.0;                 \n",
    "            }\n",
    "\t\t}\n",
    "        \n",
    "        filter_weight += input_channels * 9;\n",
    "        output_im += output_size * output_size;\n",
    "\t}\n",
    "}\n",
    "\n",
    "//1x1 convolution layer as a single kernel (V5)\n",
    "//output one feature map per kernel\n",
    "\n",
    "__kernel void conv2d1x1(\n",
    "\tconst int input_channels, \n",
    "    const int input_size,\n",
    "    const int filter_size,\n",
    "\t__global const float* restrict input_im,\n",
    "\t__global const float* restrict filter_weight,\n",
    "\t__global const float* restrict filter_bias,\n",
    "\t__global float *restrict output_im)\n",
    "{\n",
    "\t// Adding restrict keyword\n",
    "    //loop over filters\n",
    "\tfor(int f_i = 0; f_i < filter_size; f_i++)\n",
    "\t{\n",
    "        //filter_weight += f_i * input_channels;\n",
    "\n",
    "        float bias = filter_bias[f_i];\n",
    "\t\t\n",
    "        // output_im += input_size * input_size;//start_channel is for 1x1 feature map in fire layer\n",
    "\t\n",
    "\t\tfor(int ij = 0; ij < (input_size * input_size); ij++)\n",
    "\t\t{\n",
    "\t\t\tfloat tmp = bias;\n",
    "\t\t\t// int loc = i * input_size + j; // this is equal to ij\n",
    "\n",
    "\t\t\tfor(int k = 0; k < input_channels; k++)\n",
    "\t\t\t{\n",
    "\t\t\t\t//float8 weight = filter_weight[k];\n",
    "\t\t\t\t//float8 feature;\n",
    "\t\t\t\ttmp += input_im[k * input_size * input_size + ij] * filter_weight[k + f_i * input_channels];\n",
    "\t\t\t}\n",
    "\t\t\t//add relu after conv\n",
    "\t\t\toutput_im[ij + (input_size * input_size * f_i)] = (tmp > 0.0) ? tmp : 0.0;\n",
    "            //output_im[ij] = (tmp > 0.0) ? tmp : 0.0;\n",
    "\t\t}\n",
    "        //filter_weight += input_channels;\t\n",
    "        //output_im += input_size * input_size;//start_channel is for 1x1 feature map in fire layer\n",
    "\t\n",
    "\t}\n",
    "}\n",
    "\n",
    "//last layer use a 13 x 13 avgPool layer as classifier\n",
    "//one class score per kernel\n",
    "__kernel void avgpool2d(\n",
    "\t__global const float* restrict input_im,\n",
    "\t__global float* restrict output_im)\n",
    "{\n",
    "\t// int class_index = get_global_id(0);//get class score index\n",
    "    \n",
    "    //Since it's the final layer, we know that there are only 1000 classes\n",
    "    \n",
    "\t//input_im += 169 * class_index;\n",
    "\n",
    "\tfor(int class_index = 0; class_index < 1000; class_index++)\n",
    "    {\n",
    "            \n",
    "        float tmp = 0.0f;\n",
    "\n",
    "        for(int i = 0; i < 169; i++)\n",
    "        {\n",
    "            tmp += input_im[class_index * 169 + i];\n",
    "        }\n",
    "\n",
    "        output_im[class_index] = tmp / 169.0;\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run OpenCL implement  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "acumulado_pytorch = 0\n",
    " \n",
    "transform = transforms.Compose([\n",
    "transforms.Resize(256),\n",
    "transforms.CenterCrop(224),\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize(mean = [ 0.485, 0.456, 0.406 ],\n",
    "                     std = [ 0.229, 0.224, 0.225 ]),])\n",
    "\n",
    "imagen = np.random.rand(3, 224, 224).astype(np.float32)\n",
    "imagen = Image.fromarray(imagen,'RGB')\n",
    "imagen = transform(imagen).numpy()\n",
    "imagen = imagen[np.newaxis,:]\n",
    "\n",
    "#imagen = np.ones((1, 3, 224, 224))\n",
    "#print(imagen.shape)\n",
    "\n",
    "### First Conv3x3 and maxpool\n",
    "\n",
    "weights0=np.random.rand(64, 3,3,3).astype(np.float32)\n",
    "bias0=np.random.rand(64,).astype(np.float32)\n",
    "\n",
    "#### FIRE 1 ####\n",
    "weights1=np.random.rand(16, 64,1,1).astype(np.float32)\n",
    "bias1=np.random.rand(16,).astype(np.float32)\n",
    "\n",
    "weights2a=np.random.rand(64, 16,1,1).astype(np.float32)  \n",
    "bias2a=np.random.rand(64,).astype(np.float32)    \n",
    "\n",
    "weights2b=np.random.rand(64, 16,3,3).astype(np.float32)    \n",
    "bias2b=np.random.rand(64,).astype(np.float32)\n",
    "\n",
    "#### FIRE 2 ####\n",
    "weights3=np.random.rand(16, 128,1,1).astype(np.float32)\n",
    "bias3=np.random.rand(16,).astype(np.float32)\n",
    "\n",
    "weights4a=np.random.rand(64, 16,1,1).astype(np.float32)  \n",
    "bias4a=np.random.rand(64,).astype(np.float32)    \n",
    "\n",
    "weights4b=np.random.rand(64, 16,3,3).astype(np.float32)    \n",
    "bias4b=np.random.rand(64,).astype(np.float32)\n",
    "\n",
    "#### FIRE 3 ####\n",
    "weights5=np.random.rand(32, 128,1,1).astype(np.float32)\n",
    "bias5=np.random.rand(32,).astype(np.float32)\n",
    "\n",
    "weights6a=np.random.rand(128, 32,1,1).astype(np.float32)  \n",
    "bias6a=np.random.rand(128,).astype(np.float32)    \n",
    "\n",
    "weights6b=np.random.rand(128, 32,3,3).astype(np.float32)    \n",
    "bias6b=np.random.rand(128,).astype(np.float32)\n",
    "\n",
    "#### FIRE 4 ####\n",
    "weights7=np.random.rand(32, 256,1,1).astype(np.float32)\n",
    "bias7=np.random.rand(32,).astype(np.float32)\n",
    "\n",
    "weights8a=np.random.rand(128, 32,1,1).astype(np.float32)  \n",
    "bias8a=np.random.rand(128,).astype(np.float32)    \n",
    "\n",
    "weights8b=np.random.rand(128, 32,3,3).astype(np.float32)    \n",
    "bias8b=np.random.rand(128,).astype(np.float32)\n",
    "\n",
    "#### FIRE 5 ####\n",
    "weights9=np.random.rand(48, 256,1,1).astype(np.float32)\n",
    "bias9=np.random.rand(48,).astype(np.float32)\n",
    "\n",
    "weights10a=np.random.rand(192, 48,1,1).astype(np.float32)  \n",
    "bias10a=np.random.rand(192,).astype(np.float32)    \n",
    "\n",
    "weights10b=np.random.rand(192, 48,3,3).astype(np.float32)    \n",
    "bias10b=np.random.rand(192,).astype(np.float32)\n",
    "\n",
    "#### FIRE 6 ####\n",
    "weights11=np.random.rand(48, 384,1,1).astype(np.float32)\n",
    "bias11=np.random.rand(48,).astype(np.float32)\n",
    "\n",
    "weights12a=np.random.rand(192, 48,1,1).astype(np.float32)  \n",
    "bias12a=np.random.rand(192,).astype(np.float32)    \n",
    "\n",
    "weights12b=np.random.rand(192, 48,3,3).astype(np.float32)    \n",
    "bias12b=np.random.rand(192,).astype(np.float32)\n",
    "\n",
    "#### FIRE 7 ####\n",
    "weights13=np.random.rand(64, 384,1,1).astype(np.float32)\n",
    "bias13=np.random.rand(64,).astype(np.float32)\n",
    "\n",
    "weights14a=np.random.rand(256, 64,1,1).astype(np.float32)  \n",
    "bias14a=np.random.rand(256,).astype(np.float32)    \n",
    "\n",
    "weights14b=np.random.rand(256, 64,3,3).astype(np.float32)    \n",
    "bias14b=np.random.rand(256,).astype(np.float32)\n",
    "\n",
    "#### FIRE 8 ####\n",
    "weights15=np.random.rand(64, 512,1,1).astype(np.float32)\n",
    "bias15=np.random.rand(64,).astype(np.float32)\n",
    "\n",
    "weights16a=np.random.rand(256, 64,1,1).astype(np.float32)  \n",
    "bias16a=np.random.rand(256,).astype(np.float32)    \n",
    "\n",
    "weights16b=np.random.rand(256, 64,3,3).astype(np.float32)    \n",
    "bias16b=np.random.rand(256,).astype(np.float32)\n",
    "\n",
    "### Classifier Conv3x3 and maxpool\n",
    "\n",
    "weights17=np.random.rand(1000, 512,1,1).astype(np.float32)\n",
    "bias17=np.random.rand(1000,).astype(np.float32)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "params = torch.load('squeezenet1_1.pth')\n",
    "\n",
    "### First Conv3x3 and maxpool\n",
    "weights0=params['features.0.weight'].numpy()\n",
    "bias0=params['features.0.bias'].numpy()\n",
    "\n",
    "######## BLOCK 1 ########\n",
    "#fire - fire - maxpool\n",
    "#### FIRE 1 ####\n",
    "weights1=params['features.3.squeeze.weight'].numpy()\n",
    "bias1=params['features.3.squeeze.bias'].numpy()\n",
    "\n",
    "weights2a=params['features.3.expand1x1.weight'].numpy()\n",
    "bias2a=params['features.3.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights2b=params['features.3.expand3x3.weight'].numpy()   \n",
    "bias2b=params['features.3.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 2 ####\n",
    "weights3=params['features.4.squeeze.weight'].numpy()\n",
    "bias3=params['features.4.squeeze.bias'].numpy()\n",
    "\n",
    "weights4a=params['features.4.expand1x1.weight'].numpy()\n",
    "bias4a=params['features.4.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights4b=params['features.4.expand3x3.weight'].numpy()   \n",
    "bias4b=params['features.4.expand3x3.bias'].numpy()\n",
    "\n",
    "######## BLOCK 2 ########\n",
    "#fire - fire - maxpool\n",
    "#### FIRE 3 ####\n",
    "weights5=params['features.6.squeeze.weight'].numpy()\n",
    "bias5=params['features.6.squeeze.bias'].numpy()\n",
    "\n",
    "weights6a=params['features.6.expand1x1.weight'].numpy()\n",
    "bias6a=params['features.6.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights6b=params['features.6.expand3x3.weight'].numpy()   \n",
    "bias6b=params['features.6.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 4 ####\n",
    "weights7=params['features.7.squeeze.weight'].numpy()\n",
    "bias7=params['features.7.squeeze.bias'].numpy()\n",
    "\n",
    "weights8a=params['features.7.expand1x1.weight'].numpy()\n",
    "bias8a=params['features.7.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights8b=params['features.7.expand3x3.weight'].numpy()  \n",
    "bias8b=params['features.7.expand3x3.bias'].numpy()\n",
    "\n",
    "######## BLOCK 3 ########\n",
    "#fire - fire - fire - fire\n",
    "#### FIRE 5 ####\n",
    "weights9=params['features.9.squeeze.weight'].numpy()\n",
    "bias9=params['features.9.squeeze.bias'].numpy()\n",
    "\n",
    "weights10a=params['features.9.expand1x1.weight'].numpy()\n",
    "bias10a=params['features.9.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights10b=params['features.9.expand3x3.weight'].numpy()\n",
    "bias10b=params['features.9.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 6 ####\n",
    "weights11=params['features.10.squeeze.weight'].numpy()\n",
    "bias11=params['features.10.squeeze.bias'].numpy()\n",
    "\n",
    "weights12a=params['features.10.expand1x1.weight'].numpy()\n",
    "bias12a=params['features.10.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights12b=params['features.10.expand3x3.weight'].numpy()\n",
    "bias12b=params['features.10.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 7 ####\n",
    "weights13=params['features.11.squeeze.weight'].numpy()\n",
    "bias13=params['features.11.squeeze.bias'].numpy()\n",
    "\n",
    "weights14a=params['features.11.expand1x1.weight'].numpy()\n",
    "bias14a=params['features.11.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights14b=params['features.11.expand3x3.weight'].numpy()\n",
    "bias14b=params['features.11.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 8 ####\n",
    "weights15=params['features.12.squeeze.weight'].numpy()\n",
    "bias15=params['features.12.squeeze.bias'].numpy()\n",
    "\n",
    "weights16a=params['features.12.expand1x1.weight'].numpy()\n",
    "bias16a=params['features.12.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights16b=params['features.12.expand3x3.weight'].numpy()\n",
    "bias16b=params['features.12.expand3x3.bias'].numpy()\n",
    "\n",
    "######## Classifier ########\n",
    "#conv3x3 - avgpool\n",
    "### Classifier Conv3x3 and avgpool\n",
    "weights17=params['classifier.1.weight'].numpy()\n",
    "bias17=params['classifier.1.bias'].numpy()\n",
    "\n",
    "tic=pc()\n",
    "\n",
    "squeeze0=nn.Conv2d(3, 64, kernel_size=3, bias=False, stride=2)\n",
    "squeeze0.weight = nn.Parameter(torch.from_numpy(weights0))\n",
    "squeeze0.bias = nn.Parameter(torch.from_numpy(bias0))\n",
    "\n",
    "maxpool=nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "squeeze1=nn.Conv2d(64, 16, kernel_size=1, bias=False)\n",
    "squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))    \n",
    "\n",
    "squeeze2a=nn.Conv2d(16, 64, kernel_size=1, bias=False)\n",
    "squeeze2a.weight = nn.Parameter(torch.from_numpy(weights2a))\n",
    "squeeze2a.bias = nn.Parameter(torch.from_numpy(bias2a))\n",
    "\n",
    "squeeze2b=nn.Conv2d(16, 64, kernel_size=3, bias=False, padding=1)\n",
    "squeeze2b.weight = nn.Parameter(torch.from_numpy(weights2b))\n",
    "squeeze2b.bias = nn.Parameter(torch.from_numpy(bias2b))\n",
    "\n",
    "squeeze3=nn.Conv2d(128, 16, kernel_size=1, bias=False)\n",
    "squeeze3.weight = nn.Parameter(torch.from_numpy(weights3))\n",
    "squeeze3.bias = nn.Parameter(torch.from_numpy(bias3))    \n",
    "\n",
    "squeeze4a=nn.Conv2d(16, 64, kernel_size=1, bias=False)\n",
    "squeeze4a.weight = nn.Parameter(torch.from_numpy(weights4a))\n",
    "squeeze4a.bias = nn.Parameter(torch.from_numpy(bias4a))\n",
    "\n",
    "squeeze4b=nn.Conv2d(16, 64, kernel_size=3, bias=False, padding=1)\n",
    "squeeze4b.weight = nn.Parameter(torch.from_numpy(weights4b))\n",
    "squeeze4b.bias = nn.Parameter(torch.from_numpy(bias4b))\n",
    "\n",
    "squeeze5=nn.Conv2d(128, 32, kernel_size=1, bias=False)\n",
    "squeeze5.weight = nn.Parameter(torch.from_numpy(weights5))\n",
    "squeeze5.bias = nn.Parameter(torch.from_numpy(bias5))    \n",
    "\n",
    "squeeze6a=nn.Conv2d(32, 128, kernel_size=1, bias=False)\n",
    "squeeze6a.weight = nn.Parameter(torch.from_numpy(weights6a))\n",
    "squeeze6a.bias = nn.Parameter(torch.from_numpy(bias6a))\n",
    "\n",
    "squeeze6b=nn.Conv2d(32, 128, kernel_size=3, bias=False, padding=1)\n",
    "squeeze6b.weight = nn.Parameter(torch.from_numpy(weights6b))\n",
    "squeeze6b.bias = nn.Parameter(torch.from_numpy(bias6b))\n",
    "\n",
    "squeeze7=nn.Conv2d(256, 32, kernel_size=1, bias=False)\n",
    "squeeze7.weight = nn.Parameter(torch.from_numpy(weights7))\n",
    "squeeze7.bias = nn.Parameter(torch.from_numpy(bias7))    \n",
    "\n",
    "squeeze8a=nn.Conv2d(32, 128, kernel_size=1, bias=False)\n",
    "squeeze8a.weight = nn.Parameter(torch.from_numpy(weights8a))\n",
    "squeeze8a.bias = nn.Parameter(torch.from_numpy(bias8a))\n",
    "\n",
    "squeeze8b=nn.Conv2d(32, 128, kernel_size=3, bias=False, padding=1)\n",
    "squeeze8b.weight = nn.Parameter(torch.from_numpy(weights8b))\n",
    "squeeze8b.bias = nn.Parameter(torch.from_numpy(bias8b))\n",
    "\n",
    "squeeze9=nn.Conv2d(256, 48, kernel_size=1, bias=False)\n",
    "squeeze9.weight = nn.Parameter(torch.from_numpy(weights9))\n",
    "squeeze9.bias = nn.Parameter(torch.from_numpy(bias9))    \n",
    "\n",
    "squeeze10a=nn.Conv2d(48, 192, kernel_size=1, bias=False)\n",
    "squeeze10a.weight = nn.Parameter(torch.from_numpy(weights10a))\n",
    "squeeze10a.bias = nn.Parameter(torch.from_numpy(bias10a))\n",
    "\n",
    "squeeze10b=nn.Conv2d(48, 192, kernel_size=3, bias=False, padding=1)\n",
    "squeeze10b.weight = nn.Parameter(torch.from_numpy(weights10b))\n",
    "squeeze10b.bias = nn.Parameter(torch.from_numpy(bias10b))\n",
    "\n",
    "squeeze11=nn.Conv2d(384, 48, kernel_size=1, bias=False)\n",
    "squeeze11.weight = nn.Parameter(torch.from_numpy(weights11))\n",
    "squeeze11.bias = nn.Parameter(torch.from_numpy(bias11))    \n",
    "\n",
    "squeeze12a=nn.Conv2d(48, 192, kernel_size=1, bias=False)\n",
    "squeeze12a.weight = nn.Parameter(torch.from_numpy(weights12a))\n",
    "squeeze12a.bias = nn.Parameter(torch.from_numpy(bias12a))\n",
    "\n",
    "squeeze12b=nn.Conv2d(48, 192, kernel_size=3, bias=False, padding=1)\n",
    "squeeze12b.weight = nn.Parameter(torch.from_numpy(weights12b))\n",
    "squeeze12b.bias = nn.Parameter(torch.from_numpy(bias12b))\n",
    "\n",
    "squeeze13=nn.Conv2d(384, 64, kernel_size=1, bias=False)\n",
    "squeeze13.weight = nn.Parameter(torch.from_numpy(weights13))\n",
    "squeeze13.bias = nn.Parameter(torch.from_numpy(bias13))    \n",
    "\n",
    "squeeze14a=nn.Conv2d(64, 256, kernel_size=1, bias=False)\n",
    "squeeze14a.weight = nn.Parameter(torch.from_numpy(weights14a))\n",
    "squeeze14a.bias = nn.Parameter(torch.from_numpy(bias14a))\n",
    "\n",
    "squeeze14b=nn.Conv2d(64, 256, kernel_size=3, bias=False, padding=1)\n",
    "squeeze14b.weight = nn.Parameter(torch.from_numpy(weights14b))\n",
    "squeeze14b.bias = nn.Parameter(torch.from_numpy(bias14b))\n",
    "\n",
    "squeeze15=nn.Conv2d(512, 64, kernel_size=1, bias=False)\n",
    "squeeze15.weight = nn.Parameter(torch.from_numpy(weights15))\n",
    "squeeze15.bias = nn.Parameter(torch.from_numpy(bias15))    \n",
    "\n",
    "squeeze16a=nn.Conv2d(64, 256, kernel_size=1, bias=False)\n",
    "squeeze16a.weight = nn.Parameter(torch.from_numpy(weights16a))\n",
    "squeeze16a.bias = nn.Parameter(torch.from_numpy(bias16a))\n",
    "\n",
    "squeeze16b=nn.Conv2d(64, 256, kernel_size=3, bias=False, padding=1)\n",
    "squeeze16b.weight = nn.Parameter(torch.from_numpy(weights16b))\n",
    "squeeze16b.bias = nn.Parameter(torch.from_numpy(bias16b))\n",
    "\n",
    "conv_class=nn.Conv2d(512, 1000, kernel_size=1, bias=False)\n",
    "conv_class.weight = nn.Parameter(torch.from_numpy(weights17))\n",
    "conv_class.bias = nn.Parameter(torch.from_numpy(bias17))\n",
    "\n",
    "avgpool=nn.AvgPool2d(13)\n",
    "\n",
    "imagen1  = torch.from_numpy(imagen).float()\n",
    "\n",
    "salida0=squeeze0(imagen1)\n",
    "salida0_activation=squeeze_activation(salida0)\n",
    "\n",
    "salida_pool1 = maxpool(salida0_activation)\n",
    "\n",
    "salida1=squeeze1(salida_pool1)\n",
    "salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "salida2a=squeeze2a(salida1_activation)\n",
    "salida2a_activation=squeeze_activation(salida2a)\n",
    "salida2b=squeeze2b(salida1_activation)\n",
    "salida2b_activation=squeeze_activation(salida2b)    \n",
    "salida2_total=torch.cat([salida2a_activation,salida2b_activation], 1)\n",
    "\n",
    "salida3=squeeze3(salida2_total)\n",
    "salida3_activation=squeeze_activation(salida3)\n",
    "\n",
    "salida4a=squeeze4a(salida3_activation)\n",
    "salida4a_activation=squeeze_activation(salida4a)\n",
    "salida4b=squeeze4b(salida3_activation)\n",
    "salida4b_activation=squeeze_activation(salida4b)    \n",
    "salida4_total=torch.cat([salida4a_activation,salida4b_activation], 1)\n",
    "\n",
    "salida_pool2 = maxpool(salida4_total)\n",
    "\n",
    "salida5=squeeze5(salida_pool2)\n",
    "salida5_activation=squeeze_activation(salida5)\n",
    "\n",
    "salida6a=squeeze6a(salida5_activation)\n",
    "salida6a_activation=squeeze_activation(salida6a)\n",
    "salida6b=squeeze6b(salida5_activation)\n",
    "salida6b_activation=squeeze_activation(salida6b)    \n",
    "salida6_total=torch.cat([salida6a_activation,salida6b_activation], 1)\n",
    "\n",
    "salida7=squeeze7(salida6_total)\n",
    "salida7_activation=squeeze_activation(salida7)\n",
    "\n",
    "salida8a=squeeze8a(salida7_activation)\n",
    "salida8a_activation=squeeze_activation(salida8a)\n",
    "salida8b=squeeze8b(salida7_activation)\n",
    "salida8b_activation=squeeze_activation(salida8b)    \n",
    "salida8_total=torch.cat([salida8a_activation,salida8b_activation], 1)\n",
    "\n",
    "salida_pool3 = maxpool(salida8_total)\n",
    "\n",
    "salida9=squeeze9(salida_pool3)\n",
    "salida9_activation=squeeze_activation(salida9)\n",
    "\n",
    "salida10a=squeeze10a(salida9_activation)\n",
    "salida10a_activation=squeeze_activation(salida10a)\n",
    "salida10b=squeeze10b(salida9_activation)\n",
    "salida10b_activation=squeeze_activation(salida10b)    \n",
    "salida10_total=torch.cat([salida10a_activation,salida10b_activation], 1)\n",
    "\n",
    "salida11=squeeze11(salida10_total)\n",
    "salida11_activation=squeeze_activation(salida11)\n",
    "\n",
    "salida12a=squeeze12a(salida11_activation)\n",
    "salida12a_activation=squeeze_activation(salida12a)\n",
    "salida12b=squeeze12b(salida11_activation)\n",
    "salida12b_activation=squeeze_activation(salida12b)    \n",
    "salida12_total=torch.cat([salida12a_activation,salida12b_activation], 1)\n",
    "\n",
    "salida13=squeeze13(salida12_total)\n",
    "salida13_activation=squeeze_activation(salida13)\n",
    "\n",
    "salida14a=squeeze14a(salida13_activation)\n",
    "salida14a_activation=squeeze_activation(salida14a)\n",
    "salida14b=squeeze14b(salida13_activation)\n",
    "salida14b_activation=squeeze_activation(salida14b)    \n",
    "salida14_total=torch.cat([salida14a_activation,salida14b_activation], 1)\n",
    "\n",
    "salida15=squeeze15(salida14_total)\n",
    "salida15_activation=squeeze_activation(salida15)\n",
    "\n",
    "salida16a=squeeze16a(salida15_activation)\n",
    "salida16a_activation=squeeze_activation(salida16a)\n",
    "salida16b=squeeze16b(salida15_activation)\n",
    "salida16b_activation=squeeze_activation(salida16b)    \n",
    "salida16_total=torch.cat([salida16a_activation,salida16b_activation], 1)\n",
    "\n",
    "salida17=conv_class(salida16_total)\n",
    "salida17_activation=squeeze_activation(salida17)\n",
    "salida18=avgpool(salida17_activation)\n",
    "\n",
    "salida18_a_numpy=salida18.detach().numpy()\n",
    "\n",
    "toc=pc()\n",
    "\n",
    "acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "\n",
    "####### OPENCL COMPARISON #######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NDRANGE\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "conv1_weight = weights0.reshape(-1)\n",
    "conv1_bias = bias0\n",
    "\n",
    "fire1_squeeze_weight = weights1.reshape(-1)\n",
    "fire1_squeeze_bias = bias1\n",
    "fire1_expand1x1_weight = weights2a.reshape(-1)\n",
    "fire1_expand1x1_bias = bias2a\n",
    "fire1_expand3x3_weight =weights2b.reshape(-1)\n",
    "fire1_expand3x3_bias = bias2b\n",
    "\n",
    "fire2_squeeze_weight = weights3.reshape(-1)\n",
    "fire2_squeeze_bias = bias3\n",
    "fire2_expand1x1_weight = weights4a.reshape(-1)\n",
    "fire2_expand1x1_bias = bias4a\n",
    "fire2_expand3x3_weight =weights4b.reshape(-1)\n",
    "fire2_expand3x3_bias = bias4b\n",
    "\n",
    "fire3_squeeze_weight = weights5.reshape(-1)\n",
    "fire3_squeeze_bias = bias5\n",
    "fire3_expand1x1_weight = weights6a.reshape(-1)\n",
    "fire3_expand1x1_bias = bias6a\n",
    "fire3_expand3x3_weight =weights6b.reshape(-1)\n",
    "fire3_expand3x3_bias = bias6b\n",
    "\n",
    "fire4_squeeze_weight = weights7.reshape(-1)\n",
    "fire4_squeeze_bias = bias7\n",
    "fire4_expand1x1_weight = weights8a.reshape(-1)\n",
    "fire4_expand1x1_bias = bias8a\n",
    "fire4_expand3x3_weight =weights8b.reshape(-1)\n",
    "fire4_expand3x3_bias = bias8b\n",
    "\n",
    "fire5_squeeze_weight = weights9.reshape(-1)\n",
    "fire5_squeeze_bias = bias9\n",
    "fire5_expand1x1_weight = weights10a.reshape(-1)\n",
    "fire5_expand1x1_bias = bias10a\n",
    "fire5_expand3x3_weight =weights10b.reshape(-1)\n",
    "fire5_expand3x3_bias = bias10b\n",
    "\n",
    "fire6_squeeze_weight = weights11.reshape(-1)\n",
    "fire6_squeeze_bias = bias11\n",
    "fire6_expand1x1_weight = weights12a.reshape(-1)\n",
    "fire6_expand1x1_bias = bias12a\n",
    "fire6_expand3x3_weight =weights12b.reshape(-1)\n",
    "fire6_expand3x3_bias = bias12b\n",
    "\n",
    "fire7_squeeze_weight = weights13.reshape(-1)\n",
    "fire7_squeeze_bias = bias13\n",
    "fire7_expand1x1_weight = weights14a.reshape(-1)\n",
    "fire7_expand1x1_bias = bias14a\n",
    "fire7_expand3x3_weight =weights14b.reshape(-1)\n",
    "fire7_expand3x3_bias = bias14b\n",
    "\n",
    "fire8_squeeze_weight = weights15.reshape(-1)\n",
    "fire8_squeeze_bias = bias15\n",
    "fire8_expand1x1_weight = weights16a.reshape(-1)\n",
    "fire8_expand1x1_bias = bias16a\n",
    "fire8_expand3x3_weight =weights16b.reshape(-1)\n",
    "fire8_expand3x3_bias = bias16b\n",
    "\n",
    "classifier_conv_weight = weights17.reshape(-1)\n",
    "classifier_conv_bias = bias17\n",
    "\n",
    "h_result_conv = np.empty(1 * 64 * 111 * 111).astype(np.float32)\n",
    "h_result_pool1 = np.empty(1 * 64 * 55 * 55).astype(np.float32)\n",
    "\n",
    "h_result_fire1_squeeze = np.empty(1 * 16 * 55 * 55).astype(np.float32)\n",
    "h_result_fire1_expand = np.empty(1 * 128 * 55 * 55).astype(np.float32)\n",
    "h_result_fire2_squeeze = np.empty(1 * 16 * 55 * 55).astype(np.float32)\n",
    "h_result_fire2_expand = np.empty(1 * 128 * 55 * 55).astype(np.float32)\n",
    "h_result_pool2 = np.empty(1 * 128 * 27 * 27).astype(np.float32)\n",
    "\n",
    "h_result_fire3_squeeze = np.empty(1 * 32 * 27 * 27).astype(np.float32)\n",
    "h_result_fire3_expand = np.empty(1 * 256 * 27 * 27).astype(np.float32)\n",
    "h_result_fire4_squeeze = np.empty(1 * 32 * 27 * 27).astype(np.float32)\n",
    "h_result_fire4_expand = np.empty(1 * 256 * 27 * 27).astype(np.float32)\n",
    "h_result_pool3 = np.empty(1 * 256 * 13 * 13).astype(np.float32)\n",
    "\n",
    "h_result_fire5_squeeze = np.empty(1 * 48 * 13 * 13).astype(np.float32)\n",
    "h_result_fire5_expand = np.empty(1 * 384 * 13 * 13).astype(np.float32)\n",
    "h_result_fire6_squeeze = np.empty(1 * 48 * 13 * 13).astype(np.float32)\n",
    "h_result_fire6_expand = np.empty(1 * 384 * 13 * 13).astype(np.float32)\n",
    "h_result_fire7_squeeze = np.empty(1 * 64 * 13 * 13).astype(np.float32)\n",
    "h_result_fire7_expand = np.empty(1 * 512 * 13 * 13).astype(np.float32)\n",
    "h_result_fire8_squeeze = np.empty(1 * 64 * 13 * 13).astype(np.float32)\n",
    "h_result_fire8_expand = np.empty(1 * 512 * 13 * 13).astype(np.float32)\n",
    "\n",
    "h_result_classifier_conv = np.empty(1 * 1000 * 13 * 13).astype(np.float32)\n",
    "h_result_classifier = np.empty(1 * 1000).astype(np.float32)\n",
    "\n",
    "d_conv1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=conv1_weight)\n",
    "d_conv1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=conv1_bias)\n",
    "\n",
    "d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "d_fire1_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_weight)\n",
    "d_fire1_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_bias)\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "d_fire2_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_weight)\n",
    "d_fire2_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_bias)\n",
    "d_fire2_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_weight)\n",
    "d_fire2_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_bias)\n",
    "d_fire2_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_weight)\n",
    "d_fire2_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_bias)\n",
    "\n",
    "d_fire3_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_squeeze_weight)\n",
    "d_fire3_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_squeeze_bias)\n",
    "d_fire3_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand1x1_weight)\n",
    "d_fire3_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand1x1_bias)\n",
    "d_fire3_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand3x3_weight)\n",
    "d_fire3_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand3x3_bias)\n",
    "\n",
    "d_fire4_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_squeeze_weight)\n",
    "d_fire4_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_squeeze_bias)\n",
    "d_fire4_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand1x1_weight)\n",
    "d_fire4_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand1x1_bias)\n",
    "d_fire4_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand3x3_weight)\n",
    "d_fire4_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand3x3_bias)\n",
    "\n",
    "d_fire5_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_squeeze_weight)\n",
    "d_fire5_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_squeeze_bias)\n",
    "d_fire5_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand1x1_weight)\n",
    "d_fire5_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand1x1_bias)\n",
    "d_fire5_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand3x3_weight)\n",
    "d_fire5_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand3x3_bias)\n",
    "\n",
    "d_fire6_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_squeeze_weight)\n",
    "d_fire6_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_squeeze_bias)\n",
    "d_fire6_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand1x1_weight)\n",
    "d_fire6_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand1x1_bias)\n",
    "d_fire6_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand3x3_weight)\n",
    "d_fire6_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand3x3_bias)\n",
    "\n",
    "d_fire7_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_squeeze_weight)\n",
    "d_fire7_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_squeeze_bias)\n",
    "d_fire7_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand1x1_weight)\n",
    "d_fire7_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand1x1_bias)\n",
    "d_fire7_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand3x3_weight)\n",
    "d_fire7_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand3x3_bias)\n",
    "\n",
    "d_fire8_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_squeeze_weight)\n",
    "d_fire8_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_squeeze_bias)\n",
    "d_fire8_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand1x1_weight)\n",
    "d_fire8_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand1x1_bias)\n",
    "d_fire8_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand3x3_weight)\n",
    "d_fire8_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand3x3_bias)\n",
    "\n",
    "d_classifier_conv_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=classifier_conv_weight)\n",
    "d_classifier_conv_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=classifier_conv_bias)\n",
    "\n",
    "d_result_conv = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_conv.nbytes)\n",
    "d_result_pool1 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool1.nbytes)\n",
    "\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "d_result_fire2_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_squeeze.nbytes)\n",
    "d_result_fire2_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_expand.nbytes)\n",
    "d_result_pool2 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool2.nbytes)\n",
    "\n",
    "d_result_fire3_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire3_squeeze.nbytes)\n",
    "d_result_fire3_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire3_expand.nbytes)\n",
    "d_result_fire4_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire4_squeeze.nbytes)\n",
    "d_result_fire4_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire4_expand.nbytes)\n",
    "d_result_pool3 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool3.nbytes)\n",
    "\n",
    "d_result_fire5_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire5_squeeze.nbytes)\n",
    "d_result_fire5_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire5_expand.nbytes)\n",
    "d_result_fire6_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire6_squeeze.nbytes)\n",
    "d_result_fire6_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire6_expand.nbytes)\n",
    "d_result_fire7_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire7_squeeze.nbytes)\n",
    "d_result_fire7_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire7_expand.nbytes)\n",
    "d_result_fire8_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire8_squeeze.nbytes)\n",
    "d_result_fire8_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire8_expand.nbytes)\n",
    "\n",
    "d_result_classifier_conv = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_classifier_conv.nbytes)\n",
    "d_result_classifier = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_classifier.nbytes)\n",
    "\n",
    "tic2 = pc()\n",
    "\n",
    "#first conv layer\n",
    "conv3x3_NDR(queue,(64, 111), None, 3, 224, 0, 2, 0, 111, d_sample, d_conv1_weight, d_conv1_bias, d_result_conv)\n",
    "maxpool_NDR(queue, (64, ), None, 111, 55, d_result_conv, d_result_pool1)\n",
    "\n",
    "#block1\n",
    "conv1x1_NDR(queue,(16, 55), None, np.int32(64/4), 55, d_result_pool1, d_fire1_squeeze_weight, d_fire1_squeeze_bias, d_result_fire1_squeeze)\n",
    "queue.finish()\n",
    "conv1x1_NDR(queue1,(64, 55), None, np.int32(16/4), 55, d_result_fire1_squeeze, d_fire1_expand1x1_weight, d_fire1_expand1x1_bias, d_result_fire1_expand)\n",
    "conv3x3_NDR(queue,(64, 55), None, 16, 55, 1, 1, 64, 55, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "conv1x1_NDR(queue,(16, 55), None, np.int32(128/4), 55, d_result_fire1_expand, d_fire2_squeeze_weight, d_fire2_squeeze_bias, d_result_fire2_squeeze)\n",
    "queue.finish()\n",
    "conv1x1_NDR(queue1,(64, 55), None, np.int32(16/4), 55, d_result_fire2_squeeze, d_fire2_expand1x1_weight, d_fire2_expand1x1_bias, d_result_fire2_expand)\n",
    "conv3x3_NDR(queue,(64, 55), None, 16, 55, 1, 1, 64, 55, d_result_fire2_squeeze, d_fire2_expand3x3_weight, d_fire2_expand3x3_bias, d_result_fire2_expand)\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "maxpool_NDR(queue, (128, ), None, 55, 27, d_result_fire2_expand, d_result_pool2)\n",
    "\n",
    "#block2\n",
    "conv1x1_NDR(queue,(32, 27), None, np.int32(128/4), 27, d_result_pool2, d_fire3_squeeze_weight, d_fire3_squeeze_bias, d_result_fire3_squeeze)\n",
    "queue.finish()\n",
    "conv1x1_NDR(queue1,(128, 27), None, np.int32(32/4), 27, d_result_fire3_squeeze, d_fire3_expand1x1_weight, d_fire3_expand1x1_bias, d_result_fire3_expand)\n",
    "conv3x3_NDR(queue,(128, 27), None, 32, 27, 1, 1, 128, 27, d_result_fire3_squeeze, d_fire3_expand3x3_weight, d_fire3_expand3x3_bias, d_result_fire3_expand)\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "conv1x1_NDR(queue,(32, 27), None, np.int32(256/4), 27, d_result_fire3_expand, d_fire4_squeeze_weight, d_fire4_squeeze_bias, d_result_fire4_squeeze)\n",
    "queue.finish()\n",
    "conv1x1_NDR(queue1,(128, 27), None, np.int32(32/4), 27, d_result_fire4_squeeze, d_fire4_expand1x1_weight, d_fire4_expand1x1_bias, d_result_fire4_expand)\n",
    "conv3x3_NDR(queue,(128, 27), None, 32, 27, 1, 1, 128, 27, d_result_fire4_squeeze, d_fire4_expand3x3_weight, d_fire4_expand3x3_bias, d_result_fire4_expand)\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "maxpool_NDR(queue, (256, ), None, 27, 13, d_result_fire4_expand, d_result_pool3)\n",
    "\n",
    "#block3\n",
    "conv1x1_NDR(queue,(48, 13), None, np.int32(256/4), 13, d_result_pool3, d_fire5_squeeze_weight, d_fire5_squeeze_bias, d_result_fire5_squeeze)\n",
    "queue.finish()\n",
    "conv1x1_NDR(queue1,(192, 13), None, np.int32(48/4), 13, d_result_fire5_squeeze, d_fire5_expand1x1_weight, d_fire5_expand1x1_bias, d_result_fire5_expand)\n",
    "conv3x3_NDR(queue,(192, 13), None, 48, 13, 1, 1, 192, 13, d_result_fire5_squeeze, d_fire5_expand3x3_weight, d_fire5_expand3x3_bias, d_result_fire5_expand)\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "conv1x1_NDR(queue,(48, 13), None, np.int32(384/4), 13, d_result_fire5_expand, d_fire6_squeeze_weight, d_fire6_squeeze_bias, d_result_fire6_squeeze)\n",
    "queue.finish()\n",
    "conv1x1_NDR(queue1,(192, 13), None, np.int32(48/4), 13, d_result_fire6_squeeze, d_fire6_expand1x1_weight, d_fire6_expand1x1_bias, d_result_fire6_expand)\n",
    "conv3x3_NDR(queue,(192, 13), None, 48, 13, 1, 1, 192, 13, d_result_fire6_squeeze, d_fire6_expand3x3_weight, d_fire6_expand3x3_bias, d_result_fire6_expand)\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "conv1x1_NDR(queue,(64, 13), None, np.int32(384/4), 13, d_result_fire6_expand, d_fire7_squeeze_weight, d_fire7_squeeze_bias, d_result_fire7_squeeze)\n",
    "queue.finish()\n",
    "conv1x1_NDR(queue1,(256, 13), None, np.int32(64/4), 13, d_result_fire7_squeeze, d_fire7_expand1x1_weight, d_fire7_expand1x1_bias, d_result_fire7_expand)\n",
    "conv3x3_NDR(queue,(256, 13), None, 64, 13, 1, 1, 256, 13, d_result_fire7_squeeze, d_fire7_expand3x3_weight, d_fire7_expand3x3_bias, d_result_fire7_expand)\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "conv1x1_NDR(queue,(64, 13), None, np.int32(512/4), 13, d_result_fire7_expand, d_fire8_squeeze_weight, d_fire8_squeeze_bias, d_result_fire8_squeeze)\n",
    "queue.finish()\n",
    "conv1x1_NDR(queue1,(256, 13), None, np.int32(64/4), 13, d_result_fire8_squeeze, d_fire8_expand1x1_weight, d_fire8_expand1x1_bias, d_result_fire8_expand)\n",
    "conv3x3_NDR(queue,(256, 13), None, 64, 13, 1, 1, 256, 13, d_result_fire8_squeeze, d_fire8_expand3x3_weight, d_fire8_expand3x3_bias, d_result_fire8_expand)\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "# classifier\n",
    "conv1x1_NDR(queue,(1000, 13), None, np.int32(512/4), 13, d_result_fire8_expand, d_classifier_conv_weight, d_classifier_conv_bias, d_result_classifier_conv)\n",
    "\n",
    "avgpool_NDR(queue,(1000, ), None, d_result_classifier_conv, d_result_classifier)\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_classifier, d_result_classifier)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos = h_result_classifier\n",
    "\n",
    "rtime = pc() - tic2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple task\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "conv1_weight = weights0.reshape(-1)\n",
    "conv1_bias = bias0\n",
    "\n",
    "fire1_squeeze_weight = weights1.reshape(-1)\n",
    "fire1_squeeze_bias = bias1\n",
    "fire1_expand1x1_weight = weights2a.reshape(-1)\n",
    "fire1_expand1x1_bias = bias2a\n",
    "fire1_expand3x3_weight =weights2b.reshape(-1)\n",
    "fire1_expand3x3_bias = bias2b\n",
    "\n",
    "fire2_squeeze_weight = weights3.reshape(-1)\n",
    "fire2_squeeze_bias = bias3\n",
    "fire2_expand1x1_weight = weights4a.reshape(-1)\n",
    "fire2_expand1x1_bias = bias4a\n",
    "fire2_expand3x3_weight =weights4b.reshape(-1)\n",
    "fire2_expand3x3_bias = bias4b\n",
    "\n",
    "fire3_squeeze_weight = weights5.reshape(-1)\n",
    "fire3_squeeze_bias = bias5\n",
    "fire3_expand1x1_weight = weights6a.reshape(-1)\n",
    "fire3_expand1x1_bias = bias6a\n",
    "fire3_expand3x3_weight =weights6b.reshape(-1)\n",
    "fire3_expand3x3_bias = bias6b\n",
    "\n",
    "fire4_squeeze_weight = weights7.reshape(-1)\n",
    "fire4_squeeze_bias = bias7\n",
    "fire4_expand1x1_weight = weights8a.reshape(-1)\n",
    "fire4_expand1x1_bias = bias8a\n",
    "fire4_expand3x3_weight =weights8b.reshape(-1)\n",
    "fire4_expand3x3_bias = bias8b\n",
    "\n",
    "fire5_squeeze_weight = weights9.reshape(-1)\n",
    "fire5_squeeze_bias = bias9\n",
    "fire5_expand1x1_weight = weights10a.reshape(-1)\n",
    "fire5_expand1x1_bias = bias10a\n",
    "fire5_expand3x3_weight =weights10b.reshape(-1)\n",
    "fire5_expand3x3_bias = bias10b\n",
    "\n",
    "fire6_squeeze_weight = weights11.reshape(-1)\n",
    "fire6_squeeze_bias = bias11\n",
    "fire6_expand1x1_weight = weights12a.reshape(-1)\n",
    "fire6_expand1x1_bias = bias12a\n",
    "fire6_expand3x3_weight =weights12b.reshape(-1)\n",
    "fire6_expand3x3_bias = bias12b\n",
    "\n",
    "fire7_squeeze_weight = weights13.reshape(-1)\n",
    "fire7_squeeze_bias = bias13\n",
    "fire7_expand1x1_weight = weights14a.reshape(-1)\n",
    "fire7_expand1x1_bias = bias14a\n",
    "fire7_expand3x3_weight =weights14b.reshape(-1)\n",
    "fire7_expand3x3_bias = bias14b\n",
    "\n",
    "fire8_squeeze_weight = weights15.reshape(-1)\n",
    "fire8_squeeze_bias = bias15\n",
    "fire8_expand1x1_weight = weights16a.reshape(-1)\n",
    "fire8_expand1x1_bias = bias16a\n",
    "fire8_expand3x3_weight =weights16b.reshape(-1)\n",
    "fire8_expand3x3_bias = bias16b\n",
    "\n",
    "classifier_conv_weight = weights17.reshape(-1)\n",
    "classifier_conv_bias = bias17\n",
    "\n",
    "h_result_conv = np.empty(1 * 64 * 111 * 111).astype(np.float32)\n",
    "h_result_pool1 = np.empty(1 * 64 * 55 * 55).astype(np.float32)\n",
    "\n",
    "h_result_fire1_squeeze = np.empty(1 * 16 * 55 * 55).astype(np.float32)\n",
    "h_result_fire1_expand = np.empty(1 * 128 * 55 * 55).astype(np.float32)\n",
    "h_result_fire2_squeeze = np.empty(1 * 16 * 55 * 55).astype(np.float32)\n",
    "h_result_fire2_expand = np.empty(1 * 128 * 55 * 55).astype(np.float32)\n",
    "h_result_pool2 = np.empty(1 * 128 * 27 * 27).astype(np.float32)\n",
    "\n",
    "h_result_fire3_squeeze = np.empty(1 * 32 * 27 * 27).astype(np.float32)\n",
    "h_result_fire3_expand = np.empty(1 * 256 * 27 * 27).astype(np.float32)\n",
    "h_result_fire4_squeeze = np.empty(1 * 32 * 27 * 27).astype(np.float32)\n",
    "h_result_fire4_expand = np.empty(1 * 256 * 27 * 27).astype(np.float32)\n",
    "h_result_pool3 = np.empty(1 * 256 * 13 * 13).astype(np.float32)\n",
    "\n",
    "h_result_fire5_squeeze = np.empty(1 * 48 * 13 * 13).astype(np.float32)\n",
    "h_result_fire5_expand = np.empty(1 * 384 * 13 * 13).astype(np.float32)\n",
    "h_result_fire6_squeeze = np.empty(1 * 48 * 13 * 13).astype(np.float32)\n",
    "h_result_fire6_expand = np.empty(1 * 384 * 13 * 13).astype(np.float32)\n",
    "h_result_fire7_squeeze = np.empty(1 * 64 * 13 * 13).astype(np.float32)\n",
    "h_result_fire7_expand = np.empty(1 * 512 * 13 * 13).astype(np.float32)\n",
    "h_result_fire8_squeeze = np.empty(1 * 64 * 13 * 13).astype(np.float32)\n",
    "h_result_fire8_expand = np.empty(1 * 512 * 13 * 13).astype(np.float32)\n",
    "\n",
    "h_result_classifier_conv = np.empty(1 * 1000 * 13 * 13).astype(np.float32)\n",
    "h_result_classifier = np.empty(1 * 1000).astype(np.float32)\n",
    "\n",
    "d_conv1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=conv1_weight)\n",
    "d_conv1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=conv1_bias)\n",
    "\n",
    "d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "d_fire1_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_weight)\n",
    "d_fire1_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_bias)\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "d_fire2_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_weight)\n",
    "d_fire2_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_bias)\n",
    "d_fire2_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_weight)\n",
    "d_fire2_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_bias)\n",
    "d_fire2_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_weight)\n",
    "d_fire2_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_bias)\n",
    "\n",
    "d_fire3_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_squeeze_weight)\n",
    "d_fire3_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_squeeze_bias)\n",
    "d_fire3_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand1x1_weight)\n",
    "d_fire3_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand1x1_bias)\n",
    "d_fire3_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand3x3_weight)\n",
    "d_fire3_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand3x3_bias)\n",
    "\n",
    "d_fire4_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_squeeze_weight)\n",
    "d_fire4_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_squeeze_bias)\n",
    "d_fire4_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand1x1_weight)\n",
    "d_fire4_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand1x1_bias)\n",
    "d_fire4_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand3x3_weight)\n",
    "d_fire4_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand3x3_bias)\n",
    "\n",
    "d_fire5_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_squeeze_weight)\n",
    "d_fire5_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_squeeze_bias)\n",
    "d_fire5_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand1x1_weight)\n",
    "d_fire5_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand1x1_bias)\n",
    "d_fire5_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand3x3_weight)\n",
    "d_fire5_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand3x3_bias)\n",
    "\n",
    "d_fire6_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_squeeze_weight)\n",
    "d_fire6_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_squeeze_bias)\n",
    "d_fire6_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand1x1_weight)\n",
    "d_fire6_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand1x1_bias)\n",
    "d_fire6_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand3x3_weight)\n",
    "d_fire6_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand3x3_bias)\n",
    "\n",
    "d_fire7_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_squeeze_weight)\n",
    "d_fire7_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_squeeze_bias)\n",
    "d_fire7_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand1x1_weight)\n",
    "d_fire7_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand1x1_bias)\n",
    "d_fire7_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand3x3_weight)\n",
    "d_fire7_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand3x3_bias)\n",
    "\n",
    "d_fire8_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_squeeze_weight)\n",
    "d_fire8_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_squeeze_bias)\n",
    "d_fire8_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand1x1_weight)\n",
    "d_fire8_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand1x1_bias)\n",
    "d_fire8_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand3x3_weight)\n",
    "d_fire8_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand3x3_bias)\n",
    "\n",
    "d_classifier_conv_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=classifier_conv_weight)\n",
    "d_classifier_conv_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=classifier_conv_bias)\n",
    "\n",
    "d_result_conv = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_conv.nbytes)\n",
    "d_result_pool1 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool1.nbytes)\n",
    "\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "d_result_fire2_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_squeeze.nbytes)\n",
    "d_result_fire2_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_expand.nbytes)\n",
    "d_result_pool2 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool2.nbytes)\n",
    "\n",
    "d_result_fire3_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire3_squeeze.nbytes)\n",
    "d_result_fire3_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire3_expand.nbytes)\n",
    "d_result_fire4_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire4_squeeze.nbytes)\n",
    "d_result_fire4_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire4_expand.nbytes)\n",
    "d_result_pool3 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool3.nbytes)\n",
    "\n",
    "d_result_fire5_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire5_squeeze.nbytes)\n",
    "d_result_fire5_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire5_expand.nbytes)\n",
    "d_result_fire6_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire6_squeeze.nbytes)\n",
    "d_result_fire6_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire6_expand.nbytes)\n",
    "d_result_fire7_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire7_squeeze.nbytes)\n",
    "d_result_fire7_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire7_expand.nbytes)\n",
    "d_result_fire8_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire8_squeeze.nbytes)\n",
    "d_result_fire8_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire8_expand.nbytes)\n",
    "\n",
    "d_result_classifier_conv = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_classifier_conv.nbytes)\n",
    "d_result_classifier = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_classifier.nbytes)\n",
    "\n",
    "tic3 = pc()\n",
    "\n",
    "#first conv layer\n",
    "conv3x3_ST(queue,(1,), None, 3, 224, 0, 2, 0, 111, 64, d_sample, d_conv1_weight, d_conv1_bias, d_result_conv)\n",
    "maxpool_ST(queue, (1, ), None, 111, 55, 64, d_result_conv, d_result_pool1)\n",
    "\n",
    "#block1\n",
    "conv1x1_ST(queue,(1,), None, 64, 55, 16, d_result_pool1, d_fire1_squeeze_weight, d_fire1_squeeze_bias, d_result_fire1_squeeze)\n",
    "queue.finish()\n",
    "conv1x1_ST(queue1,(1,), None, 16, 55, 64, d_result_fire1_squeeze, d_fire1_expand1x1_weight, d_fire1_expand1x1_bias, d_result_fire1_expand)\n",
    "conv3x3_ST(queue,(1,), None, 16, 55, 1, 1, 64, 55, 64, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, 128, 55, 16, d_result_fire1_expand, d_fire2_squeeze_weight, d_fire2_squeeze_bias, d_result_fire2_squeeze)\n",
    "queue.finish()\n",
    "conv1x1_ST(queue1,(1,), None, 16, 55, 64, d_result_fire2_squeeze, d_fire2_expand1x1_weight, d_fire2_expand1x1_bias, d_result_fire2_expand)\n",
    "conv3x3_ST(queue,(1,), None, 16, 55, 1, 1, 64, 55, 64, d_result_fire2_squeeze, d_fire2_expand3x3_weight, d_fire2_expand3x3_bias, d_result_fire2_expand)\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "maxpool_ST(queue, (1, ), None, 55, 27, 128, d_result_fire2_expand, d_result_pool2)\n",
    "\n",
    "#block2\n",
    "conv1x1_ST(queue,(1,), None, 128, 27, 32, d_result_pool2, d_fire3_squeeze_weight, d_fire3_squeeze_bias, d_result_fire3_squeeze)\n",
    "queue.finish()\n",
    "conv1x1_ST(queue1,(1,), None, 32, 27, 128, d_result_fire3_squeeze, d_fire3_expand1x1_weight, d_fire3_expand1x1_bias, d_result_fire3_expand)\n",
    "conv3x3_ST(queue,(1,), None, 32, 27, 1, 1, 128, 27, 128, d_result_fire3_squeeze, d_fire3_expand3x3_weight, d_fire3_expand3x3_bias, d_result_fire3_expand)\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, 256, 27, 32, d_result_fire3_expand, d_fire4_squeeze_weight, d_fire4_squeeze_bias, d_result_fire4_squeeze)\n",
    "queue.finish()\n",
    "conv1x1_ST(queue1,(1,), None, 32, 27, 128, d_result_fire4_squeeze, d_fire4_expand1x1_weight, d_fire4_expand1x1_bias, d_result_fire4_expand)\n",
    "conv3x3_ST(queue,(1,), None, 32, 27, 1, 1, 128, 27, 128, d_result_fire4_squeeze, d_fire4_expand3x3_weight, d_fire4_expand3x3_bias, d_result_fire4_expand)\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "maxpool_ST(queue, (1, ), None, 27, 13, 256, d_result_fire4_expand, d_result_pool3)\n",
    "\n",
    "#block3\n",
    "conv1x1_ST(queue,(1,), None, 256, 13, 48, d_result_pool3, d_fire5_squeeze_weight, d_fire5_squeeze_bias, d_result_fire5_squeeze)\n",
    "queue.finish()\n",
    "conv1x1_ST(queue1,(1,), None, 48, 13, 192, d_result_fire5_squeeze, d_fire5_expand1x1_weight, d_fire5_expand1x1_bias, d_result_fire5_expand)\n",
    "conv3x3_ST(queue,(1,), None, 48, 13, 1, 1, 192, 13, 192, d_result_fire5_squeeze, d_fire5_expand3x3_weight, d_fire5_expand3x3_bias, d_result_fire5_expand)\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, 384, 13, 48, d_result_fire5_expand, d_fire6_squeeze_weight, d_fire6_squeeze_bias, d_result_fire6_squeeze)\n",
    "queue.finish()\n",
    "conv1x1_ST(queue1,(1,), None, 48, 13, 192, d_result_fire6_squeeze, d_fire6_expand1x1_weight, d_fire6_expand1x1_bias, d_result_fire6_expand)\n",
    "conv3x3_ST(queue,(1,), None, 48, 13, 1, 1, 192, 13, 192, d_result_fire6_squeeze, d_fire6_expand3x3_weight, d_fire6_expand3x3_bias, d_result_fire6_expand)\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, 384, 13, 64, d_result_fire6_expand, d_fire7_squeeze_weight, d_fire7_squeeze_bias, d_result_fire7_squeeze)\n",
    "queue.finish()\n",
    "conv1x1_ST(queue1,(1,), None, 64, 13, 256, d_result_fire7_squeeze, d_fire7_expand1x1_weight, d_fire7_expand1x1_bias, d_result_fire7_expand)\n",
    "conv3x3_ST(queue,(1,), None, 64, 13, 1, 1, 256, 13, 256, d_result_fire7_squeeze, d_fire7_expand3x3_weight, d_fire7_expand3x3_bias, d_result_fire7_expand)\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, 512, 13, 64, d_result_fire7_expand, d_fire8_squeeze_weight, d_fire8_squeeze_bias, d_result_fire8_squeeze)\n",
    "queue.finish()\n",
    "conv1x1_ST(queue1,(1,), None, 64, 13, 256, d_result_fire8_squeeze, d_fire8_expand1x1_weight, d_fire8_expand1x1_bias, d_result_fire8_expand)\n",
    "conv3x3_ST(queue,(1,), None, 64, 13, 1, 1, 256, 13, 256, d_result_fire8_squeeze, d_fire8_expand3x3_weight, d_fire8_expand3x3_bias, d_result_fire8_expand)\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "# classifier\n",
    "conv1x1_ST(queue,(1,), None, 512, 13, 1000, d_result_fire8_expand, d_classifier_conv_weight, d_classifier_conv_bias, d_result_classifier_conv)\n",
    "\n",
    "avgpool_ST(queue, (1, ), None, d_result_classifier_conv, d_result_classifier)\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_classifier, d_result_classifier)\n",
    "\n",
    "veamos1 = h_result_classifier\n",
    "\n",
    "rtime1 = pc() - tic3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo en segundos con pytorch=  0.0030234180003390065\n",
      "tiempo en segundos con opencl (NDRANGE)= 0.03991814599976351\n",
      "tiempo en segundos con opencl (Simple Task)= 0.04235464699922886\n",
      "comparativa (pytorch == NDRange):  True\n",
      "comparativa (pytorch == Simple Task):  True\n",
      "comparativa (NDRange == Simple Task):  True\n"
     ]
    }
   ],
   "source": [
    "print (\"tiempo en segundos con pytorch= \", toc-tic)\n",
    "print (\"tiempo en segundos con opencl (NDRANGE)=\",rtime)\n",
    "print (\"tiempo en segundos con opencl (Simple Task)=\",rtime1)\n",
    "\n",
    "comparativa1=np.allclose(salida18_a_numpy.reshape(-1), veamos,rtol=1e-01, atol=1e-01)\n",
    "comparativa2=np.allclose(salida18_a_numpy.reshape(-1), veamos1,rtol=1e-01, atol=1e-01)\n",
    "comparativa3=np.allclose(veamos, veamos1,rtol=1e-01, atol=1e-01)\n",
    "\n",
    "print(\"comparativa (pytorch == NDRange): \",comparativa1)\n",
    "print(\"comparativa (pytorch == Simple Task): \",comparativa2)\n",
    "print(\"comparativa (NDRange == Simple Task): \",comparativa3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    if (abs(salida18_a_numpy.reshape(-1)[i] - veamos1[i])) > 1e-01:\n",
    "        print(\"i:\", i, salida18_a_numpy.reshape(-1)[i], veamos1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo en segundos con pytorch=  0.05108882825000819\n",
      "tiempo en segundos con opencl (Simple Task)= 0.028037996070006555\n",
      "comparativa (pytorch == Simple Task):  True\n"
     ]
    }
   ],
   "source": [
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "count = 100\n",
    "acumulado_pytorch=0\n",
    "acumulado_kernel=0\n",
    "comparativa = True\n",
    "\n",
    "#####################################################\n",
    "\n",
    "params = torch.load('squeezenet1_1.pth')\n",
    "\n",
    "### First Conv3x3 and maxpool\n",
    "weights0=params['features.0.weight'].numpy()\n",
    "bias0=params['features.0.bias'].numpy()\n",
    "\n",
    "######## BLOCK 1 ########\n",
    "#fire - fire - maxpool\n",
    "#### FIRE 1 ####\n",
    "weights1=params['features.3.squeeze.weight'].numpy()\n",
    "bias1=params['features.3.squeeze.bias'].numpy()\n",
    "\n",
    "weights2a=params['features.3.expand1x1.weight'].numpy()\n",
    "bias2a=params['features.3.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights2b=params['features.3.expand3x3.weight'].numpy()   \n",
    "bias2b=params['features.3.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 2 ####\n",
    "weights3=params['features.4.squeeze.weight'].numpy()\n",
    "bias3=params['features.4.squeeze.bias'].numpy()\n",
    "\n",
    "weights4a=params['features.4.expand1x1.weight'].numpy()\n",
    "bias4a=params['features.4.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights4b=params['features.4.expand3x3.weight'].numpy()   \n",
    "bias4b=params['features.4.expand3x3.bias'].numpy()\n",
    "\n",
    "######## BLOCK 2 ########\n",
    "#fire - fire - maxpool\n",
    "#### FIRE 3 ####\n",
    "weights5=params['features.6.squeeze.weight'].numpy()\n",
    "bias5=params['features.6.squeeze.bias'].numpy()\n",
    "\n",
    "weights6a=params['features.6.expand1x1.weight'].numpy()\n",
    "bias6a=params['features.6.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights6b=params['features.6.expand3x3.weight'].numpy()   \n",
    "bias6b=params['features.6.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 4 ####\n",
    "weights7=params['features.7.squeeze.weight'].numpy()\n",
    "bias7=params['features.7.squeeze.bias'].numpy()\n",
    "\n",
    "weights8a=params['features.7.expand1x1.weight'].numpy()\n",
    "bias8a=params['features.7.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights8b=params['features.7.expand3x3.weight'].numpy()  \n",
    "bias8b=params['features.7.expand3x3.bias'].numpy()\n",
    "\n",
    "######## BLOCK 3 ########\n",
    "#fire - fire - fire - fire\n",
    "#### FIRE 5 ####\n",
    "weights9=params['features.9.squeeze.weight'].numpy()\n",
    "bias9=params['features.9.squeeze.bias'].numpy()\n",
    "\n",
    "weights10a=params['features.9.expand1x1.weight'].numpy()\n",
    "bias10a=params['features.9.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights10b=params['features.9.expand3x3.weight'].numpy()\n",
    "bias10b=params['features.9.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 6 ####\n",
    "weights11=params['features.10.squeeze.weight'].numpy()\n",
    "bias11=params['features.10.squeeze.bias'].numpy()\n",
    "\n",
    "weights12a=params['features.10.expand1x1.weight'].numpy()\n",
    "bias12a=params['features.10.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights12b=params['features.10.expand3x3.weight'].numpy()\n",
    "bias12b=params['features.10.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 7 ####\n",
    "weights13=params['features.11.squeeze.weight'].numpy()\n",
    "bias13=params['features.11.squeeze.bias'].numpy()\n",
    "\n",
    "weights14a=params['features.11.expand1x1.weight'].numpy()\n",
    "bias14a=params['features.11.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights14b=params['features.11.expand3x3.weight'].numpy()\n",
    "bias14b=params['features.11.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 8 ####\n",
    "weights15=params['features.12.squeeze.weight'].numpy()\n",
    "bias15=params['features.12.squeeze.bias'].numpy()\n",
    "\n",
    "weights16a=params['features.12.expand1x1.weight'].numpy()\n",
    "bias16a=params['features.12.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights16b=params['features.12.expand3x3.weight'].numpy()\n",
    "bias16b=params['features.12.expand3x3.bias'].numpy()\n",
    "\n",
    "######## Classifier ########\n",
    "#conv3x3 - avgpool\n",
    "### Classifier Conv3x3 and avgpool\n",
    "weights17=params['classifier.1.weight'].numpy()\n",
    "bias17=params['classifier.1.bias'].numpy()\n",
    "\n",
    "for i in range(count):\n",
    "   \n",
    "\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [ 0.485, 0.456, 0.406 ],\n",
    "                         std = [ 0.229, 0.224, 0.225 ]),])\n",
    "\n",
    "    imagen = np.random.rand(3, 224, 224).astype(np.float32)\n",
    "    imagen = Image.fromarray(imagen,'RGB')\n",
    "    imagen = transform(imagen).numpy()\n",
    "    imagen = imagen[np.newaxis,:]\n",
    "\n",
    "    #imagen = np.ones((1, 3, 224, 224))\n",
    "    #print(imagen.shape)\n",
    "\n",
    "    tic=pc()\n",
    "\n",
    "    squeeze0=nn.Conv2d(3, 64, kernel_size=3, bias=False, stride=2)\n",
    "    squeeze0.weight = nn.Parameter(torch.from_numpy(weights0))\n",
    "    squeeze0.bias = nn.Parameter(torch.from_numpy(bias0))\n",
    "\n",
    "    maxpool=nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "    squeeze1=nn.Conv2d(64, 16, kernel_size=1, bias=False)\n",
    "    squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "    squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))    \n",
    "\n",
    "    squeeze2a=nn.Conv2d(16, 64, kernel_size=1, bias=False)\n",
    "    squeeze2a.weight = nn.Parameter(torch.from_numpy(weights2a))\n",
    "    squeeze2a.bias = nn.Parameter(torch.from_numpy(bias2a))\n",
    "\n",
    "    squeeze2b=nn.Conv2d(16, 64, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze2b.weight = nn.Parameter(torch.from_numpy(weights2b))\n",
    "    squeeze2b.bias = nn.Parameter(torch.from_numpy(bias2b))\n",
    "\n",
    "    squeeze3=nn.Conv2d(128, 16, kernel_size=1, bias=False)\n",
    "    squeeze3.weight = nn.Parameter(torch.from_numpy(weights3))\n",
    "    squeeze3.bias = nn.Parameter(torch.from_numpy(bias3))    \n",
    "\n",
    "    squeeze4a=nn.Conv2d(16, 64, kernel_size=1, bias=False)\n",
    "    squeeze4a.weight = nn.Parameter(torch.from_numpy(weights4a))\n",
    "    squeeze4a.bias = nn.Parameter(torch.from_numpy(bias4a))\n",
    "\n",
    "    squeeze4b=nn.Conv2d(16, 64, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze4b.weight = nn.Parameter(torch.from_numpy(weights4b))\n",
    "    squeeze4b.bias = nn.Parameter(torch.from_numpy(bias4b))\n",
    "\n",
    "    squeeze5=nn.Conv2d(128, 32, kernel_size=1, bias=False)\n",
    "    squeeze5.weight = nn.Parameter(torch.from_numpy(weights5))\n",
    "    squeeze5.bias = nn.Parameter(torch.from_numpy(bias5))    \n",
    "\n",
    "    squeeze6a=nn.Conv2d(32, 128, kernel_size=1, bias=False)\n",
    "    squeeze6a.weight = nn.Parameter(torch.from_numpy(weights6a))\n",
    "    squeeze6a.bias = nn.Parameter(torch.from_numpy(bias6a))\n",
    "\n",
    "    squeeze6b=nn.Conv2d(32, 128, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze6b.weight = nn.Parameter(torch.from_numpy(weights6b))\n",
    "    squeeze6b.bias = nn.Parameter(torch.from_numpy(bias6b))\n",
    "\n",
    "    squeeze7=nn.Conv2d(256, 32, kernel_size=1, bias=False)\n",
    "    squeeze7.weight = nn.Parameter(torch.from_numpy(weights7))\n",
    "    squeeze7.bias = nn.Parameter(torch.from_numpy(bias7))    \n",
    "\n",
    "    squeeze8a=nn.Conv2d(32, 128, kernel_size=1, bias=False)\n",
    "    squeeze8a.weight = nn.Parameter(torch.from_numpy(weights8a))\n",
    "    squeeze8a.bias = nn.Parameter(torch.from_numpy(bias8a))\n",
    "\n",
    "    squeeze8b=nn.Conv2d(32, 128, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze8b.weight = nn.Parameter(torch.from_numpy(weights8b))\n",
    "    squeeze8b.bias = nn.Parameter(torch.from_numpy(bias8b))\n",
    "\n",
    "    squeeze9=nn.Conv2d(256, 48, kernel_size=1, bias=False)\n",
    "    squeeze9.weight = nn.Parameter(torch.from_numpy(weights9))\n",
    "    squeeze9.bias = nn.Parameter(torch.from_numpy(bias9))    \n",
    "\n",
    "    squeeze10a=nn.Conv2d(48, 192, kernel_size=1, bias=False)\n",
    "    squeeze10a.weight = nn.Parameter(torch.from_numpy(weights10a))\n",
    "    squeeze10a.bias = nn.Parameter(torch.from_numpy(bias10a))\n",
    "\n",
    "    squeeze10b=nn.Conv2d(48, 192, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze10b.weight = nn.Parameter(torch.from_numpy(weights10b))\n",
    "    squeeze10b.bias = nn.Parameter(torch.from_numpy(bias10b))\n",
    "\n",
    "    squeeze11=nn.Conv2d(384, 48, kernel_size=1, bias=False)\n",
    "    squeeze11.weight = nn.Parameter(torch.from_numpy(weights11))\n",
    "    squeeze11.bias = nn.Parameter(torch.from_numpy(bias11))    \n",
    "\n",
    "    squeeze12a=nn.Conv2d(48, 192, kernel_size=1, bias=False)\n",
    "    squeeze12a.weight = nn.Parameter(torch.from_numpy(weights12a))\n",
    "    squeeze12a.bias = nn.Parameter(torch.from_numpy(bias12a))\n",
    "\n",
    "    squeeze12b=nn.Conv2d(48, 192, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze12b.weight = nn.Parameter(torch.from_numpy(weights12b))\n",
    "    squeeze12b.bias = nn.Parameter(torch.from_numpy(bias12b))\n",
    "\n",
    "    squeeze13=nn.Conv2d(384, 64, kernel_size=1, bias=False)\n",
    "    squeeze13.weight = nn.Parameter(torch.from_numpy(weights13))\n",
    "    squeeze13.bias = nn.Parameter(torch.from_numpy(bias13))    \n",
    "\n",
    "    squeeze14a=nn.Conv2d(64, 256, kernel_size=1, bias=False)\n",
    "    squeeze14a.weight = nn.Parameter(torch.from_numpy(weights14a))\n",
    "    squeeze14a.bias = nn.Parameter(torch.from_numpy(bias14a))\n",
    "\n",
    "    squeeze14b=nn.Conv2d(64, 256, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze14b.weight = nn.Parameter(torch.from_numpy(weights14b))\n",
    "    squeeze14b.bias = nn.Parameter(torch.from_numpy(bias14b))\n",
    "\n",
    "    squeeze15=nn.Conv2d(512, 64, kernel_size=1, bias=False)\n",
    "    squeeze15.weight = nn.Parameter(torch.from_numpy(weights15))\n",
    "    squeeze15.bias = nn.Parameter(torch.from_numpy(bias15))    \n",
    "\n",
    "    squeeze16a=nn.Conv2d(64, 256, kernel_size=1, bias=False)\n",
    "    squeeze16a.weight = nn.Parameter(torch.from_numpy(weights16a))\n",
    "    squeeze16a.bias = nn.Parameter(torch.from_numpy(bias16a))\n",
    "\n",
    "    squeeze16b=nn.Conv2d(64, 256, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze16b.weight = nn.Parameter(torch.from_numpy(weights16b))\n",
    "    squeeze16b.bias = nn.Parameter(torch.from_numpy(bias16b))\n",
    "\n",
    "    conv_class=nn.Conv2d(512, 1000, kernel_size=1, bias=False)\n",
    "    conv_class.weight = nn.Parameter(torch.from_numpy(weights17))\n",
    "    conv_class.bias = nn.Parameter(torch.from_numpy(bias17))\n",
    "\n",
    "    avgpool=nn.AvgPool2d(13)\n",
    "\n",
    "    imagen1  = torch.from_numpy(imagen).float()\n",
    "\n",
    "    salida0=squeeze0(imagen1)\n",
    "    salida0_activation=squeeze_activation(salida0)\n",
    "\n",
    "    salida_pool1 = maxpool(salida0_activation)\n",
    "\n",
    "    salida1=squeeze1(salida_pool1)\n",
    "    salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "    salida2a=squeeze2a(salida1_activation)\n",
    "    salida2a_activation=squeeze_activation(salida2a)\n",
    "    salida2b=squeeze2b(salida1_activation)\n",
    "    salida2b_activation=squeeze_activation(salida2b)    \n",
    "    salida2_total=torch.cat([salida2a_activation,salida2b_activation], 1)\n",
    "\n",
    "    salida3=squeeze3(salida2_total)\n",
    "    salida3_activation=squeeze_activation(salida3)\n",
    "\n",
    "    salida4a=squeeze4a(salida3_activation)\n",
    "    salida4a_activation=squeeze_activation(salida4a)\n",
    "    salida4b=squeeze4b(salida3_activation)\n",
    "    salida4b_activation=squeeze_activation(salida4b)    \n",
    "    salida4_total=torch.cat([salida4a_activation,salida4b_activation], 1)\n",
    "\n",
    "    salida_pool2 = maxpool(salida4_total)\n",
    "\n",
    "    salida5=squeeze5(salida_pool2)\n",
    "    salida5_activation=squeeze_activation(salida5)\n",
    "\n",
    "    salida6a=squeeze6a(salida5_activation)\n",
    "    salida6a_activation=squeeze_activation(salida6a)\n",
    "    salida6b=squeeze6b(salida5_activation)\n",
    "    salida6b_activation=squeeze_activation(salida6b)    \n",
    "    salida6_total=torch.cat([salida6a_activation,salida6b_activation], 1)\n",
    "\n",
    "    salida7=squeeze7(salida6_total)\n",
    "    salida7_activation=squeeze_activation(salida7)\n",
    "\n",
    "    salida8a=squeeze8a(salida7_activation)\n",
    "    salida8a_activation=squeeze_activation(salida8a)\n",
    "    salida8b=squeeze8b(salida7_activation)\n",
    "    salida8b_activation=squeeze_activation(salida8b)    \n",
    "    salida8_total=torch.cat([salida8a_activation,salida8b_activation], 1)\n",
    "\n",
    "    salida_pool3 = maxpool(salida8_total)\n",
    "\n",
    "    salida9=squeeze9(salida_pool3)\n",
    "    salida9_activation=squeeze_activation(salida9)\n",
    "\n",
    "    salida10a=squeeze10a(salida9_activation)\n",
    "    salida10a_activation=squeeze_activation(salida10a)\n",
    "    salida10b=squeeze10b(salida9_activation)\n",
    "    salida10b_activation=squeeze_activation(salida10b)    \n",
    "    salida10_total=torch.cat([salida10a_activation,salida10b_activation], 1)\n",
    "\n",
    "    salida11=squeeze11(salida10_total)\n",
    "    salida11_activation=squeeze_activation(salida11)\n",
    "\n",
    "    salida12a=squeeze12a(salida11_activation)\n",
    "    salida12a_activation=squeeze_activation(salida12a)\n",
    "    salida12b=squeeze12b(salida11_activation)\n",
    "    salida12b_activation=squeeze_activation(salida12b)    \n",
    "    salida12_total=torch.cat([salida12a_activation,salida12b_activation], 1)\n",
    "\n",
    "    salida13=squeeze13(salida12_total)\n",
    "    salida13_activation=squeeze_activation(salida13)\n",
    "\n",
    "    salida14a=squeeze14a(salida13_activation)\n",
    "    salida14a_activation=squeeze_activation(salida14a)\n",
    "    salida14b=squeeze14b(salida13_activation)\n",
    "    salida14b_activation=squeeze_activation(salida14b)    \n",
    "    salida14_total=torch.cat([salida14a_activation,salida14b_activation], 1)\n",
    "\n",
    "    salida15=squeeze15(salida14_total)\n",
    "    salida15_activation=squeeze_activation(salida15)\n",
    "\n",
    "    salida16a=squeeze16a(salida15_activation)\n",
    "    salida16a_activation=squeeze_activation(salida16a)\n",
    "    salida16b=squeeze16b(salida15_activation)\n",
    "    salida16b_activation=squeeze_activation(salida16b)    \n",
    "    salida16_total=torch.cat([salida16a_activation,salida16b_activation], 1)\n",
    "\n",
    "    salida17=conv_class(salida16_total)\n",
    "    salida17_activation=squeeze_activation(salida17)\n",
    "    salida18=avgpool(salida17_activation)\n",
    "\n",
    "    salida18_a_numpy=salida18.detach().numpy()\n",
    "\n",
    "    toc=pc()\n",
    "\n",
    "    acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "\n",
    "    ####### OPENCL COMPARISON #######\n",
    "                               \n",
    "    # NDRANGE\n",
    "    h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "    d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "    conv1_weight = weights0.reshape(-1)\n",
    "    conv1_bias = bias0\n",
    "\n",
    "    fire1_squeeze_weight = weights1.reshape(-1)\n",
    "    fire1_squeeze_bias = bias1\n",
    "    fire1_expand1x1_weight = weights2a.reshape(-1)\n",
    "    fire1_expand1x1_bias = bias2a\n",
    "    fire1_expand3x3_weight =weights2b.reshape(-1)\n",
    "    fire1_expand3x3_bias = bias2b\n",
    "\n",
    "    fire2_squeeze_weight = weights3.reshape(-1)\n",
    "    fire2_squeeze_bias = bias3\n",
    "    fire2_expand1x1_weight = weights4a.reshape(-1)\n",
    "    fire2_expand1x1_bias = bias4a\n",
    "    fire2_expand3x3_weight =weights4b.reshape(-1)\n",
    "    fire2_expand3x3_bias = bias4b\n",
    "\n",
    "    fire3_squeeze_weight = weights5.reshape(-1)\n",
    "    fire3_squeeze_bias = bias5\n",
    "    fire3_expand1x1_weight = weights6a.reshape(-1)\n",
    "    fire3_expand1x1_bias = bias6a\n",
    "    fire3_expand3x3_weight =weights6b.reshape(-1)\n",
    "    fire3_expand3x3_bias = bias6b\n",
    "\n",
    "    fire4_squeeze_weight = weights7.reshape(-1)\n",
    "    fire4_squeeze_bias = bias7\n",
    "    fire4_expand1x1_weight = weights8a.reshape(-1)\n",
    "    fire4_expand1x1_bias = bias8a\n",
    "    fire4_expand3x3_weight =weights8b.reshape(-1)\n",
    "    fire4_expand3x3_bias = bias8b\n",
    "\n",
    "    fire5_squeeze_weight = weights9.reshape(-1)\n",
    "    fire5_squeeze_bias = bias9\n",
    "    fire5_expand1x1_weight = weights10a.reshape(-1)\n",
    "    fire5_expand1x1_bias = bias10a\n",
    "    fire5_expand3x3_weight =weights10b.reshape(-1)\n",
    "    fire5_expand3x3_bias = bias10b\n",
    "\n",
    "    fire6_squeeze_weight = weights11.reshape(-1)\n",
    "    fire6_squeeze_bias = bias11\n",
    "    fire6_expand1x1_weight = weights12a.reshape(-1)\n",
    "    fire6_expand1x1_bias = bias12a\n",
    "    fire6_expand3x3_weight =weights12b.reshape(-1)\n",
    "    fire6_expand3x3_bias = bias12b\n",
    "\n",
    "    fire7_squeeze_weight = weights13.reshape(-1)\n",
    "    fire7_squeeze_bias = bias13\n",
    "    fire7_expand1x1_weight = weights14a.reshape(-1)\n",
    "    fire7_expand1x1_bias = bias14a\n",
    "    fire7_expand3x3_weight =weights14b.reshape(-1)\n",
    "    fire7_expand3x3_bias = bias14b\n",
    "\n",
    "    fire8_squeeze_weight = weights15.reshape(-1)\n",
    "    fire8_squeeze_bias = bias15\n",
    "    fire8_expand1x1_weight = weights16a.reshape(-1)\n",
    "    fire8_expand1x1_bias = bias16a\n",
    "    fire8_expand3x3_weight =weights16b.reshape(-1)\n",
    "    fire8_expand3x3_bias = bias16b\n",
    "\n",
    "    classifier_conv_weight = weights17.reshape(-1)\n",
    "    classifier_conv_bias = bias17\n",
    "\n",
    "    h_result_conv = np.empty(1 * 64 * 111 * 111).astype(np.float32)\n",
    "    h_result_pool1 = np.empty(1 * 64 * 55 * 55).astype(np.float32)\n",
    "\n",
    "    h_result_fire1_squeeze = np.empty(1 * 16 * 55 * 55).astype(np.float32)\n",
    "    h_result_fire1_expand = np.empty(1 * 128 * 55 * 55).astype(np.float32)\n",
    "    h_result_fire2_squeeze = np.empty(1 * 16 * 55 * 55).astype(np.float32)\n",
    "    h_result_fire2_expand = np.empty(1 * 128 * 55 * 55).astype(np.float32)\n",
    "    h_result_pool2 = np.empty(1 * 128 * 27 * 27).astype(np.float32)\n",
    "\n",
    "    h_result_fire3_squeeze = np.empty(1 * 32 * 27 * 27).astype(np.float32)\n",
    "    h_result_fire3_expand = np.empty(1 * 256 * 27 * 27).astype(np.float32)\n",
    "    h_result_fire4_squeeze = np.empty(1 * 32 * 27 * 27).astype(np.float32)\n",
    "    h_result_fire4_expand = np.empty(1 * 256 * 27 * 27).astype(np.float32)\n",
    "    h_result_pool3 = np.empty(1 * 256 * 13 * 13).astype(np.float32)\n",
    "\n",
    "    h_result_fire5_squeeze = np.empty(1 * 48 * 13 * 13).astype(np.float32)\n",
    "    h_result_fire5_expand = np.empty(1 * 384 * 13 * 13).astype(np.float32)\n",
    "    h_result_fire6_squeeze = np.empty(1 * 48 * 13 * 13).astype(np.float32)\n",
    "    h_result_fire6_expand = np.empty(1 * 384 * 13 * 13).astype(np.float32)\n",
    "    h_result_fire7_squeeze = np.empty(1 * 64 * 13 * 13).astype(np.float32)\n",
    "    h_result_fire7_expand = np.empty(1 * 512 * 13 * 13).astype(np.float32)\n",
    "    h_result_fire8_squeeze = np.empty(1 * 64 * 13 * 13).astype(np.float32)\n",
    "    h_result_fire8_expand = np.empty(1 * 512 * 13 * 13).astype(np.float32)\n",
    "\n",
    "    h_result_classifier_conv = np.empty(1 * 1000 * 13 * 13).astype(np.float32)\n",
    "    h_result_classifier = np.empty(1 * 1000).astype(np.float32)\n",
    "\n",
    "    d_conv1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=conv1_weight)\n",
    "    d_conv1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=conv1_bias)\n",
    "\n",
    "    d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "    d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "    d_fire1_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_weight)\n",
    "    d_fire1_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_bias)\n",
    "    d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "    d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "    d_fire2_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_weight)\n",
    "    d_fire2_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_bias)\n",
    "    d_fire2_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_weight)\n",
    "    d_fire2_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_bias)\n",
    "    d_fire2_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_weight)\n",
    "    d_fire2_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_bias)\n",
    "\n",
    "    d_fire3_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_squeeze_weight)\n",
    "    d_fire3_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_squeeze_bias)\n",
    "    d_fire3_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand1x1_weight)\n",
    "    d_fire3_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand1x1_bias)\n",
    "    d_fire3_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand3x3_weight)\n",
    "    d_fire3_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand3x3_bias)\n",
    "\n",
    "    d_fire4_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_squeeze_weight)\n",
    "    d_fire4_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_squeeze_bias)\n",
    "    d_fire4_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand1x1_weight)\n",
    "    d_fire4_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand1x1_bias)\n",
    "    d_fire4_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand3x3_weight)\n",
    "    d_fire4_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand3x3_bias)\n",
    "\n",
    "    d_fire5_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_squeeze_weight)\n",
    "    d_fire5_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_squeeze_bias)\n",
    "    d_fire5_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand1x1_weight)\n",
    "    d_fire5_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand1x1_bias)\n",
    "    d_fire5_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand3x3_weight)\n",
    "    d_fire5_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand3x3_bias)\n",
    "\n",
    "    d_fire6_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_squeeze_weight)\n",
    "    d_fire6_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_squeeze_bias)\n",
    "    d_fire6_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand1x1_weight)\n",
    "    d_fire6_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand1x1_bias)\n",
    "    d_fire6_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand3x3_weight)\n",
    "    d_fire6_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand3x3_bias)\n",
    "\n",
    "    d_fire7_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_squeeze_weight)\n",
    "    d_fire7_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_squeeze_bias)\n",
    "    d_fire7_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand1x1_weight)\n",
    "    d_fire7_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand1x1_bias)\n",
    "    d_fire7_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand3x3_weight)\n",
    "    d_fire7_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand3x3_bias)\n",
    "\n",
    "    d_fire8_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_squeeze_weight)\n",
    "    d_fire8_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_squeeze_bias)\n",
    "    d_fire8_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand1x1_weight)\n",
    "    d_fire8_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand1x1_bias)\n",
    "    d_fire8_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand3x3_weight)\n",
    "    d_fire8_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand3x3_bias)\n",
    "\n",
    "    d_classifier_conv_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=classifier_conv_weight)\n",
    "    d_classifier_conv_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=classifier_conv_bias)\n",
    "\n",
    "    d_result_conv = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_conv.nbytes)\n",
    "    d_result_pool1 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool1.nbytes)\n",
    "\n",
    "    d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "    d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "    d_result_fire2_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_squeeze.nbytes)\n",
    "    d_result_fire2_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_expand.nbytes)\n",
    "    d_result_pool2 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool2.nbytes)\n",
    "\n",
    "    d_result_fire3_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire3_squeeze.nbytes)\n",
    "    d_result_fire3_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire3_expand.nbytes)\n",
    "    d_result_fire4_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire4_squeeze.nbytes)\n",
    "    d_result_fire4_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire4_expand.nbytes)\n",
    "    d_result_pool3 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool3.nbytes)\n",
    "\n",
    "    d_result_fire5_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire5_squeeze.nbytes)\n",
    "    d_result_fire5_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire5_expand.nbytes)\n",
    "    d_result_fire6_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire6_squeeze.nbytes)\n",
    "    d_result_fire6_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire6_expand.nbytes)\n",
    "    d_result_fire7_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire7_squeeze.nbytes)\n",
    "    d_result_fire7_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire7_expand.nbytes)\n",
    "    d_result_fire8_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire8_squeeze.nbytes)\n",
    "    d_result_fire8_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire8_expand.nbytes)\n",
    "\n",
    "    d_result_classifier_conv = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_classifier_conv.nbytes)\n",
    "    d_result_classifier = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_classifier.nbytes)\n",
    "\n",
    "    tic5 = pc()\n",
    "\n",
    "    #first conv layer\n",
    "    conv3x3_NDR(queue,(64, 111), None, 3, 224, 0, 2, 0, 111, d_sample, d_conv1_weight, d_conv1_bias, d_result_conv)\n",
    "    maxpool_NDR(queue, (64, ), None, 111, 55, d_result_conv, d_result_pool1)\n",
    "\n",
    "    #block1\n",
    "    conv1x1_NDR(queue,(16, 55), None, np.int32(64/4), 55, d_result_pool1, d_fire1_squeeze_weight, d_fire1_squeeze_bias, d_result_fire1_squeeze)\n",
    "    queue.finish()\n",
    "    conv1x1_NDR(queue1,(64, 55), None, np.int32(16/4), 55, d_result_fire1_squeeze, d_fire1_expand1x1_weight, d_fire1_expand1x1_bias, d_result_fire1_expand)\n",
    "    conv3x3_NDR(queue,(64, 55), None, 16, 55, 1, 1, 64, 55, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    conv1x1_NDR(queue,(16, 55), None, np.int32(128/4), 55, d_result_fire1_expand, d_fire2_squeeze_weight, d_fire2_squeeze_bias, d_result_fire2_squeeze)\n",
    "    queue.finish()\n",
    "    conv1x1_NDR(queue1,(64, 55), None, np.int32(16/4), 55, d_result_fire2_squeeze, d_fire2_expand1x1_weight, d_fire2_expand1x1_bias, d_result_fire2_expand)\n",
    "    conv3x3_NDR(queue,(64, 55), None, 16, 55, 1, 1, 64, 55, d_result_fire2_squeeze, d_fire2_expand3x3_weight, d_fire2_expand3x3_bias, d_result_fire2_expand)\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    maxpool_NDR(queue, (128, ), None, 55, 27, d_result_fire2_expand, d_result_pool2)\n",
    "\n",
    "    #block2\n",
    "    conv1x1_NDR(queue,(32, 27), None, np.int32(128/4), 27, d_result_pool2, d_fire3_squeeze_weight, d_fire3_squeeze_bias, d_result_fire3_squeeze)\n",
    "    queue.finish()\n",
    "    conv1x1_NDR(queue1,(128, 27), None, np.int32(32/4), 27, d_result_fire3_squeeze, d_fire3_expand1x1_weight, d_fire3_expand1x1_bias, d_result_fire3_expand)\n",
    "    conv3x3_NDR(queue,(128, 27), None, 32, 27, 1, 1, 128, 27, d_result_fire3_squeeze, d_fire3_expand3x3_weight, d_fire3_expand3x3_bias, d_result_fire3_expand)\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    conv1x1_NDR(queue,(32, 27), None, np.int32(256/4), 27, d_result_fire3_expand, d_fire4_squeeze_weight, d_fire4_squeeze_bias, d_result_fire4_squeeze)\n",
    "    queue.finish()\n",
    "    conv1x1_NDR(queue1,(128, 27), None, np.int32(32/4), 27, d_result_fire4_squeeze, d_fire4_expand1x1_weight, d_fire4_expand1x1_bias, d_result_fire4_expand)\n",
    "    conv3x3_NDR(queue,(128, 27), None, 32, 27, 1, 1, 128, 27, d_result_fire4_squeeze, d_fire4_expand3x3_weight, d_fire4_expand3x3_bias, d_result_fire4_expand)\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    maxpool_NDR(queue, (256, ), None, 27, 13, d_result_fire4_expand, d_result_pool3)\n",
    "\n",
    "    #block3\n",
    "    conv1x1_NDR(queue,(48, 13), None, np.int32(256/4), 13, d_result_pool3, d_fire5_squeeze_weight, d_fire5_squeeze_bias, d_result_fire5_squeeze)\n",
    "    queue.finish()\n",
    "    conv1x1_NDR(queue1,(192, 13), None, np.int32(48/4), 13, d_result_fire5_squeeze, d_fire5_expand1x1_weight, d_fire5_expand1x1_bias, d_result_fire5_expand)\n",
    "    conv3x3_NDR(queue,(192, 13), None, 48, 13, 1, 1, 192, 13, d_result_fire5_squeeze, d_fire5_expand3x3_weight, d_fire5_expand3x3_bias, d_result_fire5_expand)\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    conv1x1_NDR(queue,(48, 13), None, np.int32(384/4), 13, d_result_fire5_expand, d_fire6_squeeze_weight, d_fire6_squeeze_bias, d_result_fire6_squeeze)\n",
    "    queue.finish()\n",
    "    conv1x1_NDR(queue1,(192, 13), None, np.int32(48/4), 13, d_result_fire6_squeeze, d_fire6_expand1x1_weight, d_fire6_expand1x1_bias, d_result_fire6_expand)\n",
    "    conv3x3_NDR(queue,(192, 13), None, 48, 13, 1, 1, 192, 13, d_result_fire6_squeeze, d_fire6_expand3x3_weight, d_fire6_expand3x3_bias, d_result_fire6_expand)\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    conv1x1_NDR(queue,(64, 13), None, np.int32(384/4), 13, d_result_fire6_expand, d_fire7_squeeze_weight, d_fire7_squeeze_bias, d_result_fire7_squeeze)\n",
    "    queue.finish()\n",
    "    conv1x1_NDR(queue1,(256, 13), None, np.int32(64/4), 13, d_result_fire7_squeeze, d_fire7_expand1x1_weight, d_fire7_expand1x1_bias, d_result_fire7_expand)\n",
    "    conv3x3_NDR(queue,(256, 13), None, 64, 13, 1, 1, 256, 13, d_result_fire7_squeeze, d_fire7_expand3x3_weight, d_fire7_expand3x3_bias, d_result_fire7_expand)\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    conv1x1_NDR(queue,(64, 13), None, np.int32(512/4), 13, d_result_fire7_expand, d_fire8_squeeze_weight, d_fire8_squeeze_bias, d_result_fire8_squeeze)\n",
    "    queue.finish()\n",
    "    conv1x1_NDR(queue1,(256, 13), None, np.int32(64/4), 13, d_result_fire8_squeeze, d_fire8_expand1x1_weight, d_fire8_expand1x1_bias, d_result_fire8_expand)\n",
    "    conv3x3_NDR(queue,(256, 13), None, 64, 13, 1, 1, 256, 13, d_result_fire8_squeeze, d_fire8_expand3x3_weight, d_fire8_expand3x3_bias, d_result_fire8_expand)\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    # classifier\n",
    "    conv1x1_NDR(queue,(1000, 13), None, np.int32(512/4), 13, d_result_fire8_expand, d_classifier_conv_weight, d_classifier_conv_bias, d_result_classifier_conv)\n",
    "\n",
    "    avgpool_NDR(queue,(1000, ), None, d_result_classifier_conv, d_result_classifier)\n",
    "\n",
    "    cl.enqueue_copy(queue, h_result_classifier, d_result_classifier)\n",
    "\n",
    "    queue.finish()\n",
    "\n",
    "    veamos3 = h_result_classifier\n",
    "    \n",
    "    toc5 = pc()\n",
    "\n",
    "    acumulado_kernel = toc5 - tic5 + acumulado_kernel\n",
    "    \n",
    "    comparativa &= np.allclose(salida18_a_numpy.reshape(-1), veamos3,rtol=1e-01, atol=1e-01)\n",
    "    \n",
    "print (\"tiempo en segundos con pytorch= \", acumulado_pytorch/count)\n",
    "print (\"tiempo en segundos con opencl (NDRange)=\",acumulado_kernel/count)\n",
    "print(\"comparativa (pytorch == NDRange): \",comparativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (675052290.py, line 72)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 72\u001b[0;36m\u001b[0m\n\u001b[0;31m    tic=pc()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "queeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "count = 100\n",
    "acumulado_pytorch=0\n",
    "acumulado_kernel=0\n",
    "comparativa = True\n",
    "\n",
    "#####################################################\n",
    "\n",
    "params = torch.load('squeezenet1_1.pth')\n",
    "\n",
    "### First Conv3x3 and maxpool\n",
    "weights0=params['features.0.weight'].numpy()\n",
    "bias0=params['features.0.bias'].numpy()\n",
    "\n",
    "######## BLOCK 1 ########\n",
    "#fire - fire - maxpool\n",
    "#### FIRE 1 ####\n",
    "weights1=params['features.3.squeeze.weight'].numpy()\n",
    "bias1=params['features.3.squeeze.bias'].numpy()\n",
    "\n",
    "weights2a=params['features.3.expand1x1.weight'].numpy()\n",
    "bias2a=params['features.3.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights2b=params['features.3.expand3x3.weight'].numpy()   \n",
    "bias2b=params['features.3.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 2 ####\n",
    "weights3=params['features.4.squeeze.weight'].numpy()\n",
    "bias3=params['features.4.squeeze.bias'].numpy()\n",
    "\n",
    "weights4a=params['features.4.expand1x1.weight'].numpy()\n",
    "bias4a=params['features.4.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights4b=params['features.4.expand3x3.weight'].numpy()   \n",
    "bias4b=params['features.4.expand3x3.bias'].numpy()\n",
    "\n",
    "######## BLOCK 2 ########\n",
    "#fire - fire - maxpool\n",
    "#### FIRE 3 ####\n",
    "weights5=params['features.6.squeeze.weight'].numpy()\n",
    "bias5=params['features.6.squeeze.bias'].numpy()\n",
    "\n",
    "weights6a=params['features.6.expand1x1.weight'].numpy()\n",
    "bias6a=params['features.6.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights6b=params['features.6.expand3x3.weight'].numpy()   \n",
    "bias6b=params['features.6.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 4 ####\n",
    "weights7=params['features.7.squeeze.weight'].numpy()\n",
    "bias7=params['features.7.squeeze.bias'].numpy()\n",
    "\n",
    "weights8a=params['features.7.expand1x1.weight'].numpy()\n",
    "bias8a=params['features.7.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights8b=params['features.7.expand3x3.weight'].numpy()  \n",
    "bias8b=params['features.7.expand3x3.bias'].numpy()\n",
    "\n",
    "######## BLOCK 3 ########\n",
    "#fire - fire - fire - fire\n",
    "#### FIRE 5 ####\n",
    "weights9=params['features.9.squeeze.weight'].numpy()\n",
    "bias9=params['features.9.squeeze.bias'].numpy()\n",
    "\n",
    "weights10a=params['features.9.expand1x1.weight'].numpy()\n",
    "bias10a=params['features.9.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights10b=params['features.9.expand3x3.weight'].numpy()\n",
    "bias10b=params['features.9.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 6 ####\n",
    "weights11=params['features.10.squeeze.weight'].numpy()\n",
    "bias11=params['features.10.squeeze.bias'].numpy()\n",
    "\n",
    "weights12a=params['features.10.expand1x1.weight'].numpy()\n",
    "bias12a=params['features.10.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights12b=params['features.10.expand3x3.weight'].numpy()\n",
    "bias12b=params['features.10.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 7 ####\n",
    "weights13=params['features.11.squeeze.weight'].numpy()\n",
    "bias13=params['features.11.squeeze.bias'].numpy()\n",
    "\n",
    "weights14a=params['features.11.expand1x1.weight'].numpy()\n",
    "bias14a=params['features.11.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights14b=params['features.11.expand3x3.weight'].numpy()\n",
    "bias14b=params['features.11.expand3x3.bias'].numpy()\n",
    "\n",
    "#### FIRE 8 ####\n",
    "weights15=params['features.12.squeeze.weight'].numpy()\n",
    "bias15=params['features.12.squeeze.bias'].numpy()\n",
    "\n",
    "weights16a=params['features.12.expand1x1.weight'].numpy()\n",
    "bias16a=params['features.12.expand1x1.bias'].numpy()    \n",
    "\n",
    "weights16b=params['features.12.expand3x3.weight'].numpy()\n",
    "bias16b=params['features.12.expand3x3.bias'].numpy()\n",
    "\n",
    "######## Classifier ########\n",
    "#conv3x3 - avgpool\n",
    "### Classifier Conv3x3 and avgpool\n",
    "weights17=params['classifier.1.weight'].numpy()\n",
    "bias17=params['classifier.1.bias'].numpy()\n",
    "\n",
    "for i in range(count):\n",
    "   \n",
    "\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [ 0.485, 0.456, 0.406 ],\n",
    "                         std = [ 0.229, 0.224, 0.225 ]),])\n",
    "\n",
    "    imagen = np.random.rand(3, 224, 224).astype(np.float32)\n",
    "    imagen = Image.fromarray(imagen,'RGB')\n",
    "    imagen = transform(imagen).numpy()\n",
    "    imagen = imagen[np.newaxis,:]\n",
    "\n",
    "    #imagen = np.ones((1, 3, 224, 224))\n",
    "    #print(imagen.shape)\n",
    "\n",
    "    tic=pc()\n",
    "\n",
    "    squeeze0=nn.Conv2d(3, 64, kernel_size=3, bias=False, stride=2)\n",
    "    squeeze0.weight = nn.Parameter(torch.from_numpy(weights0))\n",
    "    squeeze0.bias = nn.Parameter(torch.from_numpy(bias0))\n",
    "\n",
    "    maxpool=nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "    squeeze1=nn.Conv2d(64, 16, kernel_size=1, bias=False)\n",
    "    squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "    squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))    \n",
    "\n",
    "    squeeze2a=nn.Conv2d(16, 64, kernel_size=1, bias=False)\n",
    "    squeeze2a.weight = nn.Parameter(torch.from_numpy(weights2a))\n",
    "    squeeze2a.bias = nn.Parameter(torch.from_numpy(bias2a))\n",
    "\n",
    "    squeeze2b=nn.Conv2d(16, 64, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze2b.weight = nn.Parameter(torch.from_numpy(weights2b))\n",
    "    squeeze2b.bias = nn.Parameter(torch.from_numpy(bias2b))\n",
    "\n",
    "    squeeze3=nn.Conv2d(128, 16, kernel_size=1, bias=False)\n",
    "    squeeze3.weight = nn.Parameter(torch.from_numpy(weights3))\n",
    "    squeeze3.bias = nn.Parameter(torch.from_numpy(bias3))    \n",
    "\n",
    "    squeeze4a=nn.Conv2d(16, 64, kernel_size=1, bias=False)\n",
    "    squeeze4a.weight = nn.Parameter(torch.from_numpy(weights4a))\n",
    "    squeeze4a.bias = nn.Parameter(torch.from_numpy(bias4a))\n",
    "\n",
    "    squeeze4b=nn.Conv2d(16, 64, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze4b.weight = nn.Parameter(torch.from_numpy(weights4b))\n",
    "    squeeze4b.bias = nn.Parameter(torch.from_numpy(bias4b))\n",
    "\n",
    "    squeeze5=nn.Conv2d(128, 32, kernel_size=1, bias=False)\n",
    "    squeeze5.weight = nn.Parameter(torch.from_numpy(weights5))\n",
    "    squeeze5.bias = nn.Parameter(torch.from_numpy(bias5))    \n",
    "\n",
    "    squeeze6a=nn.Conv2d(32, 128, kernel_size=1, bias=False)\n",
    "    squeeze6a.weight = nn.Parameter(torch.from_numpy(weights6a))\n",
    "    squeeze6a.bias = nn.Parameter(torch.from_numpy(bias6a))\n",
    "\n",
    "    squeeze6b=nn.Conv2d(32, 128, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze6b.weight = nn.Parameter(torch.from_numpy(weights6b))\n",
    "    squeeze6b.bias = nn.Parameter(torch.from_numpy(bias6b))\n",
    "\n",
    "    squeeze7=nn.Conv2d(256, 32, kernel_size=1, bias=False)\n",
    "    squeeze7.weight = nn.Parameter(torch.from_numpy(weights7))\n",
    "    squeeze7.bias = nn.Parameter(torch.from_numpy(bias7))    \n",
    "\n",
    "    squeeze8a=nn.Conv2d(32, 128, kernel_size=1, bias=False)\n",
    "    squeeze8a.weight = nn.Parameter(torch.from_numpy(weights8a))\n",
    "    squeeze8a.bias = nn.Parameter(torch.from_numpy(bias8a))\n",
    "\n",
    "    squeeze8b=nn.Conv2d(32, 128, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze8b.weight = nn.Parameter(torch.from_numpy(weights8b))\n",
    "    squeeze8b.bias = nn.Parameter(torch.from_numpy(bias8b))\n",
    "\n",
    "    squeeze9=nn.Conv2d(256, 48, kernel_size=1, bias=False)\n",
    "    squeeze9.weight = nn.Parameter(torch.from_numpy(weights9))\n",
    "    squeeze9.bias = nn.Parameter(torch.from_numpy(bias9))    \n",
    "\n",
    "    squeeze10a=nn.Conv2d(48, 192, kernel_size=1, bias=False)\n",
    "    squeeze10a.weight = nn.Parameter(torch.from_numpy(weights10a))\n",
    "    squeeze10a.bias = nn.Parameter(torch.from_numpy(bias10a))\n",
    "\n",
    "    squeeze10b=nn.Conv2d(48, 192, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze10b.weight = nn.Parameter(torch.from_numpy(weights10b))\n",
    "    squeeze10b.bias = nn.Parameter(torch.from_numpy(bias10b))\n",
    "\n",
    "    squeeze11=nn.Conv2d(384, 48, kernel_size=1, bias=False)\n",
    "    squeeze11.weight = nn.Parameter(torch.from_numpy(weights11))\n",
    "    squeeze11.bias = nn.Parameter(torch.from_numpy(bias11))    \n",
    "\n",
    "    squeeze12a=nn.Conv2d(48, 192, kernel_size=1, bias=False)\n",
    "    squeeze12a.weight = nn.Parameter(torch.from_numpy(weights12a))\n",
    "    squeeze12a.bias = nn.Parameter(torch.from_numpy(bias12a))\n",
    "\n",
    "    squeeze12b=nn.Conv2d(48, 192, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze12b.weight = nn.Parameter(torch.from_numpy(weights12b))\n",
    "    squeeze12b.bias = nn.Parameter(torch.from_numpy(bias12b))\n",
    "\n",
    "    squeeze13=nn.Conv2d(384, 64, kernel_size=1, bias=False)\n",
    "    squeeze13.weight = nn.Parameter(torch.from_numpy(weights13))\n",
    "    squeeze13.bias = nn.Parameter(torch.from_numpy(bias13))    \n",
    "\n",
    "    squeeze14a=nn.Conv2d(64, 256, kernel_size=1, bias=False)\n",
    "    squeeze14a.weight = nn.Parameter(torch.from_numpy(weights14a))\n",
    "    squeeze14a.bias = nn.Parameter(torch.from_numpy(bias14a))\n",
    "\n",
    "    squeeze14b=nn.Conv2d(64, 256, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze14b.weight = nn.Parameter(torch.from_numpy(weights14b))\n",
    "    squeeze14b.bias = nn.Parameter(torch.from_numpy(bias14b))\n",
    "\n",
    "    squeeze15=nn.Conv2d(512, 64, kernel_size=1, bias=False)\n",
    "    squeeze15.weight = nn.Parameter(torch.from_numpy(weights15))\n",
    "    squeeze15.bias = nn.Parameter(torch.from_numpy(bias15))    \n",
    "\n",
    "    squeeze16a=nn.Conv2d(64, 256, kernel_size=1, bias=False)\n",
    "    squeeze16a.weight = nn.Parameter(torch.from_numpy(weights16a))\n",
    "    squeeze16a.bias = nn.Parameter(torch.from_numpy(bias16a))\n",
    "\n",
    "    squeeze16b=nn.Conv2d(64, 256, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze16b.weight = nn.Parameter(torch.from_numpy(weights16b))\n",
    "    squeeze16b.bias = nn.Parameter(torch.from_numpy(bias16b))\n",
    "\n",
    "    conv_class=nn.Conv2d(512, 1000, kernel_size=1, bias=False)\n",
    "    conv_class.weight = nn.Parameter(torch.from_numpy(weights17))\n",
    "    conv_class.bias = nn.Parameter(torch.from_numpy(bias17))\n",
    "\n",
    "    avgpool=nn.AvgPool2d(13)\n",
    "\n",
    "    imagen1  = torch.from_numpy(imagen).float()\n",
    "\n",
    "    salida0=squeeze0(imagen1)\n",
    "    salida0_activation=squeeze_activation(salida0)\n",
    "\n",
    "    salida_pool1 = maxpool(salida0_activation)\n",
    "\n",
    "    salida1=squeeze1(salida_pool1)\n",
    "    salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "    salida2a=squeeze2a(salida1_activation)\n",
    "    salida2a_activation=squeeze_activation(salida2a)\n",
    "    salida2b=squeeze2b(salida1_activation)\n",
    "    salida2b_activation=squeeze_activation(salida2b)    \n",
    "    salida2_total=torch.cat([salida2a_activation,salida2b_activation], 1)\n",
    "\n",
    "    salida3=squeeze3(salida2_total)\n",
    "    salida3_activation=squeeze_activation(salida3)\n",
    "\n",
    "    salida4a=squeeze4a(salida3_activation)\n",
    "    salida4a_activation=squeeze_activation(salida4a)\n",
    "    salida4b=squeeze4b(salida3_activation)\n",
    "    salida4b_activation=squeeze_activation(salida4b)    \n",
    "    salida4_total=torch.cat([salida4a_activation,salida4b_activation], 1)\n",
    "\n",
    "    salida_pool2 = maxpool(salida4_total)\n",
    "\n",
    "    salida5=squeeze5(salida_pool2)\n",
    "    salida5_activation=squeeze_activation(salida5)\n",
    "\n",
    "    salida6a=squeeze6a(salida5_activation)\n",
    "    salida6a_activation=squeeze_activation(salida6a)\n",
    "    salida6b=squeeze6b(salida5_activation)\n",
    "    salida6b_activation=squeeze_activation(salida6b)    \n",
    "    salida6_total=torch.cat([salida6a_activation,salida6b_activation], 1)\n",
    "\n",
    "    salida7=squeeze7(salida6_total)\n",
    "    salida7_activation=squeeze_activation(salida7)\n",
    "\n",
    "    salida8a=squeeze8a(salida7_activation)\n",
    "    salida8a_activation=squeeze_activation(salida8a)\n",
    "    salida8b=squeeze8b(salida7_activation)\n",
    "    salida8b_activation=squeeze_activation(salida8b)    \n",
    "    salida8_total=torch.cat([salida8a_activation,salida8b_activation], 1)\n",
    "\n",
    "    salida_pool3 = maxpool(salida8_total)\n",
    "\n",
    "    salida9=squeeze9(salida_pool3)\n",
    "    salida9_activation=squeeze_activation(salida9)\n",
    "\n",
    "    salida10a=squeeze10a(salida9_activation)\n",
    "    salida10a_activation=squeeze_activation(salida10a)\n",
    "    salida10b=squeeze10b(salida9_activation)\n",
    "    salida10b_activation=squeeze_activation(salida10b)    \n",
    "    salida10_total=torch.cat([salida10a_activation,salida10b_activation], 1)\n",
    "\n",
    "    salida11=squeeze11(salida10_total)\n",
    "    salida11_activation=squeeze_activation(salida11)\n",
    "\n",
    "    salida12a=squeeze12a(salida11_activation)\n",
    "    salida12a_activation=squeeze_activation(salida12a)\n",
    "    salida12b=squeeze12b(salida11_activation)\n",
    "    salida12b_activation=squeeze_activation(salida12b)    \n",
    "    salida12_total=torch.cat([salida12a_activation,salida12b_activation], 1)\n",
    "\n",
    "    salida13=squeeze13(salida12_total)\n",
    "    salida13_activation=squeeze_activation(salida13)\n",
    "\n",
    "    salida14a=squeeze14a(salida13_activation)\n",
    "    salida14a_activation=squeeze_activation(salida14a)\n",
    "    salida14b=squeeze14b(salida13_activation)\n",
    "    salida14b_activation=squeeze_activation(salida14b)    \n",
    "    salida14_total=torch.cat([salida14a_activation,salida14b_activation], 1)\n",
    "\n",
    "    salida15=squeeze15(salida14_total)\n",
    "    salida15_activation=squeeze_activation(salida15)\n",
    "\n",
    "    salida16a=squeeze16a(salida15_activation)\n",
    "    salida16a_activation=squeeze_activation(salida16a)\n",
    "    salida16b=squeeze16b(salida15_activation)\n",
    "    salida16b_activation=squeeze_activation(salida16b)    \n",
    "    salida16_total=torch.cat([salida16a_activation,salida16b_activation], 1)\n",
    "\n",
    "    salida17=conv_class(salida16_total)\n",
    "    salida17_activation=squeeze_activation(salida17)\n",
    "    salida18=avgpool(salida17_activation)\n",
    "\n",
    "    salida18_a_numpy=salida18.detach().numpy()\n",
    "\n",
    "    toc=pc()\n",
    "\n",
    "    acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "\n",
    "    ####### OPENCL COMPARISON #######\n",
    "                               \n",
    "    # Simple task\n",
    "    h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "    d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "    conv1_weight = weights0.reshape(-1)\n",
    "    conv1_bias = bias0\n",
    "\n",
    "    fire1_squeeze_weight = weights1.reshape(-1)\n",
    "    fire1_squeeze_bias = bias1\n",
    "    fire1_expand1x1_weight = weights2a.reshape(-1)\n",
    "    fire1_expand1x1_bias = bias2a\n",
    "    fire1_expand3x3_weight =weights2b.reshape(-1)\n",
    "    fire1_expand3x3_bias = bias2b\n",
    "\n",
    "    fire2_squeeze_weight = weights3.reshape(-1)\n",
    "    fire2_squeeze_bias = bias3\n",
    "    fire2_expand1x1_weight = weights4a.reshape(-1)\n",
    "    fire2_expand1x1_bias = bias4a\n",
    "    fire2_expand3x3_weight =weights4b.reshape(-1)\n",
    "    fire2_expand3x3_bias = bias4b\n",
    "\n",
    "    fire3_squeeze_weight = weights5.reshape(-1)\n",
    "    fire3_squeeze_bias = bias5\n",
    "    fire3_expand1x1_weight = weights6a.reshape(-1)\n",
    "    fire3_expand1x1_bias = bias6a\n",
    "    fire3_expand3x3_weight =weights6b.reshape(-1)\n",
    "    fire3_expand3x3_bias = bias6b\n",
    "\n",
    "    fire4_squeeze_weight = weights7.reshape(-1)\n",
    "    fire4_squeeze_bias = bias7\n",
    "    fire4_expand1x1_weight = weights8a.reshape(-1)\n",
    "    fire4_expand1x1_bias = bias8a\n",
    "    fire4_expand3x3_weight =weights8b.reshape(-1)\n",
    "    fire4_expand3x3_bias = bias8b\n",
    "\n",
    "    fire5_squeeze_weight = weights9.reshape(-1)\n",
    "    fire5_squeeze_bias = bias9\n",
    "    fire5_expand1x1_weight = weights10a.reshape(-1)\n",
    "    fire5_expand1x1_bias = bias10a\n",
    "    fire5_expand3x3_weight =weights10b.reshape(-1)\n",
    "    fire5_expand3x3_bias = bias10b\n",
    "\n",
    "    fire6_squeeze_weight = weights11.reshape(-1)\n",
    "    fire6_squeeze_bias = bias11\n",
    "    fire6_expand1x1_weight = weights12a.reshape(-1)\n",
    "    fire6_expand1x1_bias = bias12a\n",
    "    fire6_expand3x3_weight =weights12b.reshape(-1)\n",
    "    fire6_expand3x3_bias = bias12b\n",
    "\n",
    "    fire7_squeeze_weight = weights13.reshape(-1)\n",
    "    fire7_squeeze_bias = bias13\n",
    "    fire7_expand1x1_weight = weights14a.reshape(-1)\n",
    "    fire7_expand1x1_bias = bias14a\n",
    "    fire7_expand3x3_weight =weights14b.reshape(-1)\n",
    "    fire7_expand3x3_bias = bias14b\n",
    "\n",
    "    fire8_squeeze_weight = weights15.reshape(-1)\n",
    "    fire8_squeeze_bias = bias15\n",
    "    fire8_expand1x1_weight = weights16a.reshape(-1)\n",
    "    fire8_expand1x1_bias = bias16a\n",
    "    fire8_expand3x3_weight =weights16b.reshape(-1)\n",
    "    fire8_expand3x3_bias = bias16b\n",
    "\n",
    "    classifier_conv_weight = weights17.reshape(-1)\n",
    "    classifier_conv_bias = bias17\n",
    "\n",
    "    h_result_conv = np.empty(1 * 64 * 111 * 111).astype(np.float32)\n",
    "    h_result_pool1 = np.empty(1 * 64 * 55 * 55).astype(np.float32)\n",
    "\n",
    "    h_result_fire1_squeeze = np.empty(1 * 16 * 55 * 55).astype(np.float32)\n",
    "    h_result_fire1_expand = np.empty(1 * 128 * 55 * 55).astype(np.float32)\n",
    "    h_result_fire2_squeeze = np.empty(1 * 16 * 55 * 55).astype(np.float32)\n",
    "    h_result_fire2_expand = np.empty(1 * 128 * 55 * 55).astype(np.float32)\n",
    "    h_result_pool2 = np.empty(1 * 128 * 27 * 27).astype(np.float32)\n",
    "\n",
    "    h_result_fire3_squeeze = np.empty(1 * 32 * 27 * 27).astype(np.float32)\n",
    "    h_result_fire3_expand = np.empty(1 * 256 * 27 * 27).astype(np.float32)\n",
    "    h_result_fire4_squeeze = np.empty(1 * 32 * 27 * 27).astype(np.float32)\n",
    "    h_result_fire4_expand = np.empty(1 * 256 * 27 * 27).astype(np.float32)\n",
    "    h_result_pool3 = np.empty(1 * 256 * 13 * 13).astype(np.float32)\n",
    "\n",
    "    h_result_fire5_squeeze = np.empty(1 * 48 * 13 * 13).astype(np.float32)\n",
    "    h_result_fire5_expand = np.empty(1 * 384 * 13 * 13).astype(np.float32)\n",
    "    h_result_fire6_squeeze = np.empty(1 * 48 * 13 * 13).astype(np.float32)\n",
    "    h_result_fire6_expand = np.empty(1 * 384 * 13 * 13).astype(np.float32)\n",
    "    h_result_fire7_squeeze = np.empty(1 * 64 * 13 * 13).astype(np.float32)\n",
    "    h_result_fire7_expand = np.empty(1 * 512 * 13 * 13).astype(np.float32)\n",
    "    h_result_fire8_squeeze = np.empty(1 * 64 * 13 * 13).astype(np.float32)\n",
    "    h_result_fire8_expand = np.empty(1 * 512 * 13 * 13).astype(np.float32)\n",
    "\n",
    "    h_result_classifier_conv = np.empty(1 * 1000 * 13 * 13).astype(np.float32)\n",
    "    h_result_classifier = np.empty(1 * 1000).astype(np.float32)\n",
    "\n",
    "    d_conv1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=conv1_weight)\n",
    "    d_conv1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=conv1_bias)\n",
    "\n",
    "    d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "    d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "    d_fire1_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_weight)\n",
    "    d_fire1_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_bias)\n",
    "    d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "    d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "    d_fire2_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_weight)\n",
    "    d_fire2_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_bias)\n",
    "    d_fire2_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_weight)\n",
    "    d_fire2_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_bias)\n",
    "    d_fire2_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_weight)\n",
    "    d_fire2_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_bias)\n",
    "\n",
    "    d_fire3_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_squeeze_weight)\n",
    "    d_fire3_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_squeeze_bias)\n",
    "    d_fire3_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand1x1_weight)\n",
    "    d_fire3_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand1x1_bias)\n",
    "    d_fire3_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand3x3_weight)\n",
    "    d_fire3_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand3x3_bias)\n",
    "\n",
    "    d_fire4_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_squeeze_weight)\n",
    "    d_fire4_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_squeeze_bias)\n",
    "    d_fire4_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand1x1_weight)\n",
    "    d_fire4_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand1x1_bias)\n",
    "    d_fire4_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand3x3_weight)\n",
    "    d_fire4_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand3x3_bias)\n",
    "\n",
    "    d_fire5_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_squeeze_weight)\n",
    "    d_fire5_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_squeeze_bias)\n",
    "    d_fire5_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand1x1_weight)\n",
    "    d_fire5_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand1x1_bias)\n",
    "    d_fire5_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand3x3_weight)\n",
    "    d_fire5_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand3x3_bias)\n",
    "\n",
    "    d_fire6_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_squeeze_weight)\n",
    "    d_fire6_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_squeeze_bias)\n",
    "    d_fire6_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand1x1_weight)\n",
    "    d_fire6_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand1x1_bias)\n",
    "    d_fire6_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand3x3_weight)\n",
    "    d_fire6_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand3x3_bias)\n",
    "\n",
    "    d_fire7_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_squeeze_weight)\n",
    "    d_fire7_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_squeeze_bias)\n",
    "    d_fire7_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand1x1_weight)\n",
    "    d_fire7_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand1x1_bias)\n",
    "    d_fire7_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand3x3_weight)\n",
    "    d_fire7_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand3x3_bias)\n",
    "\n",
    "    d_fire8_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_squeeze_weight)\n",
    "    d_fire8_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_squeeze_bias)\n",
    "    d_fire8_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand1x1_weight)\n",
    "    d_fire8_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand1x1_bias)\n",
    "    d_fire8_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand3x3_weight)\n",
    "    d_fire8_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand3x3_bias)\n",
    "\n",
    "    d_classifier_conv_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=classifier_conv_weight)\n",
    "    d_classifier_conv_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=classifier_conv_bias)\n",
    "\n",
    "    d_result_conv = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_conv.nbytes)\n",
    "    d_result_pool1 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool1.nbytes)\n",
    "\n",
    "    d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "    d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "    d_result_fire2_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_squeeze.nbytes)\n",
    "    d_result_fire2_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_expand.nbytes)\n",
    "    d_result_pool2 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool2.nbytes)\n",
    "\n",
    "    d_result_fire3_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire3_squeeze.nbytes)\n",
    "    d_result_fire3_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire3_expand.nbytes)\n",
    "    d_result_fire4_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire4_squeeze.nbytes)\n",
    "    d_result_fire4_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire4_expand.nbytes)\n",
    "    d_result_pool3 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool3.nbytes)\n",
    "\n",
    "    d_result_fire5_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire5_squeeze.nbytes)\n",
    "    d_result_fire5_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire5_expand.nbytes)\n",
    "    d_result_fire6_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire6_squeeze.nbytes)\n",
    "    d_result_fire6_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire6_expand.nbytes)\n",
    "    d_result_fire7_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire7_squeeze.nbytes)\n",
    "    d_result_fire7_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire7_expand.nbytes)\n",
    "    d_result_fire8_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire8_squeeze.nbytes)\n",
    "    d_result_fire8_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire8_expand.nbytes)\n",
    "\n",
    "    d_result_classifier_conv = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_classifier_conv.nbytes)\n",
    "    d_result_classifier = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_classifier.nbytes)\n",
    "\n",
    "    tic5 = pc()\n",
    "\n",
    "    #first conv layer\n",
    "    conv3x3_ST(queue,(1,), None, 3, 224, 0, 2, 0, 111, 64, d_sample, d_conv1_weight, d_conv1_bias, d_result_conv)\n",
    "    maxpool_ST(queue, (1, ), None, 111, 55, 64, d_result_conv, d_result_pool1)\n",
    "\n",
    "    #block1\n",
    "    conv1x1_ST(queue,(1,), None, 64, 55, 16, d_result_pool1, d_fire1_squeeze_weight, d_fire1_squeeze_bias, d_result_fire1_squeeze)\n",
    "    queue.finish()\n",
    "    conv1x1_ST(queue1,(1,), None, 16, 55, 64, d_result_fire1_squeeze, d_fire1_expand1x1_weight, d_fire1_expand1x1_bias, d_result_fire1_expand)\n",
    "    conv3x3_ST(queue,(1,), None, 16, 55, 1, 1, 64, 55, 64, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    conv1x1_ST(queue,(1,), None, 128, 55, 16, d_result_fire1_expand, d_fire2_squeeze_weight, d_fire2_squeeze_bias, d_result_fire2_squeeze)\n",
    "    queue.finish()\n",
    "    conv1x1_ST(queue1,(1,), None, 16, 55, 64, d_result_fire2_squeeze, d_fire2_expand1x1_weight, d_fire2_expand1x1_bias, d_result_fire2_expand)\n",
    "    conv3x3_ST(queue,(1,), None, 16, 55, 1, 1, 64, 55, 64, d_result_fire2_squeeze, d_fire2_expand3x3_weight, d_fire2_expand3x3_bias, d_result_fire2_expand)\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    maxpool_ST(queue, (1, ), None, 55, 27, 128, d_result_fire2_expand, d_result_pool2)\n",
    "\n",
    "    #block2\n",
    "    conv1x1_ST(queue,(1,), None, 128, 27, 32, d_result_pool2, d_fire3_squeeze_weight, d_fire3_squeeze_bias, d_result_fire3_squeeze)\n",
    "    queue.finish()\n",
    "    conv1x1_ST(queue1,(1,), None, 32, 27, 128, d_result_fire3_squeeze, d_fire3_expand1x1_weight, d_fire3_expand1x1_bias, d_result_fire3_expand)\n",
    "    conv3x3_ST(queue,(1,), None, 32, 27, 1, 1, 128, 27, 128, d_result_fire3_squeeze, d_fire3_expand3x3_weight, d_fire3_expand3x3_bias, d_result_fire3_expand)\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    conv1x1_ST(queue,(1,), None, 256, 27, 32, d_result_fire3_expand, d_fire4_squeeze_weight, d_fire4_squeeze_bias, d_result_fire4_squeeze)\n",
    "    queue.finish()\n",
    "    conv1x1_ST(queue1,(1,), None, 32, 27, 128, d_result_fire4_squeeze, d_fire4_expand1x1_weight, d_fire4_expand1x1_bias, d_result_fire4_expand)\n",
    "    conv3x3_ST(queue,(1,), None, 32, 27, 1, 1, 128, 27, 128, d_result_fire4_squeeze, d_fire4_expand3x3_weight, d_fire4_expand3x3_bias, d_result_fire4_expand)\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    maxpool_ST(queue, (1, ), None, 27, 13, 256, d_result_fire4_expand, d_result_pool3)\n",
    "\n",
    "    #block3\n",
    "    conv1x1_ST(queue,(1,), None, 256, 13, 48, d_result_pool3, d_fire5_squeeze_weight, d_fire5_squeeze_bias, d_result_fire5_squeeze)\n",
    "    queue.finish()\n",
    "    conv1x1_ST(queue1,(1,), None, 48, 13, 192, d_result_fire5_squeeze, d_fire5_expand1x1_weight, d_fire5_expand1x1_bias, d_result_fire5_expand)\n",
    "    conv3x3_ST(queue,(1,), None, 48, 13, 1, 1, 192, 13, 192, d_result_fire5_squeeze, d_fire5_expand3x3_weight, d_fire5_expand3x3_bias, d_result_fire5_expand)\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    conv1x1_ST(queue,(1,), None, 384, 13, 48, d_result_fire5_expand, d_fire6_squeeze_weight, d_fire6_squeeze_bias, d_result_fire6_squeeze)\n",
    "    queue.finish()\n",
    "    conv1x1_ST(queue1,(1,), None, 48, 13, 192, d_result_fire6_squeeze, d_fire6_expand1x1_weight, d_fire6_expand1x1_bias, d_result_fire6_expand)\n",
    "    conv3x3_ST(queue,(1,), None, 48, 13, 1, 1, 192, 13, 192, d_result_fire6_squeeze, d_fire6_expand3x3_weight, d_fire6_expand3x3_bias, d_result_fire6_expand)\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    conv1x1_ST(queue,(1,), None, 384, 13, 64, d_result_fire6_expand, d_fire7_squeeze_weight, d_fire7_squeeze_bias, d_result_fire7_squeeze)\n",
    "    queue.finish()\n",
    "    conv1x1_ST(queue1,(1,), None, 64, 13, 256, d_result_fire7_squeeze, d_fire7_expand1x1_weight, d_fire7_expand1x1_bias, d_result_fire7_expand)\n",
    "    conv3x3_ST(queue,(1,), None, 64, 13, 1, 1, 256, 13, 256, d_result_fire7_squeeze, d_fire7_expand3x3_weight, d_fire7_expand3x3_bias, d_result_fire7_expand)\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    conv1x1_ST(queue,(1,), None, 512, 13, 64, d_result_fire7_expand, d_fire8_squeeze_weight, d_fire8_squeeze_bias, d_result_fire8_squeeze)\n",
    "    queue.finish()\n",
    "    conv1x1_ST(queue1,(1,), None, 64, 13, 256, d_result_fire8_squeeze, d_fire8_expand1x1_weight, d_fire8_expand1x1_bias, d_result_fire8_expand)\n",
    "    conv3x3_ST(queue,(1,), None, 64, 13, 1, 1, 256, 13, 256, d_result_fire8_squeeze, d_fire8_expand3x3_weight, d_fire8_expand3x3_bias, d_result_fire8_expand)\n",
    "    queue.finish()\n",
    "    queue1.finish()\n",
    "\n",
    "    # classifier\n",
    "    conv1x1_ST(queue,(1,), None, 512, 13, 1000, d_result_fire8_expand, d_classifier_conv_weight, d_classifier_conv_bias, d_result_classifier_conv)\n",
    "\n",
    "    avgpool_ST(queue, (1, ), None, d_result_classifier_conv, d_result_classifier)\n",
    "\n",
    "    cl.enqueue_copy(queue, h_result_classifier, d_result_classifier)\n",
    "\n",
    "    veamos3 = h_result_classifier\n",
    "    \n",
    "    toc5 = pc()\n",
    "\n",
    "    acumulado_kernel = toc5 - tic5 + acumulado_kernel\n",
    "    \n",
    "    comparativa &= np.allclose(salida18_a_numpy.reshape(-1), veamos3,rtol=1e-01, atol=1e-01)\n",
    "    \n",
    "print (\"tiempo en segundos con pytorch= \", acumulado_pytorch/count)\n",
    "print (\"tiempo en segundos con opencl (Simple Task)=\",acumulado_kernel/count)\n",
    "print(\"comparativa (pytorch == Simple Task): \",comparativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
