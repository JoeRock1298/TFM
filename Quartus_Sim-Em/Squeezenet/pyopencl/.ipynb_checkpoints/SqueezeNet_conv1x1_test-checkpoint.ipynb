{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug SqueezeNet v1.3 (Simple Task) OpenCL implement with PyOpenCL and PyTorch\n",
    "Partial code are copied heavily from https://github.com/pytorch/vision/blob/master/torchvision/models/squeezenet.py  \n",
    "SqueezeNet Paper:https://arxiv.org/abs/1602.07360  \n",
    "SqueezeNet 1.1 model from https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1   \n",
    "SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters than SqueezeNet 1.0, without sacrificing accuracy.\n",
    "\n",
    "TEST DE IMPLEMENTACIÓN CONV1x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#some set up\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from PIL import Image\n",
    "import math\n",
    "import time\n",
    "from time import sleep, perf_counter as pc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aquí tenemos el medidor de pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En esta aproximacion tengo en cuenta el tiempo de definición de capas y la carga de pesos porque se supone que entre fire y fire estas operaciones tiene que hacerse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 46.  60. 115.  71.  61.]\n",
      "   [ 88.  43.  91.  85.  28.]\n",
      "   [ 44.  45.  43.  49.  99.]\n",
      "   [ 71.  56.  62.  69.  78.]\n",
      "   [ 70.  68.  89. 109.  39.]]\n",
      "\n",
      "  [[106. 125. 163.  56.  48.]\n",
      "   [ 65.  99. 166. 143.  54.]\n",
      "   [ 74. 123.  44.  85. 122.]\n",
      "   [111.  88.  67. 146. 149.]\n",
      "   [139. 152. 142. 136. 110.]]]]\n",
      "tiempo en segundos con pytorch=  0.0007013197499873058\n"
     ]
    }
   ],
   "source": [
    "canales_iniciales=4 #input_channels\n",
    "canales_contraidos=2 #filter_size\n",
    "canales_finales= canales_iniciales\n",
    "acumulado_pytorch=0\n",
    "idea=True\n",
    "count=100\n",
    "tamanyo=5 #input_size\n",
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "for i in range(count):\n",
    "\n",
    "    imagen = np.random.randint(10,size=(1,canales_iniciales, tamanyo, tamanyo))\n",
    "    weights1=np.random.randint(10,size=(canales_contraidos, canales_iniciales,1,1)).astype(np.float32)\n",
    "    bias1=np.random.randint(10,size=(canales_contraidos,)).astype(np.float32)\n",
    "      \n",
    "    tic=pc()\n",
    "    squeeze1=nn.Conv2d(canales_iniciales, canales_contraidos, kernel_size=1, bias=False)\n",
    "    squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "    squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))    \n",
    "    imagen1  = torch.from_numpy(imagen).float()\n",
    "    \n",
    "    salida1=squeeze1(imagen1)\n",
    "    salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "    salida1_a_numpy=salida1_activation.detach().numpy()\n",
    "    \n",
    "    toc=pc()\n",
    "    \n",
    "    acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "    \n",
    "print(salida1_a_numpy)\n",
    "print (\"tiempo en segundos con pytorch= \", acumulado_pytorch/count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veamos ahora conv1x1 con opencl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OpenCL setup\n",
    "import pyopencl as cl\n",
    "import sys\n",
    "sys.path.append('../common')\n",
    "import deviceinfo\n",
    "from time import time\n",
    "\n",
    "#wksp = '../device/v1.3/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step0-A: compilation for emulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aoc: OpenCL kernel compilation completed successfully.\n",
      "aoc: Linking Object files....\n",
      "aoc: Compiling for Emulation ....\n",
      "aoc: OpenCL kernel compilation completed successfully.\n",
      "aoc: Linking Object files....\n",
      "aoc: Compiling for Emulation ....\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "aoc -march=emulator ../device/v1.3/conv1x1_NDRange.cl -o ../device/v1.3/bin_em/conv1x1_NDRange.aocx\n",
    "aoc -march=emulator ../device/v1.3/conv1x1_simple_task.cl -o ../device/v1.3/bin_em/conv1x1_simple_task.aocx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step0-B: compilation for simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aoc: Environment checks completed successfully.\n",
      "Quartus location: /home/joerock/intelFPGA_pro/21.1/quartus/bin/quartus_sh\n",
      "aoc: Cached files in /var/tmp/aocl/joerock may be used to reduce compilation time\n",
      "aoc: Selected target board package /home/joerock/intelFPGA_pro/21.1/hld/board/a10_ref\n",
      "aoc: Selected target board a10gx\n",
      "aoc: Running OpenCL parser....\n",
      "aoc: OpenCL parser completed \n",
      "aoc: Linking Object files....\n",
      "aoc: Optimizing and doing static analysis of code...\n",
      "aoc: Linking with IP library ...\n",
      "aoc: Checking if memory usage is larger than 100%...\n",
      "aoc: Memory usage is not above 100.\n",
      "aoc: First stage compilation completed successfully.\n",
      "aoc: Compiling for Simulator.\n",
      "Quartus location: /home/joerock/intelFPGA_pro/21.1/quartus/bin/quartus_sh\n",
      "Creating simulation system...\n",
      "Generating simulation system...\n",
      "Compiling simulation...\n",
      "aoc: Simulation generation done!\n",
      "Simulator flow is successful.\n",
      "To execute simulator, invoke host with \n",
      "\tenv CL_CONTEXT_MPSIM_DEVICE_INTELFPGA=1 <host_program>\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#aoc -march=simulator -v -ghdl ../device/v1.3/conv1x1_NDRange.cl -o ../device/v1.3/bin_sim/conv1x1_NDRange.aocx -board=a10gx\n",
    "aoc -march=simulator -v -ghdl ../device/v1.3/conv1x1_simple_task.cl -o ../device/v1.3/bin_sim/conv1x1_simple_task.aocx -board=a10gx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step1: OpenCL preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl.Context at 0x4d12f78 on <pyopencl.Device '12th Gen Intel(R) Core(TM) i7-12650H' on 'Intel(R) OpenCL' at 0x4cc17e8>>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platforms = cl.get_platforms()\n",
    "context = cl.Context(\n",
    "        dev_type=cl.device_type.ALL,\n",
    "        properties=[(cl.context_properties.PLATFORM, platforms[0])])\n",
    "queue = cl.CommandQueue(context)\n",
    "\n",
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 2: creat kernels\n",
    "Creat & build program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "wksp = '../device/v1.3/'\n",
    "\n",
    "file_dir = wksp + 'conv1x1_NDRange.cl'\n",
    "\n",
    "kernelSource = open(file_dir).read()\n",
    "program_NDR = cl.Program(context, kernelSource).build()\n",
    "\n",
    "file_dir = wksp + 'conv1x1_simple_task.cl'\n",
    "\n",
    "kernelSource = open(file_dir).read()\n",
    "program_ST = cl.Program(context, kernelSource).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creat kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv1x1_NDR = program_NDR.conv2d1x1\n",
    "conv1x1_NDR.set_scalar_arg_dtypes([np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "conv1x1_ST = program_ST.conv2d1x1\n",
    "conv1x1_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, None, None, None, None])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenCL kernel: conv1x1_NDRange.cl\n",
    "\n",
    "conv2d1x1: 2-D 1x1 convolution. kernel size 1, stride 1  \n",
    "\n",
    "```C\n",
    "//1x1 convolution layer\n",
    "//output one feature map per kernel\n",
    "__kernel void conv2d1x1(\n",
    "\tconst int input_channels, const int input_size,\n",
    "\t__global float * restrict input_im,\n",
    "\t__global const float4* restrict filter_weight,\n",
    "\t__global const float* restrict filter_bias,\n",
    "\t__global float *restrict output_im)\n",
    "{\n",
    "\t// Adding restrict keyword\n",
    "    int filter_index = get_global_id(0); // 0 - (output_channels - 1)\n",
    "\tint i = get_global_id(1);\n",
    "\n",
    "\tfilter_weight += filter_index * input_channels;\n",
    "\n",
    "\tfloat bias = filter_bias[filter_index];\n",
    "\t\n",
    "\toutput_im += filter_index * input_size * input_size;//start_channel is for 1x1 feature map in fire layer\n",
    "\n",
    "\t//loop over output feature map\n",
    "\t//for(int i = 0; i < input_size; i++)\n",
    "\t{\n",
    "\t\tfor(int j = 0; j < input_size; j++)\n",
    "\t\t{\n",
    "\t\t\tfloat tmp = bias;\n",
    "\t\t\tint loc = i * input_size + j;\n",
    "\n",
    "\t\t\tfor(int k = 0; k < input_channels; k++)\n",
    "\t\t\t{\n",
    "\t\t\t\t//float8 weight = filter_weight[k];\n",
    "\t\t\t\t//float8 feature;\n",
    "\t\t\t\ttmp += input_im[((k << 2) + 0) * input_size * input_size + loc] * filter_weight[k].s0\n",
    "\t\t\t\t     + input_im[((k << 2) + 1) * input_size * input_size + loc] * filter_weight[k].s1\n",
    "\t\t\t\t\t + input_im[((k << 2) + 2) * input_size * input_size + loc] * filter_weight[k].s2\n",
    "\t\t\t\t\t + input_im[((k << 2) + 3) * input_size * input_size + loc] * filter_weight[k].s3;\n",
    "\t\t\t}\n",
    "\t\t\t//add relu after conv\n",
    "\t\t\toutput_im[i * input_size + j] = (tmp > 0.0) ? tmp : 0.0;\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "```\n",
    "#### OpenCL kernel: conv1x1_simple_task.cl\n",
    "\n",
    "conv2d1x1: 2-D 1x1 convolution. kernel size 1, stride 1  \n",
    "\n",
    "```C\n",
    "//1x1 convolution layer as a single kernel\n",
    "//output one feature map per kernel\n",
    "__kernel void conv2d1x1(\n",
    "\tconst int input_channels, \n",
    "    const int input_size,\n",
    "    const int filter_size,\n",
    "\t__global float * restrict input_im,\n",
    "\t__global const float4* restrict filter_weight,\n",
    "\t__global const float* restrict filter_bias,\n",
    "\t__global float *restrict output_im)\n",
    "{\n",
    "\t// Adding restrict keyword\n",
    "    //loop over filters\n",
    "\tfor(int f_i = 0; f_i < filter_size; f_i++)\n",
    "\t{\n",
    "        //filter_weight += f_i * input_channels;\n",
    "\n",
    "        float bias = filter_bias[f_i];\n",
    "\t\n",
    "        // output_im += input_size * input_size;//start_channel is for 1x1 feature map in fire layer\n",
    "\t\n",
    "\t\tfor(int ij = 0; ij < (input_size * input_size); ij++)\n",
    "\t\t{\n",
    "\t\t\tfloat tmp = bias;\n",
    "\t\t\t// int loc = i * input_size + j; // this is equal to ij\n",
    "\n",
    "\t\t\tfor(int k = 0; k < input_channels; k++)\n",
    "\t\t\t{\n",
    "\t\t\t\t//float8 weight = filter_weight[k];\n",
    "\t\t\t\t//float8 feature;\n",
    "\t\t\t\t/*tmp += input_im[((k << 2) + 0) * input_size * input_size + ij] * filter_weight[k + f_i * input_channels].s0\n",
    "\t\t\t\t     + input_im[((k << 2) + 1) * input_size * input_size + ij] * filter_weight[k + f_i * input_channels].s1\n",
    "\t\t\t\t\t + input_im[((k << 2) + 2) * input_size * input_size + ij] * filter_weight[k + f_i * input_channels].s2\n",
    "\t\t\t\t\t + input_im[((k << 2) + 3) * input_size * input_size + ij] * filter_weight[k + f_i * input_channels].s3;*/\n",
    "                tmp += input_im[((k << 2) + 0) * input_size * input_size + ij] * filter_weight[k].s0\n",
    "\t\t\t\t     + input_im[((k << 2) + 1) * input_size * input_size + ij] * filter_weight[k].s1\n",
    "\t\t\t\t\t + input_im[((k << 2) + 2) * input_size * input_size + ij] * filter_weight[k].s2\n",
    "\t\t\t\t\t + input_im[((k << 2) + 3) * input_size * input_size + ij] * filter_weight[k].s3;\n",
    "\t\t\t}\n",
    "\t\t\t//add relu after conv\n",
    "\t\t\t//output_im[ij + (input_size * input_size * f_i)] = (tmp > 0.0) ? tmp : 0.0;\n",
    "            output_im[ij] = (tmp > 0.0) ? tmp : 0.0;\n",
    "\t\t}\n",
    "        filter_weight += input_channels;\t\n",
    "        output_im += input_size * input_size;//start_channel is for 1x1 feature map in fire layer\n",
    "\t\n",
    "\t}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run OpenCL implement  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanyo=55 #input_size\n",
    "canales_iniciales=64 #input_channels\n",
    "canales_contraidos=16 #filter_size\n",
    "canales_finales = canales_iniciales\n",
    "\n",
    "acumulado_pytorch=0\n",
    "\n",
    "imagen = np.random.randint(10,size=(1,canales_iniciales, tamanyo, tamanyo)).astype(np.float32)\n",
    "#imagen = np.ones((1,canales_iniciales, tamanyo, tamanyo)).astype(np.float32)\n",
    "\n",
    "weights1=np.random.randint(10,size=(canales_contraidos, canales_iniciales,1,1)).astype(np.float32)\n",
    "bias1=np.random.randint(10,size=(canales_contraidos,)).astype(np.float32)\n",
    "\n",
    "#weights1=np.ones((canales_contraidos, canales_iniciales,1,1)).astype(np.float32)\n",
    "#bias1=np.ones((canales_contraidos,)).astype(np.float32)\n",
    "\n",
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "tic=pc()\n",
    "squeeze1=nn.Conv2d(canales_iniciales, canales_contraidos, kernel_size=1, bias=False)\n",
    "squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))\n",
    "\n",
    "imagen1  = torch.from_numpy(imagen).float()\n",
    "\n",
    "salida1=squeeze1(imagen1)\n",
    "salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "salida1_a_numpy=salida1_activation.detach().numpy()\n",
    "\n",
    "toc=pc()\n",
    "acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "\n",
    "####### OPENCL COMPARISON #######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NDRANGE\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample1 = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_squeeze_weight = weights1.reshape(-1)\n",
    "fire1_squeeze_bias = bias1\n",
    "\n",
    "d_fire1_squeeze_weight1 = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias1 = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "\n",
    "h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "d_result_fire1_squeeze1 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "\n",
    "tic2 = pc()\n",
    "\n",
    "conv1x1_NDR(queue,(canales_contraidos, tamanyo), None, np.int32(canales_iniciales/4), tamanyo, d_sample1, d_fire1_squeeze_weight1, d_fire1_squeeze_bias1, d_result_fire1_squeeze1)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire1_squeeze, d_result_fire1_squeeze1)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos = h_result_fire1_squeeze.reshape(-1,tamanyo,tamanyo)\n",
    "\n",
    "rtime = pc() - tic2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple task\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_squeeze_weight = weights1.reshape(-1)\n",
    "fire1_squeeze_bias = bias1\n",
    "\n",
    "d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "\n",
    "h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "\n",
    "tic3 = pc()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, np.int32(canales_iniciales/4), tamanyo, canales_contraidos, d_sample, d_fire1_squeeze_weight, d_fire1_squeeze_bias, d_result_fire1_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire1_squeeze, d_result_fire1_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos1 = h_result_fire1_squeeze.reshape(-1,tamanyo,tamanyo)\n",
    "\n",
    "rtime1 = pc() - tic3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo en segundos con pytorch=  0.003386429999864049\n",
      "tiempo en segundos con opencl (NDRANGE)= 0.0014173159997881157\n",
      "tiempo en segundos con opencl (Simple Task)= 0.0015757820001454093\n",
      "comparativa (pytorch == NDRange):  True\n",
      "comparativa (pytorch == Simple Task):  True\n",
      "comparativa (NDRange == Simple Task):  True\n"
     ]
    }
   ],
   "source": [
    "print (\"tiempo en segundos con pytorch= \", toc-tic)\n",
    "print (\"tiempo en segundos con opencl (NDRANGE)=\",rtime)\n",
    "print (\"tiempo en segundos con opencl (Simple Task)=\",rtime1)\n",
    "\n",
    "comparativa1=np.allclose(salida1_a_numpy, veamos,rtol=1e-01, atol=1e-01)\n",
    "comparativa2=np.allclose(salida1_a_numpy, veamos1,rtol=1e-01, atol=1e-01)\n",
    "comparativa3=np.allclose(veamos, veamos1,rtol=1e-01, atol=1e-01)\n",
    "\n",
    "print(\"comparativa (pytorch == NDRange): \",comparativa1)\n",
    "print(\"comparativa (pytorch == Simple Task): \",comparativa2)\n",
    "print(\"comparativa (NDRange == Simple Task): \",comparativa3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 3: emulation\n",
    "Creat & build program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl.Context at 0x4cd57d8 on <pyopencl.Device 'Intel(R) FPGA Emulation Device' on 'Intel(R) FPGA Emulation Platform for OpenCL(TM)' at 0x4ccc448>>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platforms = cl.get_platforms()\n",
    "context = cl.Context(\n",
    "        dev_type=cl.device_type.ALL,\n",
    "        properties=[(cl.context_properties.PLATFORM, platforms[1])])\n",
    "device = platforms[1].get_devices()\n",
    "\n",
    "queue = cl.CommandQueue(context)\n",
    "\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "wksp = '../device/v1.3/bin_em/'\n",
    "\n",
    "file_dir = wksp + 'conv1x1_NDRange.aocx'\n",
    "\n",
    "kernelSource = open(file_dir, mode='rb').read()\n",
    "program_NDR = cl.Program(context, device, [kernelSource]).build()\n",
    "\n",
    "file_dir = wksp + 'conv1x1_simple_task.aocx'\n",
    "\n",
    "kernelSource = open(file_dir, mode='rb').read()\n",
    "program_ST = cl.Program(context, device, [kernelSource]).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creat kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv1x1_NDR = program_NDR.conv2d1x1\n",
    "conv1x1_NDR.set_scalar_arg_dtypes([np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "conv1x1_ST = program_ST.conv2d1x1\n",
    "conv1x1_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, None, None, None, None])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run OpenCL implement  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanyo=55 #input_size\n",
    "canales_iniciales=64 #input_channels\n",
    "canales_contraidos=16 #filter_size\n",
    "canales_finales = canales_iniciales\n",
    "\n",
    "acumulado_pytorch=0\n",
    "\n",
    "imagen = np.random.randint(10,size=(1,canales_iniciales, tamanyo, tamanyo)).astype(np.float32)\n",
    "#imagen = np.ones((1,canales_iniciales, tamanyo, tamanyo)).astype(np.float32)\n",
    "\n",
    "weights1=np.random.randint(10,size=(canales_contraidos, canales_iniciales,1,1)).astype(np.float32)\n",
    "bias1=np.random.randint(10,size=(canales_contraidos,)).astype(np.float32)\n",
    "\n",
    "#weights1=np.ones((canales_contraidos, canales_iniciales,1,1)).astype(np.float32)\n",
    "#bias1=np.ones((canales_contraidos,)).astype(np.float32)\n",
    "\n",
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "tic=pc()\n",
    "squeeze1=nn.Conv2d(canales_iniciales, canales_contraidos, kernel_size=1, bias=False)\n",
    "squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))\n",
    "\n",
    "imagen1  = torch.from_numpy(imagen).float()\n",
    "\n",
    "salida1=squeeze1(imagen1)\n",
    "salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "salida1_a_numpy=salida1_activation.detach().numpy()\n",
    "\n",
    "toc=pc()\n",
    "acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "\n",
    "####### OPENCL COMPARISON #######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NDRANGE\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample1 = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_squeeze_weight = weights1.reshape(-1)\n",
    "fire1_squeeze_bias = bias1\n",
    "\n",
    "d_fire1_squeeze_weight1 = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias1 = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "\n",
    "h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "d_result_fire1_squeeze1 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "\n",
    "tic2 = pc()\n",
    "\n",
    "conv1x1_NDR(queue,(canales_contraidos, tamanyo), None, np.int32(canales_iniciales/4), tamanyo, d_sample1, d_fire1_squeeze_weight1, d_fire1_squeeze_bias1, d_result_fire1_squeeze1)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire1_squeeze, d_result_fire1_squeeze1)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos = h_result_fire1_squeeze.reshape(-1,tamanyo,tamanyo)\n",
    "\n",
    "rtime = pc() - tic2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple task\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_squeeze_weight = weights1.reshape(-1)\n",
    "fire1_squeeze_bias = bias1\n",
    "\n",
    "d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "\n",
    "h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "\n",
    "tic3 = pc()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, np.int32(canales_iniciales/4), tamanyo, canales_contraidos, d_sample, d_fire1_squeeze_weight, d_fire1_squeeze_bias, d_result_fire1_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire1_squeeze, d_result_fire1_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos1 = h_result_fire1_squeeze.reshape(-1,tamanyo,tamanyo)\n",
    "\n",
    "rtime1 = pc() - tic3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo en segundos con pytorch=  0.0006829490002928651\n",
      "tiempo en segundos con opencl (NDRANGE)= 0.01670902699970611\n",
      "tiempo en segundos con opencl (Simple Task)= 0.016361129999950208\n",
      "comparativa (pytorch == NDRange):  True\n",
      "comparativa (pytorch == Simple Task):  True\n",
      "comparativa (NDRange == Simple Task):  True\n"
     ]
    }
   ],
   "source": [
    "print (\"tiempo en segundos con pytorch= \", toc-tic)\n",
    "print (\"tiempo en segundos con opencl (NDRANGE)=\",rtime)\n",
    "print (\"tiempo en segundos con opencl (Simple Task)=\",rtime1)\n",
    "\n",
    "comparativa1=np.allclose(salida1_a_numpy, veamos,rtol=1e-01, atol=1e-01)\n",
    "comparativa2=np.allclose(salida1_a_numpy, veamos1,rtol=1e-01, atol=1e-01)\n",
    "comparativa3=np.allclose(veamos, veamos1,rtol=1e-01, atol=1e-01)\n",
    "\n",
    "print(\"comparativa (pytorch == NDRange): \",comparativa1)\n",
    "print(\"comparativa (pytorch == Simple Task): \",comparativa2)\n",
    "print(\"comparativa (NDRange == Simple Task): \",comparativa3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 4: simulación\n",
    "Creat & build program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl.Context at 0x631bf90 on <pyopencl.Device 'SimulatorDevice : Multi-process Simulator (aclmsim0)' on 'Intel(R) FPGA SDK for OpenCL(TM)' at 0x7f5a5c0c70d8>>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platforms = cl.get_platforms()\n",
    "context = cl.Context(\n",
    "        dev_type=cl.device_type.ALL,\n",
    "        properties=[(cl.context_properties.PLATFORM, platforms[2])])\n",
    "device = platforms[2].get_devices()\n",
    "\n",
    "queue = cl.CommandQueue(context)\n",
    "\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "wksp = '../device/v1.3/bin_sim/'\n",
    "\n",
    "file_dir = wksp + 'conv1x1_NDRange.aocx'\n",
    "\n",
    "kernelSource = open(file_dir, mode='rb').read()\n",
    "program_NDR = cl.Program(context, device, [kernelSource]).build()\n",
    "\n",
    "file_dir = wksp + 'conv1x1_simple_task.aocx'\n",
    "\n",
    "kernelSource = open(file_dir, mode='rb').read()\n",
    "program_ST = cl.Program(context, device, [kernelSource]).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creat kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv1x1_NDR = program_NDR.conv2d1x1\n",
    "conv1x1_NDR.set_scalar_arg_dtypes([np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "conv1x1_ST = program_ST.conv2d1x1\n",
    "conv1x1_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, None, None, None, None])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run OpenCL implement  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanyo=5 #input_size\n",
    "canales_iniciales=8 #input_channels\n",
    "canales_contraidos=2 #filter_size\n",
    "canales_finales = canales_iniciales\n",
    "\n",
    "acumulado_pytorch=0\n",
    "\n",
    "imagen = np.random.randint(10,size=(1,canales_iniciales, tamanyo, tamanyo)).astype(np.float32)\n",
    "#imagen = np.ones((1,canales_iniciales, tamanyo, tamanyo)).astype(np.float32)\n",
    "\n",
    "weights1=np.random.randint(10,size=(canales_contraidos, canales_iniciales,1,1)).astype(np.float32)\n",
    "bias1=np.random.randint(10,size=(canales_contraidos,)).astype(np.float32)\n",
    "\n",
    "#weights1=np.ones((canales_contraidos, canales_iniciales,1,1)).astype(np.float32)\n",
    "#bias1=np.ones((canales_contraidos,)).astype(np.float32)\n",
    "\n",
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "tic=pc()\n",
    "squeeze1=nn.Conv2d(canales_iniciales, canales_contraidos, kernel_size=1, bias=False)\n",
    "squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))\n",
    "\n",
    "imagen1  = torch.from_numpy(imagen).float()\n",
    "\n",
    "salida1=squeeze1(imagen1)\n",
    "salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "salida1_a_numpy=salida1_activation.detach().numpy()\n",
    "\n",
    "toc=pc()\n",
    "acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "\n",
    "####### OPENCL COMPARISON #######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5457/3432256041.py:12: RuntimeWarning: overflow encountered in cast\n",
      "  h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n"
     ]
    }
   ],
   "source": [
    "# NDRANGE\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample1 = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_squeeze_weight = weights1.reshape(-1)\n",
    "fire1_squeeze_bias = bias1\n",
    "\n",
    "d_fire1_squeeze_weight1 = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias1 = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "\n",
    "h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "d_result_fire1_squeeze1 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "\n",
    "tic2 = pc()\n",
    "\n",
    "conv1x1_NDR(queue,(canales_contraidos, tamanyo), None, np.int32(canales_iniciales/4), tamanyo, d_sample1, d_fire1_squeeze_weight1, d_fire1_squeeze_bias1, d_result_fire1_squeeze1)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire1_squeeze, d_result_fire1_squeeze1)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos = h_result_fire1_squeeze.reshape(-1,tamanyo,tamanyo)\n",
    "\n",
    "rtime = pc() - tic2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5457/1957108481.py:12: RuntimeWarning: overflow encountered in cast\n",
      "  h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n"
     ]
    }
   ],
   "source": [
    "# Simple task\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_squeeze_weight = weights1.reshape(-1)\n",
    "fire1_squeeze_bias = bias1\n",
    "\n",
    "d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "\n",
    "h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "\n",
    "tic3 = pc()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, np.int32(canales_iniciales/4), tamanyo, canales_contraidos, d_sample, d_fire1_squeeze_weight, d_fire1_squeeze_bias, d_result_fire1_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire1_squeeze, d_result_fire1_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos1 = h_result_fire1_squeeze.reshape(-1,tamanyo,tamanyo)\n",
    "\n",
    "rtime1 = pc() - tic3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (\"tiempo en segundos con pytorch= \", toc-tic)\n",
    "print (\"tiempo en segundos con opencl (NDRANGE)=\",rtime)\n",
    "print (\"tiempo en segundos con opencl (Simple Task)=\",rtime1)\n",
    "\n",
    "comparativa1=np.allclose(salida1_a_numpy, veamos,rtol=1e-01, atol=1e-01)\n",
    "comparativa2=np.allclose(salida1_a_numpy, veamos1,rtol=1e-01, atol=1e-01)\n",
    "comparativa3=np.allclose(veamos, veamos1,rtol=1e-01, atol=1e-01)\n",
    "\n",
    "print(\"comparativa (pytorch == NDRange): \",comparativa1)\n",
    "print(\"comparativa (pytorch == Simple Task): \",comparativa2)\n",
    "print(\"comparativa (NDRange == Simple Task): \",comparativa3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch (16, 55, 55) [1193. 1265.  962. 1468. 1151. 1208. 1168. 1300. 1210. 1278. 1195. 1442.\n",
      " 1170. 1086. 1594. 1191.  929. 1192. 1037. 1237. 1082. 1313. 1070. 1297.\n",
      " 1253. 1303. 1348. 1179. 1189. 1286.  991. 1196. 1133. 1270. 1248. 1266.\n",
      " 1213. 1182. 1212. 1323. 1340. 1210. 1350. 1394. 1361. 1346. 1275. 1347.\n",
      " 1234. 1127. 1428. 1342. 1336. 1341. 1228.]\n",
      "NDRange [1193. 1265.  962. 1468. 1151. 1208. 1168. 1300. 1210. 1278. 1195. 1442.\n",
      " 1170. 1086. 1594. 1191.  929. 1192. 1037. 1237. 1082. 1313. 1070. 1297.\n",
      " 1253. 1303. 1348. 1179. 1189. 1286.  991. 1196. 1133. 1270. 1248. 1266.\n",
      " 1213. 1182. 1212. 1323. 1340. 1210. 1350. 1394. 1361. 1346. 1275. 1347.\n",
      " 1234. 1127. 1428. 1342. 1336. 1341. 1228.]\n",
      "Simple task [1563. 1504. 1345. 1593. 1302. 1332. 1512. 1648. 1425. 1572. 1470. 1658.\n",
      " 1448. 1459. 1884. 1265. 1334. 1567. 1255. 1454. 1172. 1508. 1370. 1663.\n",
      " 1480. 1619. 1577. 1413. 1639. 1476. 1307. 1433. 1395. 1539. 1374. 1340.\n",
      " 1547. 1500. 1534. 1672. 1646. 1609. 1656. 1532. 1612. 1597. 1374. 1649.\n",
      " 1550. 1508. 1638. 1748. 1645. 1541. 1434.]\n",
      "(1, 64, 55, 55) False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\"pytorch\", veamos.shape, salida1_a_numpy.reshape(-1,tamanyo,tamanyo)[4][0])\n",
    "print(\"NDRange\", veamos[4][0])\n",
    "print(\"Simple task\", veamos1[6][0])\n",
    "print(imagen.shape, np.allclose(imagen, np.ones((1,canales_iniciales, tamanyo, tamanyo)).astype(np.float32), rtol=1e-01, atol=1e-01))\n",
    "#print(weights1[6])\n",
    "# print(fire1_squeeze_weight)\n",
    "#print(bias1[6])\n",
    "# print(imagen1_obtenida)\n",
    "# print(veamos2)\n",
    "print(np.allclose(salida1_a_numpy, veamos1,rtol=1e-01, atol=1e-01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    for j in range(55):\n",
    "        for k in range(55):\n",
    "            if (abs(salida1_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k] - veamos1[i][j][k])) > 1e-01:\n",
    "                print(\"i:\", i, \"j:\", j, \"k:\", k, salida1_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k], veamos1[i][j][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
