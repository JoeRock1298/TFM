{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug SqueezeNet v1.3 (Simple Task) OpenCL implement with PyOpenCL and PyTorch\n",
    "Partial code are copied heavily from https://github.com/pytorch/vision/blob/master/torchvision/models/squeezenet.py  \n",
    "SqueezeNet Paper:https://arxiv.org/abs/1602.07360  \n",
    "SqueezeNet 1.1 model from https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1   \n",
    "SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters than SqueezeNet 1.0, without sacrificing accuracy.\n",
    "\n",
    "Tests con bloque 1 o 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#some set up\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from PIL import Image\n",
    "import math\n",
    "import time\n",
    "from time import sleep, perf_counter as pc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aquí tenemos el medidor de pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En esta aproximacion tengo en cuenta el tiempo de definición de capas y la carga de pesos porque se supone que entre fire y fire estas operaciones tiene que hacerse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[6.5426157e+08 6.5621901e+08 6.5621901e+08 ... 6.3761094e+08\n",
      "   6.3976307e+08 6.3976307e+08]\n",
      "  [6.5426157e+08 6.5621901e+08 6.5621901e+08 ... 6.3761094e+08\n",
      "   6.3976307e+08 6.3976307e+08]\n",
      "  [6.2967846e+08 6.3237581e+08 6.3860736e+08 ... 6.3675040e+08\n",
      "   6.3721728e+08 6.3721728e+08]\n",
      "  ...\n",
      "  [6.4148608e+08 6.4148608e+08 6.3252826e+08 ... 6.5203789e+08\n",
      "   6.5634541e+08 6.5440262e+08]\n",
      "  [6.4161914e+08 6.4161914e+08 6.3261581e+08 ... 6.5829798e+08\n",
      "   6.5835443e+08 6.5440262e+08]\n",
      "  [6.3259392e+08 6.3259392e+08 6.2800890e+08 ... 6.5290278e+08\n",
      "   6.5290278e+08 6.4999520e+08]]\n",
      "\n",
      " [[7.2808813e+08 7.3098042e+08 7.3133894e+08 ... 7.1109805e+08\n",
      "   7.1363808e+08 7.1363808e+08]\n",
      "  [7.2808813e+08 7.3098042e+08 7.3133894e+08 ... 7.1149389e+08\n",
      "   7.1363808e+08 7.1363808e+08]\n",
      "  [7.0305805e+08 7.0474266e+08 7.1198650e+08 ... 7.0998016e+08\n",
      "   7.1000653e+08 7.1000653e+08]\n",
      "  ...\n",
      "  [7.1525318e+08 7.1525318e+08 7.0389581e+08 ... 7.2580979e+08\n",
      "   7.3147949e+08 7.2918579e+08]\n",
      "  [7.1525318e+08 7.1525318e+08 7.0459328e+08 ... 7.3225677e+08\n",
      "   7.3485984e+08 7.2918579e+08]\n",
      "  [7.0584115e+08 7.0584115e+08 7.0005600e+08 ... 7.2700179e+08\n",
      "   7.2804678e+08 7.2580378e+08]]\n",
      "\n",
      " [[7.0678950e+08 7.0964742e+08 7.0981466e+08 ... 6.9009395e+08\n",
      "   6.9226816e+08 6.9226816e+08]\n",
      "  [7.0678950e+08 7.0964742e+08 7.0981466e+08 ... 6.9045715e+08\n",
      "   6.9226816e+08 6.9226816e+08]\n",
      "  [6.8282477e+08 6.8407712e+08 6.9107763e+08 ... 6.8955078e+08\n",
      "   6.8900525e+08 6.8900525e+08]\n",
      "  ...\n",
      "  [6.9421613e+08 6.9421613e+08 6.8324864e+08 ... 7.0426950e+08\n",
      "   7.0952704e+08 7.0799770e+08]\n",
      "  [6.9421613e+08 6.9421613e+08 6.8403424e+08 ... 7.1083136e+08\n",
      "   7.1288954e+08 7.0799770e+08]\n",
      "  [6.8558426e+08 6.8558426e+08 6.7977862e+08 ... 7.0563552e+08\n",
      "   7.0632045e+08 7.0450669e+08]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[7.2296768e+08 7.2475795e+08 7.2527456e+08 ... 7.0616384e+08\n",
      "   7.0826406e+08 7.0826406e+08]\n",
      "  [7.2296768e+08 7.2475795e+08 7.2527456e+08 ... 7.0655117e+08\n",
      "   7.0826406e+08 7.0826406e+08]\n",
      "  [6.9708960e+08 6.9908256e+08 7.0654765e+08 ... 7.0453018e+08\n",
      "   7.0507520e+08 7.0507520e+08]\n",
      "  ...\n",
      "  [7.1027590e+08 7.1027590e+08 6.9883309e+08 ... 7.2064390e+08\n",
      "   7.2644896e+08 7.2434982e+08]\n",
      "  [7.1027590e+08 7.1027590e+08 6.9883309e+08 ... 7.2649062e+08\n",
      "   7.2992512e+08 7.2434982e+08]\n",
      "  [6.9981555e+08 6.9981555e+08 6.9437670e+08 ... 7.2133920e+08\n",
      "   7.2218291e+08 7.1952333e+08]]\n",
      "\n",
      " [[6.8213805e+08 6.8451533e+08 6.8451533e+08 ... 6.6508602e+08\n",
      "   6.6804000e+08 6.6804000e+08]\n",
      "  [6.8213805e+08 6.8451533e+08 6.8451533e+08 ... 6.6512730e+08\n",
      "   6.6804000e+08 6.6804000e+08]\n",
      "  [6.5684198e+08 6.6088909e+08 6.6711834e+08 ... 6.6381184e+08\n",
      "   6.6512096e+08 6.6512096e+08]\n",
      "  ...\n",
      "  [6.6879283e+08 6.6879283e+08 6.5972717e+08 ... 6.8110771e+08\n",
      "   6.8524051e+08 6.8195917e+08]\n",
      "  [6.6879283e+08 6.6879283e+08 6.5972717e+08 ... 6.8686419e+08\n",
      "   6.8754701e+08 6.8195917e+08]\n",
      "  [6.5967194e+08 6.5967194e+08 6.5513363e+08 ... 6.8103418e+08\n",
      "   6.8138195e+08 6.7793043e+08]]\n",
      "\n",
      " [[7.0442182e+08 7.0713856e+08 7.0713856e+08 ... 6.8742950e+08\n",
      "   6.8917037e+08 6.8917037e+08]\n",
      "  [7.0442182e+08 7.0713856e+08 7.0713856e+08 ... 6.8742950e+08\n",
      "   6.8917037e+08 6.8917037e+08]\n",
      "  [6.7923654e+08 6.8174438e+08 6.8856608e+08 ... 6.8733491e+08\n",
      "   6.8666387e+08 6.8666387e+08]\n",
      "  ...\n",
      "  [6.9173350e+08 6.9173350e+08 6.8110688e+08 ... 7.0245286e+08\n",
      "   7.0710003e+08 7.0475629e+08]\n",
      "  [6.9173350e+08 6.9173350e+08 6.8139898e+08 ... 7.0873798e+08\n",
      "   7.0953248e+08 7.0524282e+08]\n",
      "  [6.8244666e+08 6.8244666e+08 6.7696730e+08 ... 7.0285990e+08\n",
      "   7.0391846e+08 7.0115206e+08]]]\n",
      "tiempo en segundos con pytorch=  0.028754331529994487\n"
     ]
    }
   ],
   "source": [
    "canales_iniciales=64\n",
    "canales_contraidos=16\n",
    "canales_expandidos=64#expand factor\n",
    "canales_finales= np.int32(canales_iniciales+canales_iniciales)\n",
    "\n",
    "acumulado_pytorch=0\n",
    "acumulado_numpy=0\n",
    "idea=True\n",
    "\n",
    "count=100\n",
    "tamanyo=55\n",
    "tamanyo_final = np.int32((tamanyo - 3 + 2 ) / 2)\n",
    "\n",
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "for i in range(count):\n",
    "\n",
    "    imagen = np.random.randint(239,size=(1,canales_iniciales, tamanyo, tamanyo))\n",
    "    \n",
    "    weights1=np.random.rand(canales_contraidos, canales_iniciales,1,1).astype(np.float32)\n",
    "    bias1=np.random.rand(canales_contraidos,).astype(np.float32)\n",
    "\n",
    "    weights2a=np.random.rand(canales_expandidos, canales_contraidos,1,1).astype(np.float32)  \n",
    "    bias2a=np.random.rand(canales_expandidos,).astype(np.float32)    \n",
    "\n",
    "    weights2b=np.random.rand(canales_expandidos, canales_contraidos,3,3).astype(np.float32)    \n",
    "    bias2b=np.random.rand(canales_expandidos,).astype(np.float32)\n",
    "\n",
    "    weights3=np.random.rand(canales_contraidos, canales_finales,1,1).astype(np.float32)\n",
    "    bias3=np.random.rand(canales_contraidos,).astype(np.float32)\n",
    "\n",
    "    weights4a=np.random.rand(canales_expandidos, canales_contraidos,1,1).astype(np.float32)  \n",
    "    bias4a=np.random.rand(canales_expandidos,).astype(np.float32)    \n",
    "\n",
    "    weights4b=np.random.rand(canales_expandidos, canales_contraidos,3,3).astype(np.float32)    \n",
    "    bias4b=np.random.rand(canales_expandidos,).astype(np.float32)\n",
    "\n",
    "    tic=pc()\n",
    "\n",
    "    squeeze1=nn.Conv2d(canales_iniciales, canales_contraidos, kernel_size=1, bias=False)\n",
    "    squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "    squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))    \n",
    "\n",
    "    squeeze2a=nn.Conv2d(canales_contraidos, canales_expandidos, kernel_size=1, bias=False)\n",
    "    squeeze2a.weight = nn.Parameter(torch.from_numpy(weights2a))\n",
    "    squeeze2a.bias = nn.Parameter(torch.from_numpy(bias2a))\n",
    "\n",
    "    squeeze2b=nn.Conv2d(canales_contraidos, canales_expandidos, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze2b.weight = nn.Parameter(torch.from_numpy(weights2b))\n",
    "    squeeze2b.bias = nn.Parameter(torch.from_numpy(bias2b))\n",
    "\n",
    "    squeeze3=nn.Conv2d(canales_finales, canales_contraidos, kernel_size=1, bias=False)\n",
    "    squeeze3.weight = nn.Parameter(torch.from_numpy(weights3))\n",
    "    squeeze3.bias = nn.Parameter(torch.from_numpy(bias3))    \n",
    "\n",
    "    squeeze4a=nn.Conv2d(canales_contraidos, canales_expandidos, kernel_size=1, bias=False)\n",
    "    squeeze4a.weight = nn.Parameter(torch.from_numpy(weights4a))\n",
    "    squeeze4a.bias = nn.Parameter(torch.from_numpy(bias4a))\n",
    "\n",
    "    squeeze4b=nn.Conv2d(canales_contraidos, canales_expandidos, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze4b.weight = nn.Parameter(torch.from_numpy(weights4b))\n",
    "    squeeze4b.bias = nn.Parameter(torch.from_numpy(bias4b))\n",
    "\n",
    "    pool2=nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "    imagen1  = torch.from_numpy(imagen).float()\n",
    "\n",
    "    salida1=squeeze1(imagen1)\n",
    "    salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "    salida2a=squeeze2a(salida1_activation)\n",
    "    salida2a_activation=squeeze_activation(salida2a)\n",
    "    salida2b=squeeze2b(salida1_activation)\n",
    "    salida2b_activation=squeeze_activation(salida2b)    \n",
    "    salida2_total=torch.cat([salida2a_activation,salida2b_activation], 1)\n",
    "\n",
    "    salida3=squeeze3(salida2_total)\n",
    "    salida3_activation=squeeze_activation(salida3)\n",
    "\n",
    "    #salida3_test=salida3_activation.detach().numpy()\n",
    "\n",
    "    salida4a=squeeze4a(salida3_activation)\n",
    "    salida4a_activation=squeeze_activation(salida4a)\n",
    "    salida4b=squeeze4b(salida3_activation)\n",
    "    salida4b_activation=squeeze_activation(salida4b)    \n",
    "    salida4_total=torch.cat([salida4a_activation,salida4b_activation], 1)\n",
    "\n",
    "    salida_pool2=pool2(salida4_total)\n",
    "\n",
    "    #salida4_total_a_numpy=salida4_total.detach().numpy()\n",
    "    salida_pool2_a_numpy=salida_pool2.detach().numpy()\n",
    "    \n",
    "    toc=pc()\n",
    "    \n",
    "    acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "    \n",
    "    \n",
    "print(salida_pool2_a_numpy[0, -10:])\n",
    "print (\"tiempo en segundos con pytorch= \", acumulado_pytorch/count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veamos ahora fire con opencl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OpenCL setup\n",
    "import pyopencl as cl\n",
    "import sys\n",
    "sys.path.append('../common')\n",
    "import deviceinfo\n",
    "from time import time\n",
    "\n",
    "#wksp = '../device/v1.3/squeezenet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step0-A: compilation for emulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aoc: OpenCL kernel compilation completed successfully.\n",
      "aoc: Linking Object files....\n",
      "aoc: Compiling for Emulation ....\n",
      "aoc: OpenCL kernel compilation completed successfully.\n",
      "aoc: Linking Object files....\n",
      "aoc: Compiling for Emulation ....\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "aoc -march=emulator ../device/v1.3/squeezenet/squeezenet_NDRange.cl -o ../device/v1.3/squeezenet/bin_em/squeezenet_NDRange.aocx\n",
    "aoc -march=emulator ../device/v1.3/squeezenet/squeezenet_ST.cl -o ../device/v1.3/squeezenet/bin_em/squeezenet_ST.aocx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step0-B: compilation for simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aoc: Environment checks completed successfully.\n",
      "Quartus location: /home/joerock/intelFPGA_pro/21.1/quartus/bin/quartus_sh\n",
      "aoc: Cached files in /var/tmp/aocl/joerock may be used to reduce compilation time\n",
      "aoc: Selected target board package /home/joerock/intelFPGA_pro/21.1/hld/board/a10_ref\n",
      "aoc: Selected target board a10gx\n",
      "aoc: Running OpenCL parser....\n",
      "aoc: OpenCL parser completed \n",
      "aoc: Linking Object files....\n",
      "aoc: Optimizing and doing static analysis of code...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiler Warning: device/v1.3/squeezenet/squeezenet_NDRange.cl:96: declaring global arguments 'input_im', 'filter_weight' and 'filter_bias' with no 'restrict' may lead to low performance for kernel 'conv2d1x1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aoc: Linking with IP library ...\n",
      "aoc: Checking if memory usage is larger than 100%...\n",
      "aoc: Memory usage is not above 100.\n",
      "aoc: First stage compilation completed successfully.\n",
      "aoc: Compiling for Simulator.\n",
      "Quartus location: /home/joerock/intelFPGA_pro/21.1/quartus/bin/quartus_sh\n",
      "Creating simulation system...\n",
      "Generating simulation system...\n",
      "Compiling simulation...\n",
      "aoc: Simulation generation done!\n",
      "Simulator flow is successful.\n",
      "To execute simulator, invoke host with \n",
      "\tenv CL_CONTEXT_MPSIM_DEVICE_INTELFPGA=1 <host_program>\n",
      "aoc: Environment checks completed successfully.\n",
      "Quartus location: /home/joerock/intelFPGA_pro/21.1/quartus/bin/quartus_sh\n",
      "aoc: Cached files in /var/tmp/aocl/joerock may be used to reduce compilation time\n",
      "aoc: Selected target board package /home/joerock/intelFPGA_pro/21.1/hld/board/a10_ref\n",
      "aoc: Selected target board a10gx\n",
      "aoc: Running OpenCL parser....\n",
      "aoc: OpenCL parser completed \n",
      "aoc: Linking Object files....\n",
      "aoc: Optimizing and doing static analysis of code...\n",
      "aoc: Linking with IP library ...\n",
      "aoc: Checking if memory usage is larger than 100%...\n",
      "aoc: Memory usage is not above 100.\n",
      "aoc: First stage compilation completed successfully.\n",
      "aoc: Compiling for Simulator.\n",
      "Quartus location: /home/joerock/intelFPGA_pro/21.1/quartus/bin/quartus_sh\n",
      "Creating simulation system...\n",
      "Generating simulation system...\n",
      "Compiling simulation...\n",
      "aoc: Simulation generation done!\n",
      "Simulator flow is successful.\n",
      "To execute simulator, invoke host with \n",
      "\tenv CL_CONTEXT_MPSIM_DEVICE_INTELFPGA=1 <host_program>\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "aoc -march=simulator -v -ghdl ../device/v1.3/squeezenet/squeezenet_NDRange.cl -o ../device/v1.3/squeezenet/bin_sim/squeezenet_NDRange.aocx -board=a10gx\n",
    "aoc -march=simulator -v -ghdl ../device/v1.3/squeezenet/squeezenet_ST.cl -o ../device/v1.3/squeezenet/bin_sim/squeezenet_ST.aocx -board=a10gx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step1: OpenCL preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl.Context at 0x4a5f478 on <pyopencl.Device '12th Gen Intel(R) Core(TM) i7-12650H' on 'Intel(R) OpenCL' at 0x4a6b018>>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platforms = cl.get_platforms()\n",
    "context = cl.Context(\n",
    "        dev_type=cl.device_type.ALL,\n",
    "        properties=[(cl.context_properties.PLATFORM, platforms[0])])\n",
    "queue = cl.CommandQueue(context)\n",
    "queue1 = cl.CommandQueue(context)\n",
    "\n",
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 2: creat kernels\n",
    "Creat & build program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joerock/anaconda3/envs/TFM/lib/python3.8/site-packages/pyopencl/__init__.py:270: CompilerWarning: Non-empty compiler output encountered. Set the environment variable PYOPENCL_COMPILER_OUTPUT=1 to see more.\n",
      "  warn(\"Non-empty compiler output encountered. Set the \"\n"
     ]
    }
   ],
   "source": [
    "wksp = '../device/v1.3/squeezenet/'\n",
    "\n",
    "file_dir = wksp + 'squeezenet_NDRange.cl'\n",
    "\n",
    "kernelSource = open(file_dir).read()\n",
    "program_NDR = cl.Program(context, kernelSource).build()\n",
    "\n",
    "file_dir = wksp + 'squeezenet_ST.cl'\n",
    "\n",
    "kernelSource = open(file_dir).read()\n",
    "program_ST = cl.Program(context, kernelSource).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creat kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv3x3_NDR = program_NDR.conv2d3x3\n",
    "conv3x3_NDR.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "maxpool_NDR = program_NDR.maxpool2d\n",
    "maxpool_NDR.set_scalar_arg_dtypes([np.int32, np.int32, None, None])\n",
    "\n",
    "conv1x1_NDR = program_NDR.conv2d1x1\n",
    "conv1x1_NDR.set_scalar_arg_dtypes([np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "avgpool_NDR = program_NDR.avgpool2d\n",
    "avgpool_NDR.set_scalar_arg_dtypes([None, None])\n",
    "\n",
    "conv3x3_ST = program_ST.conv2d3x3\n",
    "conv3x3_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "maxpool_ST = program_ST.maxpool2d\n",
    "maxpool_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, None, None])\n",
    "\n",
    "conv1x1_ST = program_ST.conv2d1x1\n",
    "conv1x1_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "avgpool_ST = program_ST.avgpool2d\n",
    "avgpool_ST.set_scalar_arg_dtypes([None, None])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### OpenCL kernel: squeezenet_NDRange.cl\n",
    "conv2d3x3: 2-D 3x3 convolution.  \n",
    "conv2d1x1: 2-D 1x1 convolution. kerner size 1, stride 1  \n",
    "maxpool2d: 2-D max pool. kerner size 3, stride 2  \n",
    "avgpool2d: 2-D average pool. kernel size 13\n",
    "```C\n",
    "//maxPool2d \n",
    "//kernel_size=3 stride=2\n",
    "//output one feature map per kernel\n",
    "__kernel void maxpool2d(\n",
    "\tconst int input_size,\n",
    "\tconst int output_size,\n",
    "\t__global const float* restrict input_im,\n",
    "    __global float* restrict output_im)\n",
    "{\n",
    "\tint channels = get_global_id(0);//get output channel index\n",
    "\t\n",
    "\tinput_im += channels * input_size * input_size;\n",
    "\toutput_im += channels * output_size * output_size;\n",
    "\n",
    "\t//loop over output feature map\n",
    "\tfor(int i = 0; i < output_size; i++)//row\n",
    "\t{\n",
    "\t\tfor(int j = 0; j < output_size; j++)//col\n",
    "\t\t{\n",
    "\t\t\t//find the max value in 3x3 reigon \n",
    "\t\t\t//to be one element in the output feature map\n",
    "\t\t\tfloat tmp = 0.0;\n",
    "\n",
    "\t\t\t#pragma unroll 1\n",
    "\t\t\tfor(int k = 0; k < 3; k++)//row\n",
    "\t\t\t{\n",
    "\t\t\t\t#pragma unroll 1\n",
    "\t\t\t\tfor(int l = 0; l < 3; l++)//col\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\tfloat value = input_im[(i * 2 + k) * input_size  + j * 2 + l ];\n",
    "\t\t\t\t\tif(value > tmp)\n",
    "\t\t\t\t\t\ttmp = value;\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t\t//store the result to output feature map\n",
    "\t\t\toutput_im[i * output_size + j] = tmp; \n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "//3x3 convolution layer\n",
    "//output one feature map per kernel\n",
    "__kernel void conv2d3x3(\n",
    "\tconst int input_channels, const int input_size,\n",
    "\tconst int pad, const int stride,\n",
    "\tconst int start_channel, //start_channel is for 1x1 feature map in fire layer\n",
    "\tconst int output_size,\n",
    "\t__global const float* restrict input_im,\n",
    "\t__global const float* restrict filter_weight,\n",
    "\t__global const float* restrict filter_bias,\n",
    "\t__global float *restrict output_im\n",
    "\t)\n",
    "{\n",
    "\tint filter_index = get_global_id(0); //get output channel index\n",
    "\tint i =  get_global_id(1);\n",
    "\n",
    "\tfilter_weight += filter_index * input_channels * 9;\n",
    "\tfloat bias = filter_bias[filter_index];\n",
    "\toutput_im += (start_channel + filter_index) * output_size * output_size;\n",
    "\t\n",
    "\t//loop over output feature map\n",
    "\t//for(int i = 0; i < output_size; i++)\n",
    "\t{\n",
    "\t\tfor(int j = 0; j < output_size; j++)\n",
    "\t\t{\n",
    "\t\t\t//compute one element in the output feature map\n",
    "\t\t\tfloat tmp = bias;\n",
    "\t\t\t\n",
    "\t\t\t//compute dot product of 2 input_channels x 3 x 3 matrix\n",
    "\t\t\tfor(int k = 0; k < input_channels; k++)\n",
    "\t\t\t{\n",
    "\t\t\t\t#pragma unroll\n",
    "\t\t\t\tfor(int l = 0; l < 3; l++)\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\tint h = i * stride + l - pad;\n",
    "\t\t\t\t\tfor(int m = 0; m < 3; m++)\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\tint w = j * stride + m - pad;\n",
    "\t\t\t\t\t\tif((h >= 0) && (h < input_size) && (w >= 0) && (w < input_size))\n",
    "\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\ttmp += input_im[k * input_size * input_size + h * input_size + w] \\\n",
    "                               * filter_weight[9 * k + 3 * l + m];\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\t//add relu activation after conv\n",
    "\t\t\toutput_im[i * output_size + j] = (tmp > 0.0) ? tmp : 0.0;\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "//1x1 convolution layer\n",
    "//output one feature map per kernel\n",
    "__kernel void conv2d1x1(\n",
    "\tconst int input_channels, const int input_size,\n",
    "\t__global float *input_im,\n",
    "\t__global const float4* filter_weight,\n",
    "\t__global const float* filter_bias,\n",
    "\t__global float *restrict output_im)\n",
    "{\n",
    "\tint filter_index = get_global_id(0); // 0 - (output_channels - 1)\n",
    "\tint i = get_global_id(1);\n",
    "\n",
    "\tfilter_weight += filter_index * input_channels;\n",
    "\n",
    "\tfloat bias = filter_bias[filter_index];\n",
    "\t\n",
    "\toutput_im += filter_index * input_size * input_size;//start_channel is for 1x1 feature map in fire layer\n",
    "\n",
    "\t//loop over output feature map\n",
    "\t//for(int i = 0; i < input_size; i++)\n",
    "\t{\n",
    "\t\tfor(int j = 0; j < input_size; j++)\n",
    "\t\t{\n",
    "\t\t\tfloat tmp = bias;\n",
    "\t\t\tint loc = i * input_size + j;\n",
    "\n",
    "\t\t\tfor(int k = 0; k < input_channels; k++)\n",
    "\t\t\t{\n",
    "\t\t\t\t//float8 weight = filter_weight[k];\n",
    "\t\t\t\t//float8 feature;\n",
    "\t\t\t\ttmp += input_im[((k << 2) + 0) * input_size * input_size + loc] * filter_weight[k].s0\n",
    "\t\t\t\t     + input_im[((k << 2) + 1) * input_size * input_size + loc] * filter_weight[k].s1\n",
    "\t\t\t\t\t + input_im[((k << 2) + 2) * input_size * input_size + loc] * filter_weight[k].s2\n",
    "\t\t\t\t\t + input_im[((k << 2) + 3) * input_size * input_size + loc] * filter_weight[k].s3;\n",
    "\t\t\t}\n",
    "\t\t\t//add relu after conv\n",
    "\t\t\toutput_im[i * input_size + j] = (tmp > 0.0) ? tmp : 0.0;\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "//last layer use a 13 x 13 avgPool layer as classifier\n",
    "//one class score per kernel\n",
    "__kernel void avgpool2d(\n",
    "\t__global const float* restrict input_im,\n",
    "\t__global float* restrict output_im)\n",
    "{\n",
    "\tint class_index = get_global_id(0);//get class score index\n",
    "\n",
    "\tinput_im += 169 * class_index;\n",
    "\t\n",
    "\tfloat tmp = 0.0f;\n",
    "\n",
    "\tfor(int i = 0; i < 169; i++)\n",
    "\t{\n",
    "\t\ttmp += input_im[i];\n",
    "\t}\n",
    "\n",
    "\toutput_im[class_index] = tmp / 169.0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### OpenCL kernel: squeezenet_ST.cl\n",
    "conv2d3x3: 2-D 3x3 convolution.  \n",
    "conv2d1x1: 2-D 1x1 convolution. kerner size 1, stride 1  \n",
    "maxpool2d: 2-D max pool. kerner size 3, stride 2  \n",
    "avgpool2d: 2-D average pool. kernel size 13\n",
    "```C\n",
    "//maxPool2d \n",
    "//kernel_size=3 stride=2\n",
    "//output one feature map per kernel\n",
    "__kernel void maxpool2d(\n",
    "\tconst int input_size,\n",
    "\tconst int output_size,\n",
    "    const int channel_size,\n",
    "\t__global const float* restrict input_im,\n",
    "    __global float* restrict output_im)\n",
    "{\n",
    "\n",
    "    for(int channel_index = 0; channel_index < channel_size; channel_index++)\n",
    "    {\n",
    "        //loop over output feature map\n",
    "        for(int i = 0; i < output_size; i++)//row\n",
    "        {\n",
    "            for(int j = 0; j < output_size; j++)//col\n",
    "            {\n",
    "                //find the max value in 3x3 reigon \n",
    "                //to be one element in the output feature map\n",
    "                float tmp = 0.0;\n",
    "\n",
    "                #pragma unroll 1\n",
    "                for(int k = 0; k < 3; k++)//row\n",
    "                {\n",
    "                    #pragma unroll 1\n",
    "                    for(int l = 0; l < 3; l++)//col\n",
    "                    {\n",
    "                        float value = input_im[(i * 2 + k) * input_size  + j * 2 + l ];\n",
    "                        if(value > tmp)\n",
    "                            tmp = value;\n",
    "                    }\n",
    "                }\n",
    "                //store the result to output feature map\n",
    "                output_im[i * output_size + j] = tmp;\n",
    "            }\n",
    "        }\n",
    "    \n",
    "        input_im += input_size * input_size;\n",
    "        output_im += output_size * output_size;\n",
    "    }\n",
    "}\n",
    "\n",
    "//3x3 convolution layer\n",
    "//output one feature map per kernel\n",
    "__kernel void conv2d3x3(\n",
    "\tconst int input_channels, const int input_size,\n",
    "\tconst int pad, const int stride,\n",
    "\tconst int start_channel, //start_channel is for 1x1 feature map in fire layer\n",
    "\tconst int output_size,\n",
    "    const int filter_size,\n",
    "\t__global const float* restrict input_im,\n",
    "\t__global const float* restrict filter_weight,\n",
    "\t__global const float* restrict filter_bias,\n",
    "\t__global float *restrict output_im\n",
    "\t)\n",
    "{\n",
    "\t\n",
    "\t//filter_weight += filter_index * input_channels * 9;\n",
    "\toutput_im += start_channel * output_size * output_size;\n",
    "\t\n",
    "\t//loop over output feature map\n",
    "\tfor(int filter_index = 0; filter_index < filter_size; filter_index++)\n",
    "\t{\n",
    "        float bias = filter_bias[filter_index];\n",
    "\n",
    "\t\tfor(int i = 0; i < output_size; i++)\n",
    "\t\t{\n",
    "            for(int j = 0; j < output_size; j++)\n",
    "            {\n",
    "                //compute one element in the output feature map\n",
    "                float tmp = bias;\n",
    "\n",
    "                //compute dot product of 2 input_channels x 3 x 3 matrix\n",
    "                for(int k = 0; k < input_channels; k++)\n",
    "                {\n",
    "                    #pragma unroll\n",
    "                    for(int l = 0; l < 3; l++)\n",
    "                    {\n",
    "                        int h = i * stride + l - pad;\n",
    "                        for(int m = 0; m < 3; m++)\n",
    "                        {\n",
    "                            int w = j * stride + m - pad;\n",
    "                            if((h >= 0) && (h < input_size) && (w >= 0) && (w < input_size))\n",
    "                            {\n",
    "                                tmp += input_im[k * input_size * input_size + h * input_size + w] \\\n",
    "                                   * filter_weight[9 * k + 3 * l + m];\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                //add relu activation after conv\n",
    "                output_im[i * output_size + j] = (tmp > 0.0) ? tmp : 0.0;                 \n",
    "            }\n",
    "\t\t}\n",
    "        \n",
    "        filter_weight += input_channels * 9;\n",
    "        output_im += output_size * output_size;\n",
    "\t}\n",
    "}\n",
    "\n",
    "//1x1 convolution layer as a single kernel (V5)\n",
    "//output one feature map per kernel\n",
    "\n",
    "__kernel void conv2d1x1(\n",
    "\tconst int input_channels, \n",
    "    const int input_size,\n",
    "    const int filter_size,\n",
    "\t__global const float* restrict input_im,\n",
    "\t__global const float* restrict filter_weight,\n",
    "\t__global const float* restrict filter_bias,\n",
    "\t__global float *restrict output_im)\n",
    "{\n",
    "\t// Adding restrict keyword\n",
    "    //loop over filters\n",
    "\tfor(int f_i = 0; f_i < filter_size; f_i++)\n",
    "\t{\n",
    "        //filter_weight += f_i * input_channels;\n",
    "\n",
    "        float bias = filter_bias[f_i];\n",
    "\t\t\n",
    "        // output_im += input_size * input_size;//start_channel is for 1x1 feature map in fire layer\n",
    "\t\n",
    "\t\tfor(int ij = 0; ij < (input_size * input_size); ij++)\n",
    "\t\t{\n",
    "\t\t\tfloat tmp = bias;\n",
    "\t\t\t// int loc = i * input_size + j; // this is equal to ij\n",
    "\n",
    "\t\t\tfor(int k = 0; k < input_channels; k++)\n",
    "\t\t\t{\n",
    "\t\t\t\t//float8 weight = filter_weight[k];\n",
    "\t\t\t\t//float8 feature;\n",
    "\t\t\t\ttmp += input_im[k * input_size * input_size + ij] * filter_weight[k + f_i * input_channels];\n",
    "\t\t\t}\n",
    "\t\t\t//add relu after conv\n",
    "\t\t\toutput_im[ij + (input_size * input_size * f_i)] = (tmp > 0.0) ? tmp : 0.0;\n",
    "            //output_im[ij] = (tmp > 0.0) ? tmp : 0.0;\n",
    "\t\t}\n",
    "        //filter_weight += input_channels;\t\n",
    "        //output_im += input_size * input_size;//start_channel is for 1x1 feature map in fire layer\n",
    "\t\n",
    "\t}\n",
    "}\n",
    "\n",
    "//last layer use a 13 x 13 avgPool layer as classifier\n",
    "//one class score per kernel\n",
    "__kernel void avgpool2d(\n",
    "\t__global const float* restrict input_im,\n",
    "\t__global float* restrict output_im)\n",
    "{\n",
    "\t// int class_index = get_global_id(0);//get class score index\n",
    "    \n",
    "    //Since it's the final layer, we know that there are only 1000 classes\n",
    "    \n",
    "\t//input_im += 169 * class_index;\n",
    "\n",
    "\tfor(int class_index = 0; class_index < 1000; class_index++)\n",
    "    {\n",
    "            \n",
    "        float tmp = 0.0f;\n",
    "\n",
    "        for(int i = 0; i < 169; i++)\n",
    "        {\n",
    "            tmp += input_im[class_index * 169 + i];\n",
    "        }\n",
    "\n",
    "        output_im[class_index] = tmp / 169.0;\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run OpenCL implement  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "######## BLOCK 1 ########\n",
    "tamanyo=56 #input_size\n",
    "canales_iniciales=64 #input channels and \n",
    "canales_contraidos=16 #squeeze factor\n",
    "canales_expandidos=64#expand factor\n",
    "\n",
    "######## BLOCK 2 ########\n",
    "#tamanyo=28 #input_size\n",
    "#canales_iniciales=128 #input channels and \n",
    "#canales_contraidos=32 #squeeze factor\n",
    "#canales_expandidos=128#expand factor\n",
    "\n",
    "################\n",
    "\n",
    "canales_finales= np.int32(canales_expandidos * 2)\n",
    "tamanyo_final = np.int32((tamanyo - 3 + 2 ) / 2)\n",
    "\n",
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "acumulado_pytorch = 0\n",
    "\n",
    "imagen = np.random.randint(1,size=(1,canales_iniciales, tamanyo, tamanyo))\n",
    "    \n",
    "weights1=np.random.randint(1,size=(canales_contraidos, canales_iniciales,1,1)).astype(np.float32)\n",
    "bias1=np.random.randint(1,size=(canales_contraidos,)).astype(np.float32)\n",
    "\n",
    "weights2a=np.random.randint(1,size=(canales_expandidos, canales_contraidos,1,1)).astype(np.float32)  \n",
    "bias2a=np.random.randint(1,size=(canales_expandidos,)).astype(np.float32)    \n",
    "\n",
    "weights2b=np.random.randint(1,size=(canales_expandidos, canales_contraidos,3,3)).astype(np.float32)    \n",
    "bias2b=np.random.randint(1,size=(canales_expandidos,)).astype(np.float32)\n",
    "\n",
    "weights3=np.random.randint(1,size=(canales_contraidos, canales_finales,1,1)).astype(np.float32)\n",
    "bias3=np.random.randint(1,size=(canales_contraidos,)).astype(np.float32)\n",
    "\n",
    "weights4a=np.random.randint(1,size=(canales_expandidos, canales_contraidos,1,1)).astype(np.float32)  \n",
    "bias4a=np.random.randint(1,size=(canales_expandidos,)).astype(np.float32)    \n",
    "\n",
    "weights4b=np.random.randint(1,size=(canales_expandidos, canales_contraidos,3,3)).astype(np.float32)    \n",
    "bias4b=np.random.randint(1,size=(canales_expandidos,)).astype(np.float32)\n",
    "\n",
    "imagen = np.ones((1,canales_iniciales, tamanyo, tamanyo))\n",
    "    \n",
    "weights1=np.ones((canales_contraidos, canales_iniciales,1,1)).astype(np.float32)\n",
    "bias1=np.ones((canales_contraidos,)).astype(np.float32)\n",
    "\n",
    "weights2a=np.ones((canales_expandidos, canales_contraidos,1,1)).astype(np.float32)  \n",
    "bias2a=np.ones((canales_expandidos,)).astype(np.float32)    \n",
    "\n",
    "weights2b=np.ones((canales_expandidos, canales_contraidos,3,3)).astype(np.float32)    \n",
    "bias2b=np.ones((canales_expandidos,)).astype(np.float32)\n",
    "\n",
    "weights3=np.ones((canales_contraidos, canales_finales,1,1)).astype(np.float32)\n",
    "bias3=np.ones((canales_contraidos,)).astype(np.float32)\n",
    "\n",
    "weights4a=np.ones((canales_expandidos, canales_contraidos,1,1)).astype(np.float32)  \n",
    "bias4a=np.ones((canales_expandidos,)).astype(np.float32)    \n",
    "\n",
    "weights4b=np.ones((canales_expandidos, canales_contraidos,3,3)).astype(np.float32)    \n",
    "bias4b=np.ones((canales_expandidos,)).astype(np.float32)\n",
    "\n",
    "\n",
    "#imagen = np.random.randint(239,size=(1,canales_iniciales, tamanyo, tamanyo))\n",
    "#params = torch.load('squeezenet1_1.pth')\n",
    "\n",
    "######## BLOCK 1 ########\n",
    "#fire - fire - maxpool block 1\n",
    "#weights1 = params['features.3.squeeze.weight'].numpy()\n",
    "#bias1 = params['features.3.squeeze.bias'].numpy()\n",
    "\n",
    "#weights2a = params['features.3.expand1x1.weight'].numpy()\n",
    "#bias2a = params['features.3.expand1x1.bias'].numpy()\n",
    "\n",
    "#weights2b = params['features.3.expand3x3.weight'].numpy()\n",
    "#bias2b = params['features.3.expand3x3.bias'].numpy()\n",
    "\n",
    "#weights3 = params['features.4.squeeze.weight'].numpy()\n",
    "#bias3 = params['features.4.squeeze.bias'].numpy()\n",
    "\n",
    "#weights4a = params['features.4.expand1x1.weight'].numpy()\n",
    "#bias4a = params['features.4.expand1x1.bias'].numpy()\n",
    "\n",
    "#weights4b = params['features.4.expand3x3.weight'].numpy()\n",
    "#bias4b = params['features.4.expand3x3.bias'].numpy()\n",
    "\n",
    "######## BLOCK 2 ########\n",
    "#fire - fire - maxpool block 2\n",
    "#weights1 = params['features.6.squeeze.weight'].numpy()\n",
    "#bias1 = params['features.6.squeeze.bias'].numpy()\n",
    "\n",
    "#weights2a = params['features.6.expand1x1.weight'].numpy()\n",
    "#bias2a = params['features.6.expand1x1.bias'].numpy()\n",
    "\n",
    "#weights2b = params['features.6.expand3x3.weight'].numpy()\n",
    "#bias2b = params['features.6.expand3x3.bias'].numpy()\n",
    "\n",
    "#weights3 = params['features.7.squeeze.weight'].numpy()\n",
    "#bias3 = params['features.7.squeeze.bias'].numpy()\n",
    "\n",
    "#weights4a = params['features.7.expand1x1.weight'].numpy()\n",
    "#bias4a = params['features.7.expand1x1.bias'].numpy()\n",
    "\n",
    "#weights4b = params['features.7.expand3x3.weight'].numpy()\n",
    "#bias4b = params['features.7.expand3x3.bias'].numpy()\n",
    "\n",
    "tic=pc()\n",
    "\n",
    "squeeze1=nn.Conv2d(canales_iniciales, canales_contraidos, kernel_size=1, bias=False)\n",
    "squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))    \n",
    "\n",
    "squeeze2a=nn.Conv2d(canales_contraidos, canales_expandidos, kernel_size=1, bias=False)\n",
    "squeeze2a.weight = nn.Parameter(torch.from_numpy(weights2a))\n",
    "squeeze2a.bias = nn.Parameter(torch.from_numpy(bias2a))\n",
    "\n",
    "squeeze2b=nn.Conv2d(canales_contraidos, canales_expandidos, kernel_size=3, bias=False, padding=1)\n",
    "squeeze2b.weight = nn.Parameter(torch.from_numpy(weights2b))\n",
    "squeeze2b.bias = nn.Parameter(torch.from_numpy(bias2b))\n",
    "\n",
    "squeeze3=nn.Conv2d(canales_finales, canales_contraidos, kernel_size=1, bias=False)\n",
    "squeeze3.weight = nn.Parameter(torch.from_numpy(weights3))\n",
    "squeeze3.bias = nn.Parameter(torch.from_numpy(bias3))    \n",
    "\n",
    "squeeze4a=nn.Conv2d(canales_contraidos, canales_expandidos, kernel_size=1, bias=False)\n",
    "squeeze4a.weight = nn.Parameter(torch.from_numpy(weights4a))\n",
    "squeeze4a.bias = nn.Parameter(torch.from_numpy(bias4a))\n",
    "\n",
    "squeeze4b=nn.Conv2d(canales_contraidos, canales_expandidos, kernel_size=3, bias=False, padding=1)\n",
    "squeeze4b.weight = nn.Parameter(torch.from_numpy(weights4b))\n",
    "squeeze4b.bias = nn.Parameter(torch.from_numpy(bias4b))\n",
    "\n",
    "pool2=nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "imagen1  = torch.from_numpy(imagen).float()\n",
    "\n",
    "salida1=squeeze1(imagen1)\n",
    "salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "salida2a=squeeze2a(salida1_activation)\n",
    "salida2a_activation=squeeze_activation(salida2a)\n",
    "salida2b=squeeze2b(salida1_activation)\n",
    "salida2b_activation=squeeze_activation(salida2b)    \n",
    "salida2_total=torch.cat([salida2a_activation,salida2b_activation], 1)\n",
    "\n",
    "salida3=squeeze3(salida2_total)\n",
    "salida3_activation=squeeze_activation(salida3)\n",
    "\n",
    "salida3_test=salida3_activation.detach().numpy()\n",
    "\n",
    "salida4a=squeeze4a(salida3_activation)\n",
    "salida4a_activation=squeeze_activation(salida4a)\n",
    "salida4b=squeeze4b(salida3_activation)\n",
    "salida4b_activation=squeeze_activation(salida4b)    \n",
    "salida4_total=torch.cat([salida4a_activation,salida4b_activation], 1)\n",
    "\n",
    "#salida_pool2=pool2(salida4_total)\n",
    "\n",
    "salida4_total_a_numpy=salida4_total.detach().numpy()\n",
    "#salida_pool2_a_numpy=salida_pool2.detach().numpy()\n",
    "\n",
    "toc=pc()\n",
    "\n",
    "acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "\n",
    "####### OPENCL COMPARISON #######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4019/2151643433.py:21: RuntimeWarning: overflow encountered in cast\n",
      "  h_result_fire1_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n",
      "/tmp/ipykernel_4019/2151643433.py:24: RuntimeWarning: overflow encountered in cast\n",
      "  h_result_fire2_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n"
     ]
    }
   ],
   "source": [
    "# NDRANGE\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_squeeze_weight = weights1.reshape(-1)\n",
    "fire1_squeeze_bias = bias1\n",
    "fire1_expand1x1_weight = weights2a.reshape(-1)\n",
    "fire1_expand1x1_bias = bias2a\n",
    "fire1_expand3x3_weight =weights2b.reshape(-1)\n",
    "fire1_expand3x3_bias = bias2b\n",
    "\n",
    "fire2_squeeze_weight = weights3.reshape(-1)\n",
    "fire2_squeeze_bias = bias3\n",
    "fire2_expand1x1_weight = weights4a.reshape(-1)\n",
    "fire2_expand1x1_bias = bias4a\n",
    "fire2_expand3x3_weight =weights4b.reshape(-1)\n",
    "fire2_expand3x3_bias = bias4b\n",
    "\n",
    "h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire1_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "h_result_fire2_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire2_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "h_result_pool2 = np.empty(1 * canales_finales * tamanyo_final * tamanyo_final).astype(np.float32)\n",
    "\n",
    "d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "d_fire1_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_weight)\n",
    "d_fire1_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_bias)\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "d_fire2_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_weight)\n",
    "d_fire2_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_bias)\n",
    "d_fire2_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_weight)\n",
    "d_fire2_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_bias)\n",
    "d_fire2_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_weight)\n",
    "d_fire2_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_bias)\n",
    "\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "\n",
    "d_result_fire2_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_squeeze.nbytes)\n",
    "d_result_fire2_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_expand.nbytes)\n",
    "\n",
    "d_result_pool2 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool2.nbytes)\n",
    "\n",
    "tic2 = pc()\n",
    "\n",
    "conv1x1_NDR(queue,(canales_contraidos, tamanyo), None, np.int32(canales_iniciales/4), tamanyo, d_sample, d_fire1_squeeze_weight, d_fire1_squeeze_bias, d_result_fire1_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_NDR(queue1,(canales_expandidos, tamanyo), None, np.int32(canales_contraidos/4), tamanyo, d_result_fire1_squeeze, d_fire1_expand1x1_weight, d_fire1_expand1x1_bias, d_result_fire1_expand)\n",
    "conv3x3_NDR(queue,(canales_expandidos, tamanyo), None, canales_contraidos, tamanyo, 1, 1, canales_expandidos, tamanyo, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "conv1x1_NDR(queue,(canales_contraidos, tamanyo), None, np.int32(canales_finales/4), tamanyo, d_result_fire1_expand, d_fire2_squeeze_weight, d_fire2_squeeze_bias, d_result_fire2_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_NDR(queue1,(canales_expandidos, tamanyo), None, np.int32(canales_contraidos/4), tamanyo, d_result_fire2_squeeze, d_fire2_expand1x1_weight, d_fire2_expand1x1_bias, d_result_fire2_expand)\n",
    "conv3x3_NDR(queue,(canales_expandidos, tamanyo), None, canales_contraidos, tamanyo, 1, 1, canales_expandidos, tamanyo, d_result_fire2_squeeze, d_fire2_expand3x3_weight, d_fire2_expand3x3_bias, d_result_fire2_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "#maxpool_NDR(queue, (canales_finales, ), None, tamanyo, tamanyo_final, d_result_fire2_expand, d_result_pool2)\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire2_expand, d_result_fire2_expand)\n",
    "#cl.enqueue_copy(queue, h_result_pool2, d_result_pool2)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos = h_result_fire2_expand.reshape(-1,tamanyo,tamanyo)\n",
    "#veamos = h_result_pool2.reshape(-1,tamanyo_final,tamanyo_final)\n",
    "\n",
    "rtime = pc() - tic2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4019/48616990.py:21: RuntimeWarning: overflow encountered in cast\n",
      "  h_result_fire1_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n",
      "/tmp/ipykernel_4019/48616990.py:24: RuntimeWarning: overflow encountered in cast\n",
      "  h_result_fire2_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n"
     ]
    }
   ],
   "source": [
    "# Simple task\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_squeeze_weight = weights1.reshape(-1)\n",
    "fire1_squeeze_bias = bias1\n",
    "fire1_expand1x1_weight = weights2a.reshape(-1)\n",
    "fire1_expand1x1_bias = bias2a\n",
    "fire1_expand3x3_weight =weights2b.reshape(-1)\n",
    "fire1_expand3x3_bias = bias2b\n",
    "\n",
    "fire2_squeeze_weight = weights3.reshape(-1)\n",
    "fire2_squeeze_bias = bias3\n",
    "fire2_expand1x1_weight = weights4a.reshape(-1)\n",
    "fire2_expand1x1_bias = bias4a\n",
    "fire2_expand3x3_weight =weights4b.reshape(-1)\n",
    "fire2_expand3x3_bias = bias4b\n",
    "\n",
    "h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire1_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "h_result_fire2_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire2_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "h_result_pool2 = np.empty(1 * canales_finales * tamanyo_final * tamanyo_final).astype(np.float32)\n",
    "\n",
    "d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "d_fire1_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_weight)\n",
    "d_fire1_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_bias)\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "d_fire2_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_weight)\n",
    "d_fire2_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_bias)\n",
    "d_fire2_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_weight)\n",
    "d_fire2_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_bias)\n",
    "d_fire2_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_weight)\n",
    "d_fire2_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_bias)\n",
    "\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "\n",
    "d_result_fire2_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_squeeze.nbytes)\n",
    "d_result_fire2_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_expand.nbytes)\n",
    "\n",
    "d_result_pool2 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool2.nbytes)\n",
    "\n",
    "tic3 = pc()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, canales_iniciales, tamanyo, canales_contraidos, d_sample, d_fire1_squeeze_weight, d_fire1_squeeze_bias, d_result_fire1_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_ST(queue1,(1,), None, canales_contraidos, tamanyo, canales_expandidos, d_result_fire1_squeeze, d_fire1_expand1x1_weight, d_fire1_expand1x1_bias, d_result_fire1_expand)\n",
    "conv3x3_ST(queue,(1,), None, canales_contraidos, tamanyo, 1, 1, canales_expandidos, tamanyo, canales_expandidos, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, canales_finales, tamanyo, canales_contraidos, d_result_fire1_expand, d_fire2_squeeze_weight, d_fire2_squeeze_bias, d_result_fire2_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_ST(queue1,(1,), None, canales_contraidos, tamanyo, canales_expandidos, d_result_fire2_squeeze, d_fire2_expand1x1_weight, d_fire2_expand1x1_bias, d_result_fire2_expand)\n",
    "conv3x3_ST(queue,(1,), None, canales_contraidos, tamanyo, 1, 1, canales_expandidos, tamanyo, canales_expandidos, d_result_fire2_squeeze, d_fire2_expand3x3_weight, d_fire2_expand3x3_bias, d_result_fire2_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "#maxpool_ST(queue, (1, ), None, tamanyo, tamanyo_final, canales_finales, d_result_fire2_expand, d_result_pool2)\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire2_expand, d_result_fire2_expand)\n",
    "#cl.enqueue_copy(queue, h_result_pool2, d_result_pool2)\n",
    "\n",
    "veamos1 = h_result_fire2_expand.reshape(-1,tamanyo,tamanyo)\n",
    "#veamos1 = h_result_pool2.reshape(-1,tamanyo_final,tamanyo_final)\n",
    "\n",
    "rtime1 = pc() - tic3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo en segundos con pytorch=  0.055478766000078394\n",
      "tiempo en segundos con opencl (NDRANGE)= 0.053643190000002505\n",
      "tiempo en segundos con opencl (Simple Task)= 0.08680652199996075\n",
      "comparativa (pytorch == NDRange):  True\n",
      "comparativa (pytorch == Simple Task):  True\n",
      "comparativa (NDRange == Simple Task):  True\n"
     ]
    }
   ],
   "source": [
    "print (\"tiempo en segundos con pytorch= \", toc-tic)\n",
    "print (\"tiempo en segundos con opencl (NDRANGE)=\",rtime)\n",
    "print (\"tiempo en segundos con opencl (Simple Task)=\",rtime1)\n",
    "\n",
    "comparativa1=np.allclose(salida4_total_a_numpy.reshape(-1,tamanyo,tamanyo), veamos,rtol=1e-01, atol=1e-01)\n",
    "comparativa2=np.allclose(salida4_total_a_numpy.reshape(-1,tamanyo,tamanyo), veamos1,rtol=1e-01, atol=1e-01)\n",
    "#comparativa1=np.allclose(h_result_pool2.reshape(-1,tamanyo_final,tamanyo_final), veamos,rtol=1e-01, atol=1e-01)\n",
    "#comparativa2=np.allclose(h_result_pool2.reshape(-1,tamanyo_final,tamanyo_final), veamos1,rtol=1e-01, atol=1e-01)\n",
    "comparativa3=np.allclose(veamos, veamos1,rtol=1e-01, atol=1e-01)\n",
    "\n",
    "print(\"comparativa (pytorch == NDRange): \",comparativa1)\n",
    "print(\"comparativa (pytorch == Simple Task): \",comparativa2)\n",
    "print(\"comparativa (NDRange == Simple Task): \",comparativa3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 16, 56, 56) [[665729. 665729. 665729.]\n",
      " [665729. 665729. 665729.]\n",
      " [665729. 665729. 665729.]]\n",
      "expected value  95864977.0 665729.0\n",
      "(1, 1, 3, 3) [[[[42606620. 63909916. 42606620.]\n",
      "   [63909916. 95864864. 63909916.]\n",
      "   [42606620. 63909916. 42606620.]]]]\n",
      "1.0\n",
      "95864977.0\n"
     ]
    }
   ],
   "source": [
    "print(salida3_test.shape,salida3_test[0,0,27:30,27:30])\n",
    "\n",
    "weights=np.ones((1, 16,3,3)).astype(np.float32)    \n",
    "bias=np.ones((1,)).astype(np.float32)\n",
    "\n",
    "conv3x3=nn.Conv2d(16, 1, kernel_size=3, bias=False, padding=1)\n",
    "conv3x3.weight = nn.Parameter(torch.from_numpy(weights))\n",
    "conv3x3.bias = nn.Parameter(torch.from_numpy(bias))\n",
    "\n",
    "in_test_np = np.zeros((1,16,3,3)).astype(np.float32)\n",
    "val_in = np.float32(665729)\n",
    "in_test_np.fill(val_in)\n",
    "print('expected value ', (val_in*16*9)+1, in_test_np[0, 0, 0, 0])\n",
    "\n",
    "#in_test = torch.from_numpy(salida3_test[:,:,27:30,27:30]).float()\n",
    "in_test = torch.from_numpy(in_test_np).float()\n",
    "\n",
    "salida_test=conv3x3(in_test)\n",
    "\n",
    "salida_test_activation=squeeze_activation(salida_test)\n",
    "salida3_test1=salida_test_activation.detach().numpy()\n",
    "\n",
    "print(salida3_test1.shape, salida3_test1)\n",
    "\n",
    "tmp = np.float64(1.0) ## bias\n",
    "print(tmp)\n",
    "for channels in range(16):\n",
    "    for pix_i in range(3):\n",
    "        for  pix_j in range (3):\n",
    "            tmp = in_test_np[0, channels, pix_i, pix_j] * weights[0, channels, pix_i, pix_j] + tmp\n",
    "print(tmp)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10651665 95864977\n",
      "[[95864864. 95864864. 95864864.]\n",
      " [95864864. 95864864. 95864864.]\n",
      " [95864864. 95864864. 95864864.]] [[95864864. 95864864. 95864864.]\n",
      " [95864864. 95864864. 95864864.]\n",
      " [95864864. 95864864. 95864864.]]\n",
      "[[10651665. 10651665. 10651665.]\n",
      " [10651665. 10651665. 10651665.]\n",
      " [10651665. 10651665. 10651665.]] [[10651665. 10651665. 10651665.]\n",
      " [10651665. 10651665. 10651665.]\n",
      " [10651665. 10651665. 10651665.]]\n",
      "(1, 128, 56, 56) (128, 56, 56)\n",
      "i: 64 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 64 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 64 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 64 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 64 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 65 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 65 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 65 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 65 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 65 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 66 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 66 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 66 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 66 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 66 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 67 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 67 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 67 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 67 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 67 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 68 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 68 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 68 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 68 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 68 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 69 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 69 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 69 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 69 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 69 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 70 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 70 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 70 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 70 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 70 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 71 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 71 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 71 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 71 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 71 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 72 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 72 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 72 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 72 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 72 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 73 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 73 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 73 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 73 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 73 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 74 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 74 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 74 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 74 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 74 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 75 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 75 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 75 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 75 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 75 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 76 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 76 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 76 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 76 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 76 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 77 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 77 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 77 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 77 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 77 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 78 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 78 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 78 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 78 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 78 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 79 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 79 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 79 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 79 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 79 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 80 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 80 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 80 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 80 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 80 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 81 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 81 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 81 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 81 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 81 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 82 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 82 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 82 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 82 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 82 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 83 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 83 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 83 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 83 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 83 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 84 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 84 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 84 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 84 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 84 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 85 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 85 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 85 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 85 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 85 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 86 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 86 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 86 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 86 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 86 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 87 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 87 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 87 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 87 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 87 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 88 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 88 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 88 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 88 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 88 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 89 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 89 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 89 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 89 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 89 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 90 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 90 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 90 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 90 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 90 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 91 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 91 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 91 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 91 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 91 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 92 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 92 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 92 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 92 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 92 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 93 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 93 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 93 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 93 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 93 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 94 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 94 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 94 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 94 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 94 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 95 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 95 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 95 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 95 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 95 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 96 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 96 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 96 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 96 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 96 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 97 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 97 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 97 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 97 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 97 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 98 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 98 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 98 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 98 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 98 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 99 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 99 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 99 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 99 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 99 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 100 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 100 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 100 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 100 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 100 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 101 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 101 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 101 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 101 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 101 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 102 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 102 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 102 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 102 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 102 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 103 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 103 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 103 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 103 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 103 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 104 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 104 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 104 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 104 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 104 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 105 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 105 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 105 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 105 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 105 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 106 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 106 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 106 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 106 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 106 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 107 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 107 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 107 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 107 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 107 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 108 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 108 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 108 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 108 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 108 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 109 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 109 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 109 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 109 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 109 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 110 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 110 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 110 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 110 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 110 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 111 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 111 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 111 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 111 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 111 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 112 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 112 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 112 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 112 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 112 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 113 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 113 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 113 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 113 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 113 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 114 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 114 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 114 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 114 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 114 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 115 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 115 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 115 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 115 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 115 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 116 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 116 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 116 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 116 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 116 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 117 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 117 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 117 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 117 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 117 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 118 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 118 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 118 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 118 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 118 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 119 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 119 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 119 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 119 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 119 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 120 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 120 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 120 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 120 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 120 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 121 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 121 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 121 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 121 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 121 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 122 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 122 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 122 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 122 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 122 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 123 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 123 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 123 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 123 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 123 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 124 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 124 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 124 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 124 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 124 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 125 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 125 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 125 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 125 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 125 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 126 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 126 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 126 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 126 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 126 j: 55 k: 54 49000480.0 49000484.0\n",
      "i: 127 j: 1 k: 55 49000480.0 49000484.0\n",
      "i: 127 j: 54 k: 0 49000480.0 49000484.0\n",
      "i: 127 j: 54 k: 55 49000480.0 49000484.0\n",
      "i: 127 j: 55 k: 1 49000480.0 49000484.0\n",
      "i: 127 j: 55 k: 54 49000480.0 49000484.0\n"
     ]
    }
   ],
   "source": [
    "print(665729*16+1, (665729*16*9)+1)\n",
    "#print(salida4_total_a_numpy.reshape(-1,tamanyo,tamanyo)[canales_expandidos, 20:30, 20:30], veamos[canales_expandidos, 20:30, 20:30])\n",
    "print(salida4_total_a_numpy.reshape(-1,tamanyo,tamanyo)[64,27:30,27:30], veamos1[64,27:30,27:30])\n",
    "print(salida4_total_a_numpy.reshape(-1,tamanyo,tamanyo)[0,27:30,27:30], veamos1[0,27:30,27:30])\n",
    "print(salida4_total_a_numpy.shape, veamos.shape)\n",
    "#print(np.allclose(salida4_total_a_numpy.reshape(-1,tamanyo,tamanyo), veamos1,rtol=1e-01, atol=1e-01))\n",
    "for i in range(canales_finales):\n",
    "    for j in range(tamanyo):\n",
    "        for k in range(tamanyo):\n",
    "            if (salida4_total_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k] == (665729*16*9)+1):\n",
    "                print(\"i:\", i, \"j:\", j, \"k:\", k)\n",
    "            if (abs(salida4_total_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k] - veamos1[i][j][k])) > 1e-01:\n",
    "                print(\"i:\", i, \"j:\", j, \"k:\", k, salida4_total_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k], veamos1[i][j][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 3: emulation\n",
    "Creat & build program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl.Context at 0x8292bb8 on <pyopencl.Device 'Intel(R) FPGA Emulation Device' on 'Intel(R) FPGA Emulation Platform for OpenCL(TM)' at 0x71e8c88>>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platforms = cl.get_platforms()\n",
    "context = cl.Context(\n",
    "        dev_type=cl.device_type.ALL,\n",
    "        properties=[(cl.context_properties.PLATFORM, platforms[1])])\n",
    "device = platforms[1].get_devices()\n",
    "\n",
    "queue = cl.CommandQueue(context)\n",
    "queue1 = cl.CommandQueue(context)\n",
    "\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wksp = '../device/v1.3/squeezenet/bin_em/'\n",
    "\n",
    "file_dir = wksp + 'squeezenet_NDRange.aocx'\n",
    "\n",
    "kernelSource = open(file_dir, mode='rb').read()\n",
    "program_NDR = cl.Program(context, device, [kernelSource]).build()\n",
    "\n",
    "file_dir = wksp + 'squeezenet_ST.aocx'\n",
    "\n",
    "kernelSource = open(file_dir, mode='rb').read()\n",
    "program_ST = cl.Program(context, device, [kernelSource]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv3x3_NDR = program_NDR.conv2d3x3\n",
    "conv3x3_NDR.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "maxpool_NDR = program_NDR.maxpool2d\n",
    "maxpool_NDR.set_scalar_arg_dtypes([np.int32, np.int32, None, None])\n",
    "\n",
    "conv1x1_NDR = program_NDR.conv2d1x1\n",
    "conv1x1_NDR.set_scalar_arg_dtypes([np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "avgpool_NDR = program_NDR.avgpool2d\n",
    "avgpool_NDR.set_scalar_arg_dtypes([None, None])\n",
    "\n",
    "conv3x3_ST = program_ST.conv2d3x3\n",
    "conv3x3_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "maxpool_ST = program_ST.maxpool2d\n",
    "maxpool_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, None, None])\n",
    "\n",
    "conv1x1_ST = program_ST.conv2d1x1\n",
    "conv1x1_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "avgpool_ST = program_ST.avgpool2d\n",
    "avgpool_ST.set_scalar_arg_dtypes([None, None])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run OpenCL implement  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## BLOCK 1 ########\n",
    "#tamanyo=56 #input_size\n",
    "#canales_iniciales=64 #input channels and \n",
    "#canales_contraidos=16 #squeeze factor\n",
    "#canales_expandidos=64#expand factor\n",
    "\n",
    "######## BLOCK 2 ########\n",
    "tamanyo=28 #input_size\n",
    "canales_iniciales=128 #input channels and \n",
    "canales_contraidos=32 #squeeze factor\n",
    "canales_expandidos=128#expand factor\n",
    "\n",
    "################\n",
    "\n",
    "canales_finales= np.int32(canales_expandidos * 2)\n",
    "tamanyo_final = np.int32((tamanyo - 3 + 2 ) / 2)\n",
    "\n",
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "acumulado_pytorch = 0\n",
    "\n",
    "imagen = np.random.randint(1,size=(1,canales_iniciales, tamanyo, tamanyo))\n",
    "    \n",
    "weights1=np.random.randint(1,size=(canales_contraidos, canales_iniciales,1,1)).astype(np.float32)\n",
    "bias1=np.random.randint(1,size=(canales_contraidos,)).astype(np.float32)\n",
    "\n",
    "weights2a=np.random.randint(1,size=(canales_expandidos, canales_contraidos,1,1)).astype(np.float32)  \n",
    "bias2a=np.random.randint(1,size=(canales_expandidos,)).astype(np.float32)    \n",
    "\n",
    "weights2b=np.random.randint(1,size=(canales_expandidos, canales_contraidos,3,3)).astype(np.float32)    \n",
    "bias2b=np.random.randint(1,size=(canales_expandidos,)).astype(np.float32)\n",
    "\n",
    "weights3=np.random.randint(1,size=(canales_contraidos, canales_finales,1,1)).astype(np.float32)\n",
    "bias3=np.random.randint(1,size=(canales_contraidos,)).astype(np.float32)\n",
    "\n",
    "weights4a=np.random.randint(1,size=(canales_expandidos, canales_contraidos,1,1)).astype(np.float32)  \n",
    "bias4a=np.random.randint(1,size=(canales_expandidos,)).astype(np.float32)    \n",
    "\n",
    "weights4b=np.random.randint(1,size=(canales_expandidos, canales_contraidos,3,3)).astype(np.float32)    \n",
    "bias4b=np.random.randint(1,size=(canales_expandidos,)).astype(np.float32)\n",
    "\n",
    "imagen = np.ones((1,canales_iniciales, tamanyo, tamanyo))\n",
    "    \n",
    "weights1=np.ones((canales_contraidos, canales_iniciales,1,1)).astype(np.float32)\n",
    "bias1=np.ones((canales_contraidos,)).astype(np.float32)\n",
    "\n",
    "weights2a=np.ones((canales_expandidos, canales_contraidos,1,1)).astype(np.float32)  \n",
    "bias2a=np.ones((canales_expandidos,)).astype(np.float32)    \n",
    "\n",
    "weights2b=np.ones((canales_expandidos, canales_contraidos,3,3)).astype(np.float32)    \n",
    "bias2b=np.ones((canales_expandidos,)).astype(np.float32)\n",
    "\n",
    "weights3=np.ones((canales_contraidos, canales_finales,1,1)).astype(np.float32)\n",
    "bias3=np.ones((canales_contraidos,)).astype(np.float32)\n",
    "\n",
    "weights4a=np.ones((canales_expandidos, canales_contraidos,1,1)).astype(np.float32)  \n",
    "bias4a=np.ones((canales_expandidos,)).astype(np.float32)    \n",
    "\n",
    "weights4b=np.ones((canales_expandidos, canales_contraidos,3,3)).astype(np.float32)    \n",
    "bias4b=np.ones((canales_expandidos,)).astype(np.float32)\n",
    "\n",
    "\n",
    "imagen = np.random.randint(239,size=(1,canales_iniciales, tamanyo, tamanyo))\n",
    "params = torch.load('squeezenet1_1.pth')\n",
    "\n",
    "######## BLOCK 1 ########\n",
    "#fire - fire - maxpool block 1\n",
    "#weights1 = params['features.3.squeeze.weight'].numpy()\n",
    "#bias1 = params['features.3.squeeze.bias'].numpy()\n",
    "\n",
    "#weights2a = params['features.3.expand1x1.weight'].numpy()\n",
    "#bias2a = params['features.3.expand1x1.bias'].numpy()\n",
    "\n",
    "#weights2b = params['features.3.expand3x3.weight'].numpy()\n",
    "#bias2b = params['features.3.expand3x3.bias'].numpy()\n",
    "\n",
    "#weights3 = params['features.4.squeeze.weight'].numpy()\n",
    "#bias3 = params['features.4.squeeze.bias'].numpy()\n",
    "\n",
    "#weights4a = params['features.4.expand1x1.weight'].numpy()\n",
    "#bias4a = params['features.4.expand1x1.bias'].numpy()\n",
    "\n",
    "#weights4b = params['features.4.expand3x3.weight'].numpy()\n",
    "#bias4b = params['features.4.expand3x3.bias'].numpy()\n",
    "\n",
    "######## BLOCK 2 ########\n",
    "#fire - fire - maxpool block 2\n",
    "weights1 = params['features.6.squeeze.weight'].numpy()\n",
    "bias1 = params['features.6.squeeze.bias'].numpy()\n",
    "\n",
    "weights2a = params['features.6.expand1x1.weight'].numpy()\n",
    "bias2a = params['features.6.expand1x1.bias'].numpy()\n",
    "\n",
    "weights2b = params['features.6.expand3x3.weight'].numpy()\n",
    "bias2b = params['features.6.expand3x3.bias'].numpy()\n",
    "\n",
    "weights3 = params['features.7.squeeze.weight'].numpy()\n",
    "bias3 = params['features.7.squeeze.bias'].numpy()\n",
    "\n",
    "weights4a = params['features.7.expand1x1.weight'].numpy()\n",
    "bias4a = params['features.7.expand1x1.bias'].numpy()\n",
    "\n",
    "weights4b = params['features.7.expand3x3.weight'].numpy()\n",
    "bias4b = params['features.7.expand3x3.bias'].numpy()\n",
    "\n",
    "tic=pc()\n",
    "\n",
    "squeeze1=nn.Conv2d(canales_iniciales, canales_contraidos, kernel_size=1, bias=False)\n",
    "squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))    \n",
    "\n",
    "squeeze2a=nn.Conv2d(canales_contraidos, canales_expandidos, kernel_size=1, bias=False)\n",
    "squeeze2a.weight = nn.Parameter(torch.from_numpy(weights2a))\n",
    "squeeze2a.bias = nn.Parameter(torch.from_numpy(bias2a))\n",
    "\n",
    "squeeze2b=nn.Conv2d(canales_contraidos, canales_expandidos, kernel_size=3, bias=False, padding=1)\n",
    "squeeze2b.weight = nn.Parameter(torch.from_numpy(weights2b))\n",
    "squeeze2b.bias = nn.Parameter(torch.from_numpy(bias2b))\n",
    "\n",
    "squeeze3=nn.Conv2d(canales_finales, canales_contraidos, kernel_size=1, bias=False)\n",
    "squeeze3.weight = nn.Parameter(torch.from_numpy(weights3))\n",
    "squeeze3.bias = nn.Parameter(torch.from_numpy(bias3))    \n",
    "\n",
    "squeeze4a=nn.Conv2d(canales_contraidos, canales_expandidos, kernel_size=1, bias=False)\n",
    "squeeze4a.weight = nn.Parameter(torch.from_numpy(weights4a))\n",
    "squeeze4a.bias = nn.Parameter(torch.from_numpy(bias4a))\n",
    "\n",
    "squeeze4b=nn.Conv2d(canales_contraidos, canales_expandidos, kernel_size=3, bias=False, padding=1)\n",
    "squeeze4b.weight = nn.Parameter(torch.from_numpy(weights4b))\n",
    "squeeze4b.bias = nn.Parameter(torch.from_numpy(bias4b))\n",
    "\n",
    "pool2=nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "imagen1  = torch.from_numpy(imagen).float()\n",
    "\n",
    "salida1=squeeze1(imagen1)\n",
    "salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "salida2a=squeeze2a(salida1_activation)\n",
    "salida2a_activation=squeeze_activation(salida2a)\n",
    "salida2b=squeeze2b(salida1_activation)\n",
    "salida2b_activation=squeeze_activation(salida2b)    \n",
    "salida2_total=torch.cat([salida2a_activation,salida2b_activation], 1)\n",
    "\n",
    "salida3=squeeze3(salida2_total)\n",
    "salida3_activation=squeeze_activation(salida3)\n",
    "\n",
    "#salida3_test=salida3_activation.detach().numpy()\n",
    "\n",
    "salida4a=squeeze4a(salida3_activation)\n",
    "salida4a_activation=squeeze_activation(salida4a)\n",
    "salida4b=squeeze4b(salida3_activation)\n",
    "salida4b_activation=squeeze_activation(salida4b)    \n",
    "salida4_total=torch.cat([salida4a_activation,salida4b_activation], 1)\n",
    "\n",
    "salida_pool2=pool2(salida4_total)\n",
    "\n",
    "#salida4_total_a_numpy=salida4_total.detach().numpy()\n",
    "salida_pool2_a_numpy=salida_pool2.detach().numpy()\n",
    "\n",
    "toc=pc()\n",
    "\n",
    "acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "\n",
    "####### OPENCL COMPARISON #######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NDRANGE\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_squeeze_weight = weights1.reshape(-1)\n",
    "fire1_squeeze_bias = bias1\n",
    "fire1_expand1x1_weight = weights2a.reshape(-1)\n",
    "fire1_expand1x1_bias = bias2a\n",
    "fire1_expand3x3_weight =weights2b.reshape(-1)\n",
    "fire1_expand3x3_bias = bias2b\n",
    "\n",
    "fire2_squeeze_weight = weights3.reshape(-1)\n",
    "fire2_squeeze_bias = bias3\n",
    "fire2_expand1x1_weight = weights4a.reshape(-1)\n",
    "fire2_expand1x1_bias = bias4a\n",
    "fire2_expand3x3_weight =weights4b.reshape(-1)\n",
    "fire2_expand3x3_bias = bias4b\n",
    "\n",
    "h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire1_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "h_result_fire2_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire2_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "h_result_pool2 = np.empty(1 * canales_finales * tamanyo_final * tamanyo_final).astype(np.float32)\n",
    "\n",
    "d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "d_fire1_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_weight)\n",
    "d_fire1_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_bias)\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "d_fire2_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_weight)\n",
    "d_fire2_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_bias)\n",
    "d_fire2_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_weight)\n",
    "d_fire2_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_bias)\n",
    "d_fire2_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_weight)\n",
    "d_fire2_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_bias)\n",
    "\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "\n",
    "d_result_fire2_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_squeeze.nbytes)\n",
    "d_result_fire2_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_expand.nbytes)\n",
    "\n",
    "d_result_pool2 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool2.nbytes)\n",
    "\n",
    "tic2 = pc()\n",
    "\n",
    "conv1x1_NDR(queue,(canales_contraidos, tamanyo), None, np.int32(canales_iniciales/4), tamanyo, d_sample, d_fire1_squeeze_weight, d_fire1_squeeze_bias, d_result_fire1_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_NDR(queue1,(canales_expandidos, tamanyo), None, np.int32(canales_contraidos/4), tamanyo, d_result_fire1_squeeze, d_fire1_expand1x1_weight, d_fire1_expand1x1_bias, d_result_fire1_expand)\n",
    "conv3x3_NDR(queue,(canales_expandidos, tamanyo), None, canales_contraidos, tamanyo, 1, 1, canales_expandidos, tamanyo, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "conv1x1_NDR(queue,(canales_contraidos, tamanyo), None, np.int32(canales_finales/4), tamanyo, d_result_fire1_expand, d_fire2_squeeze_weight, d_fire2_squeeze_bias, d_result_fire2_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_NDR(queue1,(canales_expandidos, tamanyo), None, np.int32(canales_contraidos/4), tamanyo, d_result_fire2_squeeze, d_fire2_expand1x1_weight, d_fire2_expand1x1_bias, d_result_fire2_expand)\n",
    "conv3x3_NDR(queue,(canales_expandidos, tamanyo), None, canales_contraidos, tamanyo, 1, 1, canales_expandidos, tamanyo, d_result_fire2_squeeze, d_fire2_expand3x3_weight, d_fire2_expand3x3_bias, d_result_fire2_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "maxpool_NDR(queue, (canales_finales, ), None, tamanyo, tamanyo_final, d_result_fire2_expand, d_result_pool2)\n",
    "\n",
    "#cl.enqueue_copy(queue, h_result_fire2_expand, d_result_fire2_expand)\n",
    "cl.enqueue_copy(queue, h_result_pool2, d_result_pool2)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "#veamos = h_result_fire2_expand.reshape(-1,tamanyo,tamanyo)\n",
    "veamos = h_result_pool2.reshape(-1,tamanyo_final,tamanyo_final)\n",
    "\n",
    "rtime = pc() - tic2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple task\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_squeeze_weight = weights1.reshape(-1)\n",
    "fire1_squeeze_bias = bias1\n",
    "fire1_expand1x1_weight = weights2a.reshape(-1)\n",
    "fire1_expand1x1_bias = bias2a\n",
    "fire1_expand3x3_weight =weights2b.reshape(-1)\n",
    "fire1_expand3x3_bias = bias2b\n",
    "\n",
    "fire2_squeeze_weight = weights3.reshape(-1)\n",
    "fire2_squeeze_bias = bias3\n",
    "fire2_expand1x1_weight = weights4a.reshape(-1)\n",
    "fire2_expand1x1_bias = bias4a\n",
    "fire2_expand3x3_weight =weights4b.reshape(-1)\n",
    "fire2_expand3x3_bias = bias4b\n",
    "\n",
    "h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire1_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "h_result_fire2_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire2_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "h_result_pool2 = np.empty(1 * canales_finales * tamanyo_final * tamanyo_final).astype(np.float32)\n",
    "\n",
    "d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "d_fire1_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_weight)\n",
    "d_fire1_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_bias)\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "d_fire2_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_weight)\n",
    "d_fire2_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_bias)\n",
    "d_fire2_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_weight)\n",
    "d_fire2_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_bias)\n",
    "d_fire2_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_weight)\n",
    "d_fire2_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_bias)\n",
    "\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "\n",
    "d_result_fire2_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_squeeze.nbytes)\n",
    "d_result_fire2_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_expand.nbytes)\n",
    "\n",
    "d_result_pool2 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool2.nbytes)\n",
    "\n",
    "tic3 = pc()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, canales_iniciales, tamanyo, canales_contraidos, d_sample, d_fire1_squeeze_weight, d_fire1_squeeze_bias, d_result_fire1_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_ST(queue1,(1,), None, canales_contraidos, tamanyo, canales_expandidos, d_result_fire1_squeeze, d_fire1_expand1x1_weight, d_fire1_expand1x1_bias, d_result_fire1_expand)\n",
    "conv3x3_ST(queue,(1,), None, canales_contraidos, tamanyo, 1, 1, canales_expandidos, tamanyo, canales_expandidos, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, canales_finales, tamanyo, canales_contraidos, d_result_fire1_expand, d_fire2_squeeze_weight, d_fire2_squeeze_bias, d_result_fire2_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_ST(queue1,(1,), None, canales_contraidos, tamanyo, canales_expandidos, d_result_fire2_squeeze, d_fire2_expand1x1_weight, d_fire2_expand1x1_bias, d_result_fire2_expand)\n",
    "conv3x3_ST(queue,(1,), None, canales_contraidos, tamanyo, 1, 1, canales_expandidos, tamanyo, canales_expandidos, d_result_fire2_squeeze, d_fire2_expand3x3_weight, d_fire2_expand3x3_bias, d_result_fire2_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "maxpool_ST(queue, (1, ), None, tamanyo, tamanyo_final, canales_finales, d_result_fire2_expand, d_result_pool2)\n",
    "\n",
    "#cl.enqueue_copy(queue, h_result_fire2_expand, d_result_fire2_expand)\n",
    "cl.enqueue_copy(queue, h_result_pool2, d_result_pool2)\n",
    "\n",
    "#veamos1 = h_result_fire2_expand.reshape(-1,tamanyo,tamanyo)\n",
    "veamos1 = h_result_pool2.reshape(-1,tamanyo_final,tamanyo_final)\n",
    "\n",
    "rtime1 = pc() - tic3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo en segundos con pytorch=  0.008962621000137005\n",
      "tiempo en segundos con opencl (NDRANGE)= 0.05659885700015366\n",
      "tiempo en segundos con opencl (Simple Task)= 0.09984346100009134\n",
      "comparativa (pytorch == NDRange):  True\n",
      "comparativa (pytorch == Simple Task):  True\n",
      "comparativa (NDRange == Simple Task):  True\n"
     ]
    }
   ],
   "source": [
    "print (\"tiempo en segundos con pytorch= \", toc-tic)\n",
    "print (\"tiempo en segundos con opencl (NDRANGE)=\",rtime)\n",
    "print (\"tiempo en segundos con opencl (Simple Task)=\",rtime1)\n",
    "\n",
    "comparativa1=np.allclose(h_result_pool2.reshape(-1,tamanyo_final,tamanyo_final), veamos,rtol=1e-01, atol=1e-01)\n",
    "comparativa2=np.allclose(h_result_pool2.reshape(-1,tamanyo_final,tamanyo_final), veamos1,rtol=1e-01, atol=1e-01)\n",
    "comparativa3=np.allclose(veamos, veamos1,rtol=1e-01, atol=1e-01)\n",
    "\n",
    "print(\"comparativa (pytorch == NDRange): \",comparativa1)\n",
    "print(\"comparativa (pytorch == Simple Task): \",comparativa2)\n",
    "print(\"comparativa (NDRange == Simple Task): \",comparativa3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(canales_finales):\n",
    "    for j in range(tamanyo_final):\n",
    "        for k in range(tamanyo_final):\n",
    "            if (abs(h_result_pool2.reshape(-1,tamanyo_final,tamanyo_final)[i][j][k] - veamos1[i][j][k])) > 1e-01:\n",
    "                print(\"i:\", i, \"j:\", j, \"k:\", k, h_result_pool2.reshape(-1,tamanyo_final,tamanyo_final)[i][j][k], veamos1[i][j][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 4: simulación\n",
    "Creat & build program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl.Context at 0x43f1e50 on <pyopencl.Device 'SimulatorDevice : Multi-process Simulator (aclmsim0)' on 'Intel(R) FPGA SDK for OpenCL(TM)' at 0x7f1c313bd0d8>>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platforms = cl.get_platforms()\n",
    "context = cl.Context(\n",
    "        dev_type=cl.device_type.ALL,\n",
    "        properties=[(cl.context_properties.PLATFORM, platforms[2])])\n",
    "device = platforms[2].get_devices()\n",
    "\n",
    "queue = cl.CommandQueue(context)\n",
    "queue1 = cl.CommandQueue(context)\n",
    "\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joerock/anaconda3/envs/TFM/lib/python3.8/site-packages/pyopencl/__init__.py:270: CompilerWarning: Non-empty compiler output encountered. Set the environment variable PYOPENCL_COMPILER_OUTPUT=1 to see more.\n",
      "  warn(\"Non-empty compiler output encountered. Set the \"\n"
     ]
    }
   ],
   "source": [
    "wksp = '../device/v1.3/squeezenet/bin_sim/'\n",
    "\n",
    "file_dir = wksp + 'squeezenet_NDRange.aocx'\n",
    "\n",
    "kernelSource = open(file_dir, mode='rb').read()\n",
    "program_NDR = cl.Program(context, device, [kernelSource]).build()\n",
    "\n",
    "file_dir = wksp + 'squeezenet_ST.aocx'\n",
    "\n",
    "kernelSource = open(file_dir, mode='rb').read()\n",
    "program_ST = cl.Program(context, device, [kernelSource]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv3x3_NDR = program_NDR.conv2d3x3\n",
    "conv3x3_NDR.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "maxpool_NDR = program_NDR.maxpool2d\n",
    "maxpool_NDR.set_scalar_arg_dtypes([np.int32, np.int32, None, None])\n",
    "\n",
    "conv1x1_NDR = program_NDR.conv2d1x1\n",
    "conv1x1_NDR.set_scalar_arg_dtypes([np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "avgpool_NDR = program_NDR.avgpool2d\n",
    "avgpool_NDR.set_scalar_arg_dtypes([None, None])\n",
    "\n",
    "conv3x3_ST = program_ST.conv2d3x3\n",
    "conv3x3_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "maxpool_ST = program_ST.maxpool2d\n",
    "maxpool_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, None, None])\n",
    "\n",
    "conv1x1_ST = program_ST.conv2d1x1\n",
    "conv1x1_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "avgpool_ST = program_ST.avgpool2d\n",
    "avgpool_ST.set_scalar_arg_dtypes([None, None])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run OpenCL implement  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanyo=5 #input_size\n",
    "canales_iniciales=8 #input channels and \n",
    "canales_contraidos=4 #squeeze factor\n",
    "canales_expandidos=4#expand factor\n",
    "canales_finales= np.int32(canales_expandidos * 2)\n",
    "tamanyo_final = np.int32((tamanyo - 3 + 2 ) / 2)\n",
    "\n",
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "acumulado_pytorch = 0\n",
    "\n",
    "imagen = np.ones((1,canales_iniciales, tamanyo, tamanyo))\n",
    "    \n",
    "weights1=np.ones((canales_contraidos, canales_iniciales,1,1)).astype(np.float32)\n",
    "bias1=np.ones((canales_contraidos,)).astype(np.float32)\n",
    "\n",
    "weights2a=np.ones((canales_expandidos, canales_contraidos,1,1)).astype(np.float32)  \n",
    "bias2a=np.ones((canales_expandidos,)).astype(np.float32)    \n",
    "\n",
    "weights2b=np.ones((canales_expandidos, canales_contraidos,3,3)).astype(np.float32)    \n",
    "bias2b=np.ones((canales_expandidos,)).astype(np.float32)\n",
    "\n",
    "weights3=np.ones((canales_contraidos, canales_finales,1,1)).astype(np.float32)\n",
    "bias3=np.ones((canales_contraidos,)).astype(np.float32)\n",
    "\n",
    "weights4a=np.ones((canales_expandidos, canales_contraidos,1,1)).astype(np.float32)  \n",
    "bias4a=np.ones((canales_expandidos,)).astype(np.float32)    \n",
    "\n",
    "weights4b=np.ones((canales_expandidos, canales_contraidos,3,3)).astype(np.float32)    \n",
    "bias4b=np.ones((canales_expandidos,)).astype(np.float32)\n",
    "\n",
    "\n",
    "imagen = np.random.randint(239,size=(1,canales_iniciales, tamanyo, tamanyo))\n",
    "#params = torch.load('squeezenet1_1.pth')\n",
    "\n",
    "#fire - fire - maxpool block 1\n",
    "#weights1 = params['features.3.squeeze.weight'].numpy()\n",
    "#bias1 = params['features.3.squeeze.bias'].numpy()\n",
    "\n",
    "#weights2a = params['features.3.expand1x1.weight'].numpy()\n",
    "#bias2a = params['features.3.expand1x1.bias'].numpy()\n",
    "\n",
    "#weights2b = params['features.3.expand3x3.weight'].numpy()\n",
    "#bias2b = params['features.3.expand3x3.bias'].numpy()\n",
    "\n",
    "#weights3 = params['features.4.squeeze.weight'].numpy()\n",
    "#bias3 = params['features.4.squeeze.bias'].numpy()\n",
    "\n",
    "#weights4a = params['features.4.expand1x1.weight'].numpy()\n",
    "#bias4a = params['features.4.expand1x1.bias'].numpy()\n",
    "\n",
    "#weights4b = params['features.4.expand3x3.weight'].numpy()\n",
    "#bias4b = params['features.4.expand3x3.bias'].numpy()\n",
    "    \n",
    "weights1=np.random.rand(canales_contraidos, canales_iniciales,1,1).astype(np.float32)\n",
    "bias1=np.random.rand(canales_contraidos,).astype(np.float32)\n",
    "\n",
    "weights2a=np.random.rand(canales_expandidos, canales_contraidos,1,1).astype(np.float32)  \n",
    "bias2a=np.random.rand(canales_expandidos,).astype(np.float32)    \n",
    "\n",
    "weights2b=np.random.rand(canales_expandidos, canales_contraidos,3,3).astype(np.float32)    \n",
    "bias2b=np.random.rand(canales_expandidos,).astype(np.float32)\n",
    "\n",
    "weights3=np.random.rand(canales_contraidos, canales_finales,1,1).astype(np.float32)\n",
    "bias3=np.random.rand(canales_contraidos,).astype(np.float32)\n",
    "\n",
    "weights4a=np.random.rand(canales_expandidos, canales_contraidos,1,1).astype(np.float32)  \n",
    "bias4a=np.random.rand(canales_expandidos,).astype(np.float32)    \n",
    "\n",
    "weights4b=np.random.rand(canales_expandidos, canales_contraidos,3,3).astype(np.float32)    \n",
    "bias4b=np.random.rand(canales_expandidos,).astype(np.float32)\n",
    "\n",
    "tic=pc()\n",
    "\n",
    "squeeze1=nn.Conv2d(canales_iniciales, canales_contraidos, kernel_size=1, bias=False)\n",
    "squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))    \n",
    "\n",
    "squeeze2a=nn.Conv2d(canales_contraidos, canales_expandidos, kernel_size=1, bias=False)\n",
    "squeeze2a.weight = nn.Parameter(torch.from_numpy(weights2a))\n",
    "squeeze2a.bias = nn.Parameter(torch.from_numpy(bias2a))\n",
    "\n",
    "squeeze2b=nn.Conv2d(canales_contraidos, canales_expandidos, kernel_size=3, bias=False, padding=1)\n",
    "squeeze2b.weight = nn.Parameter(torch.from_numpy(weights2b))\n",
    "squeeze2b.bias = nn.Parameter(torch.from_numpy(bias2b))\n",
    "\n",
    "squeeze3=nn.Conv2d(canales_finales, canales_contraidos, kernel_size=1, bias=False)\n",
    "squeeze3.weight = nn.Parameter(torch.from_numpy(weights3))\n",
    "squeeze3.bias = nn.Parameter(torch.from_numpy(bias3))    \n",
    "\n",
    "squeeze4a=nn.Conv2d(canales_contraidos, canales_expandidos, kernel_size=1, bias=False)\n",
    "squeeze4a.weight = nn.Parameter(torch.from_numpy(weights4a))\n",
    "squeeze4a.bias = nn.Parameter(torch.from_numpy(bias4a))\n",
    "\n",
    "squeeze4b=nn.Conv2d(canales_contraidos, canales_expandidos, kernel_size=3, bias=False, padding=1)\n",
    "squeeze4b.weight = nn.Parameter(torch.from_numpy(weights4b))\n",
    "squeeze4b.bias = nn.Parameter(torch.from_numpy(bias4b))\n",
    "\n",
    "pool2=nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "imagen1  = torch.from_numpy(imagen).float()\n",
    "\n",
    "salida1=squeeze1(imagen1)\n",
    "salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "salida2a=squeeze2a(salida1_activation)\n",
    "salida2a_activation=squeeze_activation(salida2a)\n",
    "salida2b=squeeze2b(salida1_activation)\n",
    "salida2b_activation=squeeze_activation(salida2b)    \n",
    "salida2_total=torch.cat([salida2a_activation,salida2b_activation], 1)\n",
    "\n",
    "salida3=squeeze3(salida2_total)\n",
    "salida3_activation=squeeze_activation(salida3)\n",
    "\n",
    "#salida3_test=salida3_activation.detach().numpy()\n",
    "\n",
    "salida4a=squeeze4a(salida3_activation)\n",
    "salida4a_activation=squeeze_activation(salida4a)\n",
    "salida4b=squeeze4b(salida3_activation)\n",
    "salida4b_activation=squeeze_activation(salida4b)    \n",
    "salida4_total=torch.cat([salida4a_activation,salida4b_activation], 1)\n",
    "\n",
    "salida_pool2=pool2(salida4_total)\n",
    "\n",
    "#salida4_total_a_numpy=salida4_total.detach().numpy()\n",
    "salida_pool2_a_numpy=salida_pool2.detach().numpy()\n",
    "\n",
    "toc=pc()\n",
    "\n",
    "acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "\n",
    "####### OPENCL COMPARISON #######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4314/1359629572.py:20: RuntimeWarning: overflow encountered in cast\n",
      "  h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
      "/tmp/ipykernel_4314/1359629572.py:21: RuntimeWarning: overflow encountered in cast\n",
      "  h_result_fire1_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n",
      "/tmp/ipykernel_4314/1359629572.py:24: RuntimeWarning: overflow encountered in cast\n",
      "  h_result_fire2_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n"
     ]
    }
   ],
   "source": [
    "# NDRANGE\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_squeeze_weight = weights1.reshape(-1)\n",
    "fire1_squeeze_bias = bias1\n",
    "fire1_expand1x1_weight = weights2a.reshape(-1)\n",
    "fire1_expand1x1_bias = bias2a\n",
    "fire1_expand3x3_weight =weights2b.reshape(-1)\n",
    "fire1_expand3x3_bias = bias2b\n",
    "\n",
    "fire2_squeeze_weight = weights3.reshape(-1)\n",
    "fire2_squeeze_bias = bias3\n",
    "fire2_expand1x1_weight = weights4a.reshape(-1)\n",
    "fire2_expand1x1_bias = bias4a\n",
    "fire2_expand3x3_weight =weights4b.reshape(-1)\n",
    "fire2_expand3x3_bias = bias4b\n",
    "\n",
    "h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire1_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "h_result_fire2_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire2_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "h_result_pool2 = np.empty(1 * canales_finales * tamanyo_final * tamanyo_final).astype(np.float32)\n",
    "\n",
    "d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "d_fire1_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_weight)\n",
    "d_fire1_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_bias)\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "d_fire2_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_weight)\n",
    "d_fire2_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_bias)\n",
    "d_fire2_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_weight)\n",
    "d_fire2_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_bias)\n",
    "d_fire2_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_weight)\n",
    "d_fire2_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_bias)\n",
    "\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "\n",
    "d_result_fire2_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_squeeze.nbytes)\n",
    "d_result_fire2_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_expand.nbytes)\n",
    "\n",
    "d_result_pool2 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool2.nbytes)\n",
    "\n",
    "tic2 = pc()\n",
    "\n",
    "conv1x1_NDR(queue,(canales_contraidos, tamanyo), None, np.int32(canales_iniciales/4), tamanyo, d_sample, d_fire1_squeeze_weight, d_fire1_squeeze_bias, d_result_fire1_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_NDR(queue1,(canales_expandidos, tamanyo), None, np.int32(canales_contraidos/4), tamanyo, d_result_fire1_squeeze, d_fire1_expand1x1_weight, d_fire1_expand1x1_bias, d_result_fire1_expand)\n",
    "conv3x3_NDR(queue,(canales_expandidos, tamanyo), None, canales_contraidos, tamanyo, 1, 1, canales_expandidos, tamanyo, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "conv1x1_NDR(queue,(canales_contraidos, tamanyo), None, np.int32(canales_finales/4), tamanyo, d_result_fire1_expand, d_fire2_squeeze_weight, d_fire2_squeeze_bias, d_result_fire2_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_NDR(queue1,(canales_expandidos, tamanyo), None, np.int32(canales_contraidos/4), tamanyo, d_result_fire2_squeeze, d_fire2_expand1x1_weight, d_fire2_expand1x1_bias, d_result_fire2_expand)\n",
    "conv3x3_NDR(queue,(canales_expandidos, tamanyo), None, canales_contraidos, tamanyo, 1, 1, canales_expandidos, tamanyo, d_result_fire2_squeeze, d_fire2_expand3x3_weight, d_fire2_expand3x3_bias, d_result_fire2_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "maxpool_NDR(queue, (canales_finales, ), None, tamanyo, tamanyo_final, d_result_fire2_expand, d_result_pool2)\n",
    "\n",
    "#cl.enqueue_copy(queue, h_result_fire2_expand, d_result_fire2_expand)\n",
    "cl.enqueue_copy(queue, h_result_pool2, d_result_pool2)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "#veamos = h_result_fire2_expand.reshape(-1,tamanyo,tamanyo)\n",
    "veamos = h_result_pool2.reshape(-1,tamanyo_final,tamanyo_final)\n",
    "\n",
    "rtime = pc() - tic2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4314/2707542369.py:23: RuntimeWarning: overflow encountered in cast\n",
      "  h_result_fire2_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n"
     ]
    }
   ],
   "source": [
    "# Simple task\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_squeeze_weight = weights1.reshape(-1)\n",
    "fire1_squeeze_bias = bias1\n",
    "fire1_expand1x1_weight = weights2a.reshape(-1)\n",
    "fire1_expand1x1_bias = bias2a\n",
    "fire1_expand3x3_weight =weights2b.reshape(-1)\n",
    "fire1_expand3x3_bias = bias2b\n",
    "\n",
    "fire2_squeeze_weight = weights3.reshape(-1)\n",
    "fire2_squeeze_bias = bias3\n",
    "fire2_expand1x1_weight = weights4a.reshape(-1)\n",
    "fire2_expand1x1_bias = bias4a\n",
    "fire2_expand3x3_weight =weights4b.reshape(-1)\n",
    "fire2_expand3x3_bias = bias4b\n",
    "\n",
    "h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire1_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "h_result_fire2_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire2_expand = np.empty(1 * canales_finales * tamanyo * tamanyo).astype(np.float32)\n",
    "\n",
    "h_result_pool2 = np.empty(1 * canales_finales * tamanyo_final * tamanyo_final).astype(np.float32)\n",
    "\n",
    "d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "d_fire1_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_weight)\n",
    "d_fire1_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_bias)\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "d_fire2_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_weight)\n",
    "d_fire2_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_bias)\n",
    "d_fire2_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_weight)\n",
    "d_fire2_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_bias)\n",
    "d_fire2_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_weight)\n",
    "d_fire2_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_bias)\n",
    "\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "\n",
    "d_result_fire2_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_squeeze.nbytes)\n",
    "d_result_fire2_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_expand.nbytes)\n",
    "\n",
    "d_result_pool2 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool2.nbytes)\n",
    "\n",
    "tic3 = pc()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, canales_iniciales, tamanyo, canales_contraidos, d_sample, d_fire1_squeeze_weight, d_fire1_squeeze_bias, d_result_fire1_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_ST(queue1,(1,), None, canales_contraidos, tamanyo, canales_expandidos, d_result_fire1_squeeze, d_fire1_expand1x1_weight, d_fire1_expand1x1_bias, d_result_fire1_expand)\n",
    "conv3x3_ST(queue,(1,), None, canales_contraidos, tamanyo, 1, 1, canales_expandidos, tamanyo, canales_expandidos, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "conv1x1_ST(queue,(1,), None, canales_finales, tamanyo, canales_contraidos, d_result_fire1_expand, d_fire2_squeeze_weight, d_fire2_squeeze_bias, d_result_fire2_squeeze)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "conv1x1_ST(queue1,(1,), None, canales_contraidos, tamanyo, canales_expandidos, d_result_fire2_squeeze, d_fire2_expand1x1_weight, d_fire2_expand1x1_bias, d_result_fire2_expand)\n",
    "conv3x3_ST(queue,(1,), None, canales_contraidos, tamanyo, 1, 1, canales_expandidos, tamanyo, canales_expandidos, d_result_fire2_squeeze, d_fire2_expand3x3_weight, d_fire2_expand3x3_bias, d_result_fire2_expand)\n",
    "\n",
    "queue.finish()\n",
    "queue1.finish()\n",
    "\n",
    "maxpool_ST(queue, (1, ), None, tamanyo, tamanyo_final, canales_finales, d_result_fire2_expand, d_result_pool2)\n",
    "\n",
    "#cl.enqueue_copy(queue, h_result_fire2_expand, d_result_fire2_expand)\n",
    "cl.enqueue_copy(queue, h_result_pool2, d_result_pool2)\n",
    "\n",
    "#veamos1 = h_result_fire2_expand.reshape(-1,tamanyo,tamanyo)\n",
    "veamos1 = h_result_pool2.reshape(-1,tamanyo_final,tamanyo_final)\n",
    "\n",
    "rtime1 = pc() - tic3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo en segundos con pytorch=  0.0010922950000349374\n",
      "tiempo en segundos con opencl (NDRANGE)= 423.794803107\n",
      "tiempo en segundos con opencl (Simple Task)= 1226.4308158269998\n",
      "comparativa (pytorch == NDRange):  True\n",
      "comparativa (pytorch == Simple Task):  True\n",
      "comparativa (NDRange == Simple Task):  True\n"
     ]
    }
   ],
   "source": [
    "print (\"tiempo en segundos con pytorch= \", toc-tic)\n",
    "print (\"tiempo en segundos con opencl (NDRANGE)=\",rtime)\n",
    "print (\"tiempo en segundos con opencl (Simple Task)=\",rtime1)\n",
    "\n",
    "comparativa1=np.allclose(h_result_pool2.reshape(-1,tamanyo_final,tamanyo_final), veamos,rtol=1e-01, atol=1e-01)\n",
    "comparativa2=np.allclose(h_result_pool2.reshape(-1,tamanyo_final,tamanyo_final), veamos1,rtol=1e-01, atol=1e-01)\n",
    "comparativa3=np.allclose(veamos, veamos1,rtol=1e-01, atol=1e-01)\n",
    "\n",
    "print(\"comparativa (pytorch == NDRange): \",comparativa1)\n",
    "print(\"comparativa (pytorch == Simple Task): \",comparativa2)\n",
    "print(\"comparativa (NDRange == Simple Task): \",comparativa3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch (2, 5, 5) [123. 151. 184. 152. 138.]\n",
      "NDRange [123. 151. 184. 152. 138.]\n",
      "Simple task [ 77.  71. 126. 184. 132.]\n",
      "(1, 8, 5, 5) False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"pytorch\", veamos.shape, salida1_a_numpy.reshape(-1,tamanyo,tamanyo)[0][0])\n",
    "print(\"NDRange\", veamos[0][0])\n",
    "print(\"Simple task\", veamos1[0][0])\n",
    "print(imagen.shape, np.allclose(imagen, np.ones((1,canales_iniciales, tamanyo, tamanyo)).astype(np.float32), rtol=1e-01, atol=1e-01))\n",
    "#print(weights1[6])\n",
    "# print(fire1_squeeze_weight)\n",
    "#print(bias1[6])\n",
    "# print(imagen1_obtenida)\n",
    "# print(veamos2)\n",
    "print(np.allclose(salida1_a_numpy, veamos1,rtol=1e-01, atol=1e-01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(canales_finales):\n",
    "    for j in range(tamanyo_final):\n",
    "        for k in range(tamanyo_final):\n",
    "            if (abs(h_result_pool2.reshape(-1,tamanyo_final,tamanyo_final)[i][j][k] - veamos1[i][j][k])) > 1e-01:\n",
    "                print(\"i:\", i, \"j:\", j, \"k:\", k, h_result_pool2.reshape(-1,tamanyo_final,tamanyo_final)[i][j][k], veamos1[i][j][k])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
