{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug SqueezeNet v1.3 (Simple Task) OpenCL implement with PyOpenCL and PyTorch\n",
    "Partial code are copied heavily from https://github.com/pytorch/vision/blob/master/torchvision/models/squeezenet.py  \n",
    "SqueezeNet Paper:https://arxiv.org/abs/1602.07360  \n",
    "SqueezeNet 1.1 model from https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1   \n",
    "SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters than SqueezeNet 1.0, without sacrificing accuracy.\n",
    "\n",
    "TEST DE IMPLEMENTACIÓN CONV3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#some set up\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from PIL import Image\n",
    "import math\n",
    "import time\n",
    "from time import sleep, perf_counter as pc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aquí tenemos el medidor de pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En esta aproximacion tengo en cuenta el tiempo de definición de capas y la carga de pesos porque se supone que entre fire y fire estas operaciones tiene que hacerse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 50.  70.  88.  87. 124.]\n",
      "   [ 94. 140.  57. 138. 102.]\n",
      "   [ 78.  84.  96.  91. 119.]\n",
      "   [ 41. 108.  79.  77.  81.]\n",
      "   [ 66.  79. 121.  70.  62.]]\n",
      "\n",
      "  [[ 29. 101.  55.  86.  71.]\n",
      "   [ 86. 116.  37.  86.  75.]\n",
      "   [ 67.  95. 138.  28.  64.]\n",
      "   [ 30.  53.  99.  92.  83.]\n",
      "   [ 90.  71. 161.  58.  88.]]]]\n",
      "tiempo en segundos con pytorch=  0.00011299011999881259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "canales_iniciales=4 #input_channels\n",
    "canales_contraidos=2 #filter_size\n",
    "canales_finales= canales_iniciales\n",
    "acumulado_pytorch=0\n",
    "idea=True\n",
    "count=100\n",
    "tamanyo=5 #input_size\n",
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "for i in range(count):\n",
    "\n",
    "    imagen = np.random.randint(10,size=(1,canales_iniciales, tamanyo, tamanyo))\n",
    "    weights1=np.random.randint(10,size=(canales_contraidos, canales_iniciales,1,1)).astype(np.float32)\n",
    "    bias1=np.random.randint(10,size=(canales_contraidos,)).astype(np.float32)\n",
    "      \n",
    "    tic=pc()\n",
    "    squeeze1=nn.Conv2d(canales_iniciales, canales_contraidos, kernel_size=1, bias=False)\n",
    "    squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "    squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))    \n",
    "    imagen1  = torch.from_numpy(imagen).float()\n",
    "    \n",
    "    salida1=squeeze1(imagen1)\n",
    "    salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "    salida1_a_numpy=salida1_activation.detach().numpy()\n",
    "    \n",
    "    toc=pc()\n",
    "    \n",
    "    acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "    \n",
    "print(salida1_a_numpy)\n",
    "print (\"tiempo en segundos con pytorch= \", acumulado_pytorch/count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veamos ahora solo conv3x3 con opencl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OpenCL setup\n",
    "import pyopencl as cl\n",
    "import sys\n",
    "sys.path.append('../common')\n",
    "import deviceinfo\n",
    "from time import time\n",
    "\n",
    "#wksp = '../device/v1.3/conv3x3'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step0-A: compilation for emulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aoc: OpenCL kernel compilation completed successfully.\n",
      "aoc: Linking Object files....\n",
      "aoc: Compiling for Emulation ....\n",
      "aoc: OpenCL kernel compilation completed successfully.\n",
      "aoc: Linking Object files....\n",
      "aoc: Compiling for Emulation ....\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "aoc -march=emulator ../device/v1.3/conv3x3/conv3x3_NDRange.cl -o ../device/v1.3/conv3x3/bin_em/conv3x3_NDRange.aocx\n",
    "aoc -march=emulator ../device/v1.3/conv3x3/conv3x3_ST.cl -o ../device/v1.3/conv3x3/bin_em/conv3x3_ST.aocx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step0-B: compilation for simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aoc: Environment checks completed successfully.\n",
      "Quartus location: /home/joerock/intelFPGA_pro/21.1/quartus/bin/quartus_sh\n",
      "aoc: Cached files in /var/tmp/aocl/joerock may be used to reduce compilation time\n",
      "aoc: Selected target board package /home/joerock/intelFPGA_pro/21.1/hld/board/a10_ref\n",
      "aoc: Selected target board a10gx\n",
      "aoc: Running OpenCL parser....\n",
      "aoc: OpenCL parser completed \n",
      "aoc: Linking Object files....\n",
      "aoc: Optimizing and doing static analysis of code...\n",
      "aoc: Linking with IP library ...\n",
      "aoc: Checking if memory usage is larger than 100%...\n",
      "aoc: Memory usage is not above 100.\n",
      "aoc: First stage compilation completed successfully.\n",
      "aoc: Compiling for Simulator.\n",
      "Quartus location: /home/joerock/intelFPGA_pro/21.1/quartus/bin/quartus_sh\n",
      "Creating simulation system...\n",
      "Generating simulation system...\n",
      "Compiling simulation...\n",
      "aoc: Simulation generation done!\n",
      "Simulator flow is successful.\n",
      "To execute simulator, invoke host with \n",
      "\tenv CL_CONTEXT_MPSIM_DEVICE_INTELFPGA=1 <host_program>\n",
      "aoc: Environment checks completed successfully.\n",
      "Quartus location: /home/joerock/intelFPGA_pro/21.1/quartus/bin/quartus_sh\n",
      "aoc: Cached files in /var/tmp/aocl/joerock may be used to reduce compilation time\n",
      "aoc: Selected target board package /home/joerock/intelFPGA_pro/21.1/hld/board/a10_ref\n",
      "aoc: Selected target board a10gx\n",
      "aoc: Running OpenCL parser....\n",
      "aoc: OpenCL parser completed \n",
      "aoc: Linking Object files....\n",
      "aoc: Optimizing and doing static analysis of code...\n",
      "aoc: Linking with IP library ...\n",
      "aoc: Checking if memory usage is larger than 100%...\n",
      "aoc: Memory usage is not above 100.\n",
      "aoc: First stage compilation completed successfully.\n",
      "aoc: Compiling for Simulator.\n",
      "Quartus location: /home/joerock/intelFPGA_pro/21.1/quartus/bin/quartus_sh\n",
      "Creating simulation system...\n",
      "Generating simulation system...\n",
      "Compiling simulation...\n",
      "aoc: Simulation generation done!\n",
      "Simulator flow is successful.\n",
      "To execute simulator, invoke host with \n",
      "\tenv CL_CONTEXT_MPSIM_DEVICE_INTELFPGA=1 <host_program>\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "aoc -march=simulator -v -ghdl ../device/v1.3/conv3x3/conv3x3_NDRange.cl -o ../device/v1.3/conv3x3/bin_sim/conv3x3_NDRange.aocx -board=a10gx\n",
    "aoc -march=simulator -v -ghdl ../device/v1.3/conv3x3/conv3x3_ST.cl -o ../device/v1.3/conv3x3/bin_sim/conv3x3_ST.aocx -board=a10gx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step1: OpenCL preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl.Context at 0x687a4a8 on <pyopencl.Device '12th Gen Intel(R) Core(TM) i7-12650H' on 'Intel(R) OpenCL' at 0x4f7fab8>>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platforms = cl.get_platforms()\n",
    "context = cl.Context(\n",
    "        dev_type=cl.device_type.ALL,\n",
    "        properties=[(cl.context_properties.PLATFORM, platforms[0])])\n",
    "queue = cl.CommandQueue(context)\n",
    "\n",
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 2: creat kernels\n",
    "Creat & build program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joerock/anaconda3/envs/TFM/lib/python3.8/site-packages/pyopencl/__init__.py:270: CompilerWarning: Non-empty compiler output encountered. Set the environment variable PYOPENCL_COMPILER_OUTPUT=1 to see more.\n",
      "  warn(\"Non-empty compiler output encountered. Set the \"\n"
     ]
    }
   ],
   "source": [
    "wksp = '../device/v1.3/conv3x3/'\n",
    "\n",
    "file_dir = wksp + 'conv3x3_NDRange.cl'\n",
    "\n",
    "kernelSource = open(file_dir).read()\n",
    "program_NDR = cl.Program(context, kernelSource).build()\n",
    "\n",
    "file_dir = wksp + 'conv3x3_ST.cl'\n",
    "\n",
    "kernelSource = open(file_dir).read()\n",
    "program_ST = cl.Program(context, kernelSource).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creat kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv3x3_NDR = program_NDR.conv2d3x3\n",
    "conv3x3_NDR.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "conv3x3_ST = program_ST.conv2d3x3\n",
    "conv3x3_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenCL kernel: conv3x3_NDRange.cl\n",
    "\n",
    "conv2d3x3: 2-D 3x3 convolution.  \n",
    "\n",
    "```C\n",
    "//3x3 convolution layer\n",
    "//output one feature map per kernel\n",
    "__kernel void conv2d3x3(\n",
    "\tconst int input_channels, const int input_size,\n",
    "\tconst int pad, const int stride,\n",
    "\tconst int start_channel, //start_channel is for 1x1 feature map in fire layer\n",
    "\tconst int output_size,\n",
    "\t__global float* input_im,\n",
    "\t__global const float* filter_weight,\n",
    "\t__global const float* filter_bias,\n",
    "\t__global float *restrict output_im\n",
    "\t)\n",
    "{\n",
    "\tint filter_index = get_global_id(0); //get output channel index\n",
    "\tint i =  get_global_id(1);\n",
    "\n",
    "\tfilter_weight += filter_index * input_channels * 9;\n",
    "\tfloat bias = filter_bias[filter_index];\n",
    "\toutput_im += (start_channel + filter_index) * output_size * output_size;\n",
    "\t\n",
    "\t//loop over output feature map\n",
    "\t//for(int i = 0; i < output_size; i++)\n",
    "\t{\n",
    "\t\tfor(int j = 0; j < output_size; j++)\n",
    "\t\t{\n",
    "\t\t\t//compute one element in the output feature map\n",
    "\t\t\tfloat tmp = bias;\n",
    "\t\t\t\n",
    "\t\t\t//compute dot product of 2 input_channels x 3 x 3 matrix\n",
    "\t\t\tfor(int k = 0; k < input_channels; k++)\n",
    "\t\t\t{\n",
    "\t\t\t\t#pragma unroll\n",
    "\t\t\t\tfor(int l = 0; l < 3; l++)\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\tint h = i * stride + l - pad;\n",
    "\t\t\t\t\tfor(int m = 0; m < 3; m++)\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\tint w = j * stride + m - pad;\n",
    "\t\t\t\t\t\tif((h >= 0) && (h < input_size) && (w >= 0) && (w < input_size))\n",
    "\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\ttmp += input_im[k * input_size * input_size + h * input_size + w] \\\n",
    "                               * filter_weight[9 * k + 3 * l + m];\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\t//add relu activation after conv\n",
    "\t\t\toutput_im[i * output_size + j] = (tmp > 0.0) ? tmp : 0.0;\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "```\n",
    "#### OpenCL kernel: conv3x3_ST.cl\n",
    "\n",
    "conv2d3x3: 2-D 3x3 convolution. \n",
    "\n",
    "```C\n",
    "//3x3 convolution layer\n",
    "//output one feature map per kernel\n",
    "__kernel void conv2d3x3(\n",
    "\tconst int input_channels, const int input_size,\n",
    "\tconst int pad, const int stride,\n",
    "\tconst int start_channel, //start_channel is for 1x1 feature map in fire layer\n",
    "\tconst int output_size,\n",
    "    const int filter_size,\n",
    "\t__global float* input_im,\n",
    "\t__global const float* filter_weight,\n",
    "\t__global const float* filter_bias,\n",
    "\t__global float *restrict output_im\n",
    "\t)\n",
    "{\n",
    "\t\n",
    "\t//filter_weight += filter_index * input_channels * 9;\n",
    "\toutput_im += start_channel * output_size * output_size;\n",
    "\t\n",
    "\t//loop over output feature map\n",
    "\tfor(int filter_index = 0; filter_index < filter_size; filter_index++)\n",
    "\t{\n",
    "        float bias = filter_bias[filter_index];\n",
    "\n",
    "\t\tfor(int i = 0; i < output_size; i++)\n",
    "\t\t{\n",
    "            for(int j = 0; j < output_size; j++)\n",
    "            {\n",
    "                //compute one element in the output feature map\n",
    "                float tmp = bias;\n",
    "\n",
    "                //compute dot product of 2 input_channels x 3 x 3 matrix\n",
    "                for(int k = 0; k < input_channels; k++)\n",
    "                {\n",
    "                    #pragma unroll\n",
    "                    for(int l = 0; l < 3; l++)\n",
    "                    {\n",
    "                        int h = i * stride + l - pad;\n",
    "                        for(int m = 0; m < 3; m++)\n",
    "                        {\n",
    "                            int w = j * stride + m - pad;\n",
    "                            if((h >= 0) && (h < input_size) && (w >= 0) && (w < input_size))\n",
    "                            {\n",
    "                                tmp += input_im[k * input_size * input_size + h * input_size + w] \\\n",
    "                                   * filter_weight[9 * k + 3 * l + m];\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                //add relu activation after conv\n",
    "                output_im[i * output_size + j] = (tmp > 0.0) ? tmp : 0.0;                 \n",
    "            }\n",
    "\t\t}\n",
    "        \n",
    "        filter_weight += input_channels * 9;\n",
    "        output_im += output_size * output_size;\n",
    "\t}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run OpenCL implement  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanyo=56 #input_size\n",
    "canales_iniciales=64 #input_channels\n",
    "canales_contraidos=16 #filter_size\n",
    "canales_finales = 128\n",
    "\n",
    "acumulado_pytorch=0\n",
    "\n",
    "imagen = np.random.randint(10,size=(1,canales_contraidos, tamanyo, tamanyo)).astype(np.float32)\n",
    "#imagen = np.ones((1,canales_contraidos, tamanyo, tamanyo)).astype(np.float32)\n",
    "\n",
    "weights1=np.random.randint(10,size=(canales_iniciales, canales_contraidos, 3, 3)).astype(np.float32)\n",
    "bias1=np.random.randint(10,size=(canales_iniciales,)).astype(np.float32)\n",
    "\n",
    "#weights1=np.ones((canales_iniciales, canales_contraidos, 3, 3)).astype(np.float32)\n",
    "#bias1=np.ones((canales_iniciales,)).astype(np.float32)\n",
    "\n",
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "tic=pc()\n",
    "squeeze1=nn.Conv2d(canales_iniciales, canales_contraidos, kernel_size=3, bias=False, padding=1)\n",
    "squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))\n",
    "\n",
    "imagen1  = torch.from_numpy(imagen).float()\n",
    "\n",
    "salida1=squeeze1(imagen1)\n",
    "salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "salida1_a_numpy=salida1_activation.detach().numpy()\n",
    "\n",
    "toc=pc()\n",
    "acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "\n",
    "####### OPENCL COMPARISON #######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NDRANGE\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_expand3x3_weight = weights1.reshape(-1)\n",
    "fire1_expand3x3_bias = bias1\n",
    "\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "h_result_fire1_expand = np.empty(1 * canales_iniciales * tamanyo * tamanyo).astype(np.float32) # we wil only check 3x3 convolituional performance\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "\n",
    "#offset = np.int32(canales_iniciales)\n",
    "offset = np.int32(0)\n",
    "\n",
    "tic2 = pc()\n",
    "\n",
    "conv3x3_NDR(queue,(canales_iniciales, tamanyo), None, canales_contraidos, tamanyo, 1, 1, offset, tamanyo, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire1_expand, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos = h_result_fire1_expand.reshape(-1,tamanyo,tamanyo)\n",
    "\n",
    "rtime = pc() - tic2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple task\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_expand3x3_weight = weights1.reshape(-1)\n",
    "fire1_expand3x3_bias = bias1\n",
    "\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "h_result_fire1_expand = np.empty(1 * canales_iniciales * tamanyo * tamanyo).astype(np.float32) # we wil only check 3x3 convolituional performance\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "\n",
    "#offset = np.int32(canales_iniciales)\n",
    "offset = np.int32(0)\n",
    "\n",
    "tic3 = pc()\n",
    "\n",
    "conv3x3_ST(queue,(1,), None, np.int32(canales_contraidos), tamanyo, 1, 1, offset, tamanyo, canales_iniciales, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire1_expand, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos1 = h_result_fire1_expand.reshape(-1,tamanyo,tamanyo)\n",
    "\n",
    "rtime1 = pc() - tic3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo en segundos con pytorch=  0.23023968800043804\n",
      "tiempo en segundos con opencl (NDRANGE)= 0.03479939099997864\n",
      "tiempo en segundos con opencl (Simple Task)= 0.014478344000053767\n",
      "comparativa (pytorch == NDRange):  True\n",
      "comparativa (pytorch == Simple Task):  True\n",
      "comparativa (NDRange == Simple Task):  True\n"
     ]
    }
   ],
   "source": [
    "print (\"tiempo en segundos con pytorch= \", toc-tic)\n",
    "print (\"tiempo en segundos con opencl (NDRANGE)=\",rtime)\n",
    "print (\"tiempo en segundos con opencl (Simple Task)=\",rtime1)\n",
    "\n",
    "comparativa1=np.allclose(salida1_a_numpy, veamos,rtol=1e-01, atol=1e-01)\n",
    "comparativa2=np.allclose(salida1_a_numpy, veamos1,rtol=1e-01, atol=1e-01)\n",
    "comparativa3=np.allclose(veamos, veamos1,rtol=1e-01, atol=1e-01)\n",
    "\n",
    "print(\"comparativa (pytorch == NDRange): \",comparativa1)\n",
    "print(\"comparativa (pytorch == Simple Task): \",comparativa2)\n",
    "print(\"comparativa (NDRange == Simple Task): \",comparativa3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(canales_contraidos):\n",
    "    for j in range(tamanyo):\n",
    "        for k in range(tamanyo):\n",
    "            if (abs(salida1_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k] - veamos1[i][j][k])) > 1e-01:\n",
    "                print(\"i:\", i, \"j:\", j, \"k:\", k, salida1_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k], veamos1[i][j][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 3: emulation\n",
    "Creat & build program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl.Context at 0x67691f8 on <pyopencl.Device 'Intel(R) FPGA Emulation Device' on 'Intel(R) FPGA Emulation Platform for OpenCL(TM)' at 0x4f89ba8>>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platforms = cl.get_platforms()\n",
    "context = cl.Context(\n",
    "        dev_type=cl.device_type.ALL,\n",
    "        properties=[(cl.context_properties.PLATFORM, platforms[1])])\n",
    "device = platforms[1].get_devices()\n",
    "\n",
    "queue = cl.CommandQueue(context)\n",
    "\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "wksp = '../device/v1.3/conv3x3/bin_em/'\n",
    "\n",
    "file_dir = wksp + 'conv3x3_NDRange.aocx'\n",
    "\n",
    "kernelSource = open(file_dir, mode='rb').read()\n",
    "program_NDR = cl.Program(context, device, [kernelSource]).build()\n",
    "\n",
    "file_dir = wksp + 'conv3x3_ST.aocx'\n",
    "\n",
    "kernelSource = open(file_dir, mode='rb').read()\n",
    "program_ST = cl.Program(context, device, [kernelSource]).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creat kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv3x3_NDR = program_NDR.conv2d3x3\n",
    "conv3x3_NDR.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "conv3x3_ST = program_ST.conv2d3x3\n",
    "conv3x3_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run OpenCL implement  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanyo=56 #input_size\n",
    "canales_iniciales=64 #input_channels\n",
    "canales_contraidos=16 #filter_size\n",
    "canales_finales = 128\n",
    "\n",
    "acumulado_pytorch=0\n",
    "\n",
    "imagen = np.random.randint(10,size=(1,canales_contraidos, tamanyo, tamanyo)).astype(np.float32)\n",
    "#imagen = np.ones((1,canales_contraidos, tamanyo, tamanyo)).astype(np.float32)\n",
    "\n",
    "weights1=np.random.randint(10,size=(canales_iniciales, canales_contraidos, 3, 3)).astype(np.float32)\n",
    "bias1=np.random.randint(10,size=(canales_iniciales,)).astype(np.float32)\n",
    "\n",
    "#weights1=np.ones((canales_iniciales, canales_contraidos, 3, 3)).astype(np.float32)\n",
    "#bias1=np.ones((canales_iniciales,)).astype(np.float32)\n",
    "\n",
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "tic=pc()\n",
    "squeeze1=nn.Conv2d(canales_iniciales, canales_contraidos, kernel_size=3, bias=False, padding=1)\n",
    "squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))\n",
    "\n",
    "imagen1  = torch.from_numpy(imagen).float()\n",
    "\n",
    "salida1=squeeze1(imagen1)\n",
    "salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "salida1_a_numpy=salida1_activation.detach().numpy()\n",
    "\n",
    "toc=pc()\n",
    "acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "\n",
    "####### OPENCL COMPARISON #######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NDRANGE\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_expand3x3_weight = weights1.reshape(-1)\n",
    "fire1_expand3x3_bias = bias1\n",
    "\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "h_result_fire1_expand = np.empty(1 * canales_iniciales * tamanyo * tamanyo).astype(np.float32) # we wil only check 3x3 convolituional performance\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "\n",
    "#offset = np.int32(canales_iniciales)\n",
    "offset = np.int32(0)\n",
    "\n",
    "tic2 = pc()\n",
    "\n",
    "conv3x3_NDR(queue,(canales_iniciales, tamanyo), None, canales_contraidos, tamanyo, 1, 1, offset, tamanyo, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire1_expand, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos = h_result_fire1_expand.reshape(-1,tamanyo,tamanyo)\n",
    "\n",
    "rtime = pc() - tic2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple task\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_expand3x3_weight = weights1.reshape(-1)\n",
    "fire1_expand3x3_bias = bias1\n",
    "\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "h_result_fire1_expand = np.empty(1 * canales_iniciales * tamanyo * tamanyo).astype(np.float32) # we wil only check 3x3 convolituional performance\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "\n",
    "#offset = np.int32(canales_iniciales)\n",
    "offset = np.int32(0)\n",
    "\n",
    "tic3 = pc()\n",
    "\n",
    "conv3x3_ST(queue,(1,), None, np.int32(canales_contraidos), tamanyo, 1, 1, offset, tamanyo, canales_iniciales, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire1_expand, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos1 = h_result_fire1_expand.reshape(-1,tamanyo,tamanyo)\n",
    "\n",
    "rtime1 = pc() - tic3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo en segundos con pytorch=  0.0030234180003390065\n",
      "tiempo en segundos con opencl (NDRANGE)= 0.03991814599976351\n",
      "tiempo en segundos con opencl (Simple Task)= 0.04235464699922886\n",
      "comparativa (pytorch == NDRange):  True\n",
      "comparativa (pytorch == Simple Task):  True\n",
      "comparativa (NDRange == Simple Task):  True\n"
     ]
    }
   ],
   "source": [
    "print (\"tiempo en segundos con pytorch= \", toc-tic)\n",
    "print (\"tiempo en segundos con opencl (NDRANGE)=\",rtime)\n",
    "print (\"tiempo en segundos con opencl (Simple Task)=\",rtime1)\n",
    "\n",
    "comparativa1=np.allclose(salida1_a_numpy, veamos,rtol=1e-01, atol=1e-01)\n",
    "comparativa2=np.allclose(salida1_a_numpy, veamos1,rtol=1e-01, atol=1e-01)\n",
    "comparativa3=np.allclose(veamos, veamos1,rtol=1e-01, atol=1e-01)\n",
    "\n",
    "print(\"comparativa (pytorch == NDRange): \",comparativa1)\n",
    "print(\"comparativa (pytorch == Simple Task): \",comparativa2)\n",
    "print(\"comparativa (NDRange == Simple Task): \",comparativa3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(canales_contraidos):\n",
    "    for j in range(tamanyo):\n",
    "        for k in range(tamanyo):\n",
    "            if (abs(salida1_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k] - veamos1[i][j][k])) > 1e-01:\n",
    "                print(\"i:\", i, \"j:\", j, \"k:\", k, salida1_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k], veamos1[i][j][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 4: simulación\n",
    "Creat & build program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl.Context at 0x8e027b0 on <pyopencl.Device 'SimulatorDevice : Multi-process Simulator (aclmsim0)' on 'Intel(R) FPGA SDK for OpenCL(TM)' at 0x7f5963ab50d8>>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platforms = cl.get_platforms()\n",
    "context = cl.Context(\n",
    "        dev_type=cl.device_type.ALL,\n",
    "        properties=[(cl.context_properties.PLATFORM, platforms[2])])\n",
    "device = platforms[2].get_devices()\n",
    "\n",
    "queue = cl.CommandQueue(context)\n",
    "\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "wksp = '../device/v1.3/conv3x3/bin_sim/'\n",
    "\n",
    "file_dir = wksp + 'conv3x3_NDRange.aocx'\n",
    "\n",
    "kernelSource = open(file_dir, mode='rb').read()\n",
    "program_NDR = cl.Program(context, device, [kernelSource]).build()\n",
    "\n",
    "file_dir = wksp + 'conv3x3_ST.aocx'\n",
    "\n",
    "kernelSource = open(file_dir, mode='rb').read()\n",
    "program_ST = cl.Program(context, device, [kernelSource]).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creat kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv3x3_NDR = program_NDR.conv2d3x3\n",
    "conv3x3_NDR.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n",
    "\n",
    "conv3x3_ST = program_ST.conv2d3x3\n",
    "conv3x3_ST.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, None, None, None, None])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run OpenCL implement  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanyo=5 #input_size\n",
    "canales_iniciales=8 #input_channels\n",
    "canales_contraidos=2 #filter_size\n",
    "canales_finales = canales_iniciales\n",
    "\n",
    "acumulado_pytorch=0\n",
    "\n",
    "imagen = np.random.randint(10,size=(1,canales_contraidos, tamanyo, tamanyo)).astype(np.float32)\n",
    "#imagen = np.ones((1,canales_contraidos, tamanyo, tamanyo)).astype(np.float32)\n",
    "\n",
    "weights1=np.random.randint(10,size=(canales_iniciales, canales_contraidos, 3, 3)).astype(np.float32)\n",
    "bias1=np.random.randint(10,size=(canales_iniciales,)).astype(np.float32)\n",
    "\n",
    "#weights1=np.ones((canales_iniciales, canales_contraidos, 3, 3)).astype(np.float32)\n",
    "#bias1=np.ones((canales_iniciales,)).astype(np.float32)\n",
    "\n",
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "tic=pc()\n",
    "squeeze1=nn.Conv2d(canales_iniciales, canales_contraidos, kernel_size=3, bias=False, padding=1)\n",
    "squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))\n",
    "\n",
    "imagen1  = torch.from_numpy(imagen).float()\n",
    "\n",
    "salida1=squeeze1(imagen1)\n",
    "salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "salida1_a_numpy=salida1_activation.detach().numpy()\n",
    "\n",
    "toc=pc()\n",
    "acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "\n",
    "####### OPENCL COMPARISON #######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4523/1417617651.py:12: RuntimeWarning: overflow encountered in cast\n",
      "  h_result_fire1_expand = np.empty(1 * canales_iniciales * tamanyo * tamanyo).astype(np.float32) # we wil only check 3x3 convolituional performance\n"
     ]
    }
   ],
   "source": [
    "# NDRANGE\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_expand3x3_weight = weights1.reshape(-1)\n",
    "fire1_expand3x3_bias = bias1\n",
    "\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "h_result_fire1_expand = np.empty(1 * canales_iniciales * tamanyo * tamanyo).astype(np.float32) # we wil only check 3x3 convolituional performance\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "\n",
    "#offset = np.int32(canales_iniciales)\n",
    "offset = np.int32(0)\n",
    "\n",
    "tic2 = pc()\n",
    "\n",
    "conv3x3_NDR(queue,(canales_iniciales, tamanyo), None, canales_contraidos, tamanyo, 1, 1, offset, tamanyo, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire1_expand, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos = h_result_fire1_expand.reshape(-1,tamanyo,tamanyo)\n",
    "\n",
    "rtime = pc() - tic2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4523/1696061528.py:12: RuntimeWarning: overflow encountered in cast\n",
      "  h_result_fire1_expand = np.empty(1 * canales_iniciales * tamanyo * tamanyo).astype(np.float32) # we wil only check 3x3 convolituional performance\n"
     ]
    }
   ],
   "source": [
    "# Simple task\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_expand3x3_weight = weights1.reshape(-1)\n",
    "fire1_expand3x3_bias = bias1\n",
    "\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "h_result_fire1_expand = np.empty(1 * canales_iniciales * tamanyo * tamanyo).astype(np.float32) # we wil only check 3x3 convolituional performance\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "\n",
    "#offset = np.int32(canales_iniciales)\n",
    "offset = np.int32(0)\n",
    "\n",
    "tic3 = pc()\n",
    "\n",
    "conv3x3_ST(queue,(1,), None, np.int32(canales_contraidos), tamanyo, 1, 1, offset, tamanyo, canales_iniciales, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "cl.enqueue_copy(queue, h_result_fire1_expand, d_result_fire1_expand)\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "veamos1 = h_result_fire1_expand.reshape(-1,tamanyo,tamanyo)\n",
    "\n",
    "rtime1 = pc() - tic3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo en segundos con pytorch=  0.0005055000001448207\n",
      "tiempo en segundos con opencl (NDRANGE)= 42.37730355199983\n",
      "tiempo en segundos con opencl (Simple Task)= 339.99705950299995\n",
      "comparativa (pytorch == NDRange):  True\n",
      "comparativa (pytorch == Simple Task):  True\n",
      "comparativa (NDRange == Simple Task):  True\n"
     ]
    }
   ],
   "source": [
    "print (\"tiempo en segundos con pytorch= \", toc-tic)\n",
    "print (\"tiempo en segundos con opencl (NDRANGE)=\",rtime)\n",
    "print (\"tiempo en segundos con opencl (Simple Task)=\",rtime1)\n",
    "\n",
    "comparativa1=np.allclose(salida1_a_numpy, veamos,rtol=1e-01, atol=1e-01)\n",
    "comparativa2=np.allclose(salida1_a_numpy, veamos1,rtol=1e-01, atol=1e-01)\n",
    "comparativa3=np.allclose(veamos, veamos1,rtol=1e-01, atol=1e-01)\n",
    "\n",
    "print(\"comparativa (pytorch == NDRange): \",comparativa1)\n",
    "print(\"comparativa (pytorch == Simple Task): \",comparativa2)\n",
    "print(\"comparativa (NDRange == Simple Task): \",comparativa3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch (2, 5, 5) [123. 151. 184. 152. 138.]\n",
      "NDRange [123. 151. 184. 152. 138.]\n",
      "Simple task [ 77.  71. 126. 184. 132.]\n",
      "(1, 8, 5, 5) False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"pytorch\", veamos.shape, salida1_a_numpy.reshape(-1,tamanyo,tamanyo)[0][0])\n",
    "print(\"NDRange\", veamos[0][0])\n",
    "print(\"Simple task\", veamos1[0][0])\n",
    "print(imagen.shape, np.allclose(imagen, np.ones((1,canales_iniciales, tamanyo, tamanyo)).astype(np.float32), rtol=1e-01, atol=1e-01))\n",
    "#print(weights1[6])\n",
    "# print(fire1_squeeze_weight)\n",
    "#print(bias1[6])\n",
    "# print(imagen1_obtenida)\n",
    "# print(veamos2)\n",
    "print(np.allclose(salida1_a_numpy, veamos1,rtol=1e-01, atol=1e-01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(canales_contraidos):\n",
    "    for j in range(tamanyo):\n",
    "        for k in range(tamanyo):\n",
    "            if (abs(salida1_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k] - veamos1[i][j][k])) > 1e-01:\n",
    "                print(\"i:\", i, \"j:\", j, \"k:\", k, salida1_a_numpy.reshape(-1,tamanyo,tamanyo)[i][j][k], veamos1[i][j][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
