{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPROBACION DE FIRE MEDIANTE PYTORCH Y MEDIANTE NUMPY CON MATRIX MULTIPLICATIONS\n",
    "Partial code are copied heavily from https://github.com/pytorch/vision/blob/master/torchvision/models/squeezenet.py  \n",
    "SqueezeNet Paper:https://arxiv.org/abs/1602.07360  \n",
    "SqueezeNet 1.1 model from https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1   \n",
    "SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters than SqueezeNet 1.0, without sacrificing accuracy.\n",
    "\n",
    "Vamos a trabajar ya con fire1 del bloque 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#some set up\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from PIL import Image\n",
    "import math\n",
    "import time\n",
    "from time import sleep, perf_counter as pc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aquí tenemos el medidor entre pytorch y numpy adecuado para cada fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En esta aproximacion tengo en cuenta el tiempo de definición de capas y la carga de pesos porque se supone que entre fire y fire estas operaciones tiene que hacerse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[  655.   762.   865.   917.   581.]\n",
      "   [  658.   850.   633.  1137.   849.]\n",
      "   [  686.   998.  1013.   608.  1054.]\n",
      "   [  882.   753.  1101.   469.  1004.]\n",
      "   [  845.  1139.   495.   256.   435.]]\n",
      "\n",
      "  [[  976.  1254.  1360.  1462.   830.]\n",
      "   [ 1006.  1320.  1042.  1748.  1398.]\n",
      "   [ 1132.  1524.  1652.   902.  1732.]\n",
      "   [ 1332.  1076.  1718.   722.  1606.]\n",
      "   [ 1380.  1856.   762.   396.   646.]]\n",
      "\n",
      "  [[  874.  1151.  1234.  1331.   735.]\n",
      "   [  907.  1194.   957.  1576.  1283.]\n",
      "   [ 1040.  1372.  1512.   807.  1588.]\n",
      "   [ 1196.   952.  1555.   653.  1463.]\n",
      "   [ 1264.  1698.   689.   360.   579.]]\n",
      "\n",
      "  [[  596.   736.   812.   868.   516.]\n",
      "   [  608.   792.   612.  1052.   820.]\n",
      "   [  664.   920.   972.   552.  1016.]\n",
      "   [  808.   668.  1028.   436.   952.]\n",
      "   [  812.  1092.   460.   240.   396.]]\n",
      "\n",
      "  [[ 2616.  4840.  5771.  5787.  4839.]\n",
      "   [ 5178.  8385.  8808.  8336.  5326.]\n",
      "   [ 5326.  8245.  8463.  9151.  5144.]\n",
      "   [ 6214.  8829.  7501.  6257.  3909.]\n",
      "   [ 3194.  4522.  3920.  3125.  1991.]]\n",
      "\n",
      "  [[ 2707.  4206.  4942.  4727.  3885.]\n",
      "   [ 3979.  7155.  7798.  8042.  5698.]\n",
      "   [ 4203.  7552.  7483.  7586.  6344.]\n",
      "   [ 4640.  7815.  7736.  5909.  4562.]\n",
      "   [ 3033.  4669.  3916.  3613.  2563.]]\n",
      "\n",
      "  [[ 3876.  6436.  7536.  7451.  5377.]\n",
      "   [ 5495.  9704. 10497. 10295.  7271.]\n",
      "   [ 5579. 10293.  9935. 10848.  6970.]\n",
      "   [ 6407. 10398.  8973.  8480.  4874.]\n",
      "   [ 3159.  5647.  5416.  4505.  2629.]]\n",
      "\n",
      "  [[ 3182.  5017.  5947.  5834.  4841.]\n",
      "   [ 4132.  7274.  7550.  7868.  5110.]\n",
      "   [ 4249.  7463.  7418.  7784.  4656.]\n",
      "   [ 5093.  7792.  6541.  5731.  3116.]\n",
      "   [ 2799.  4033.  2973.  2674.  1248.]]]]\n",
      "[[[  655.   762.   865.   917.   581.]\n",
      "  [  658.   850.   633.  1137.   849.]\n",
      "  [  686.   998.  1013.   608.  1054.]\n",
      "  [  882.   753.  1101.   469.  1004.]\n",
      "  [  845.  1139.   495.   256.   435.]]\n",
      "\n",
      " [[  976.  1254.  1360.  1462.   830.]\n",
      "  [ 1006.  1320.  1042.  1748.  1398.]\n",
      "  [ 1132.  1524.  1652.   902.  1732.]\n",
      "  [ 1332.  1076.  1718.   722.  1606.]\n",
      "  [ 1380.  1856.   762.   396.   646.]]\n",
      "\n",
      " [[  874.  1151.  1234.  1331.   735.]\n",
      "  [  907.  1194.   957.  1576.  1283.]\n",
      "  [ 1040.  1372.  1512.   807.  1588.]\n",
      "  [ 1196.   952.  1555.   653.  1463.]\n",
      "  [ 1264.  1698.   689.   360.   579.]]\n",
      "\n",
      " [[  596.   736.   812.   868.   516.]\n",
      "  [  608.   792.   612.  1052.   820.]\n",
      "  [  664.   920.   972.   552.  1016.]\n",
      "  [  808.   668.  1028.   436.   952.]\n",
      "  [  812.  1092.   460.   240.   396.]]\n",
      "\n",
      " [[ 2616.  4840.  5771.  5787.  4839.]\n",
      "  [ 5178.  8385.  8808.  8336.  5326.]\n",
      "  [ 5326.  8245.  8463.  9151.  5144.]\n",
      "  [ 6214.  8829.  7501.  6257.  3909.]\n",
      "  [ 3194.  4522.  3920.  3125.  1991.]]\n",
      "\n",
      " [[ 2707.  4206.  4942.  4727.  3885.]\n",
      "  [ 3979.  7155.  7798.  8042.  5698.]\n",
      "  [ 4203.  7552.  7483.  7586.  6344.]\n",
      "  [ 4640.  7815.  7736.  5909.  4562.]\n",
      "  [ 3033.  4669.  3916.  3613.  2563.]]\n",
      "\n",
      " [[ 3876.  6436.  7536.  7451.  5377.]\n",
      "  [ 5495.  9704. 10497. 10295.  7271.]\n",
      "  [ 5579. 10293.  9935. 10848.  6970.]\n",
      "  [ 6407. 10398.  8973.  8480.  4874.]\n",
      "  [ 3159.  5647.  5416.  4505.  2629.]]\n",
      "\n",
      " [[ 3182.  5017.  5947.  5834.  4841.]\n",
      "  [ 4132.  7274.  7550.  7868.  5110.]\n",
      "  [ 4249.  7463.  7418.  7784.  4656.]\n",
      "  [ 5093.  7792.  6541.  5731.  3116.]\n",
      "  [ 2799.  4033.  2973.  2674.  1248.]]]\n",
      "tiempo en segundos con pytorch=  0.0021028031036257745\n",
      "tiempo en segundos con numpy=  0.00033237744122743606\n",
      "pytorch==numpy, total: True\n"
     ]
    }
   ],
   "source": [
    "canales_iniciales=4\n",
    "canales_contraidos=2\n",
    "canales_finales=4\n",
    "acumulado_pytorch=0\n",
    "acumulado_numpy=0\n",
    "idea=True\n",
    "count=100\n",
    "tamanyo=5\n",
    "squeeze_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "for i in range(count):\n",
    "\n",
    "    imagen = np.random.randint(10,size=(1,canales_iniciales, tamanyo, tamanyo))\n",
    "    weights1=np.random.randint(10,size=(canales_contraidos, canales_iniciales,1,1)).astype(np.float32)\n",
    "    bias1=np.random.randint(10,size=(canales_contraidos,)).astype(np.float32)\n",
    "    weights2a=np.random.randint(10,size=(canales_finales, canales_contraidos,1,1)).astype(np.float32)  \n",
    "    bias2a=np.random.randint(10,size=(canales_finales,)).astype(np.float32)    \n",
    "    weights2b=np.random.randint(10,size=(canales_finales, canales_contraidos,3,3)).astype(np.float32)    \n",
    "    bias2b=np.random.randint(10,size=(canales_finales,)).astype(np.float32)    \n",
    "    tic=pc()\n",
    "    squeeze1=nn.Conv2d(canales_iniciales, canales_contraidos, kernel_size=1, bias=False)\n",
    "    squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "    squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))    \n",
    "\n",
    "    squeeze2a=nn.Conv2d(canales_contraidos, canales_finales, kernel_size=1, bias=False)\n",
    "    squeeze2a.weight = nn.Parameter(torch.from_numpy(weights2a))\n",
    "    squeeze2a.bias = nn.Parameter(torch.from_numpy(bias2a))\n",
    "    \n",
    "    squeeze2b=nn.Conv2d(canales_contraidos, canales_finales, kernel_size=3, bias=False, padding=1)\n",
    "    squeeze2b.weight = nn.Parameter(torch.from_numpy(weights2b))\n",
    "    squeeze2b.bias = nn.Parameter(torch.from_numpy(bias2b))    \n",
    "\n",
    "    imagen1  = torch.from_numpy(imagen).float()\n",
    "    \n",
    "    salida1=squeeze1(imagen1)\n",
    "    salida1_activation=squeeze_activation(salida1)\n",
    "    \n",
    "    salida2a=squeeze2a(salida1_activation)\n",
    "    salida2a_activation=squeeze_activation(salida2a)\n",
    "    salida2b=squeeze2b(salida1_activation)\n",
    "    salida2b_activation=squeeze_activation(salida2b)    \n",
    "    salida2_total=torch.cat([salida2a_activation,salida2b_activation], 1)\n",
    "    salida2_total_a_numpy=salida2_total.detach().numpy()\n",
    "    toc=pc()\n",
    "    acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "    \n",
    "    \n",
    "    tic2=pc()\n",
    "    n_h=1\n",
    "    n_w=1\n",
    "    pesos1=np.transpose(weights1, axes=(1, 0, 2, 3)).reshape(canales_iniciales*n_h*n_w, -1)\n",
    "    pesos2a=np.transpose(weights2a, axes=(1, 0, 2, 3)).reshape(canales_contraidos*n_h*n_w, -1)\n",
    "\n",
    "    n_h=3\n",
    "    n_w=3\n",
    "    idea2b_pre=weights2b.reshape(-1,canales_contraidos*n_h*n_w)\n",
    "    pesos2b=np.transpose(idea2b_pre)   \n",
    "    bt, c_i = imagen.shape[0:2] \n",
    "    s=1\n",
    "    n_h=1\n",
    "    n_w=1\n",
    "    k=imagen.shape[2]-n_h+1\n",
    "    col = np.zeros((bt, c_i , k,k, n_h, n_w))\n",
    "\n",
    "    for i in range(k):\n",
    "        i_max = i + s*n_h\n",
    "        for j in range(k):\n",
    "            j_max = j + s*n_w\n",
    "            col[:, :, i, j, :, :] = imagen[:, :, i:i_max:s, j:j_max:s]\n",
    "    # col = np.transpose(col, axes=(1, 4, 5, 0, 2, 3)).reshape(c_i*n_h*n_w, -1)\n",
    "    col = col.reshape(c_i*n_h*n_w, -1)\n",
    "    imagen1_numpy=np.transpose(col)\n",
    "    salida1_obtenida= np.dot(imagen1_numpy,pesos1)+bias1\n",
    "    salida1_obtenida_activacion=np.maximum(0,salida1_obtenida)\n",
    "    imagen1_obtenida = np.transpose(salida1_obtenida_activacion, axes=(1,0)).reshape(canales_contraidos,tamanyo,tamanyo)\n",
    "    imagen1_obtenida_ampliada=np.pad(imagen1_obtenida,((0,0),(1,1),(1,1)))\n",
    "    salida2a_obtenida= np.dot(salida1_obtenida,pesos2a)+bias2a\n",
    "    salida2a_obtenida_activacion=np.maximum(0,salida2a_obtenida)\n",
    "    c_i = imagen1_obtenida_ampliada.shape[0] \n",
    "    n_h=3\n",
    "    n_w=3\n",
    "    k=imagen1_obtenida_ampliada.shape[1]-n_h+1\n",
    "    col = np.zeros(( c_i , k,k, n_h, n_w))\n",
    "\n",
    "    for i in range(k):\n",
    "        i_max = i + s*n_h\n",
    "        for j in range(k):\n",
    "            j_max = j + s*n_w\n",
    "            col[ :, i, j, :, :] = imagen1_obtenida_ampliada[ :, i:i_max:s, j:j_max:s]\n",
    "    col = np.transpose(col, axes=(0, 3, 4, 1, 2)).reshape(c_i*n_h*n_w, -1)\n",
    "    #col = col.reshape(c_i*n_h*n_w, -1)\n",
    "    salida_obtenida_2b=np.transpose(col)\n",
    "    salida2b_obtenida= np.dot(salida_obtenida_2b,pesos2b)+bias2b\n",
    "    salida2b_obtenida_activacion=np.maximum(0,salida2b_obtenida)\n",
    "    salida2_total_numpy=np.concatenate((salida2a_obtenida_activacion,salida2b_obtenida_activacion), axis=1)\n",
    "    imagen_total_obtenida = np.transpose(salida2_total_numpy, axes=(1,0)).reshape(canales_finales*2,tamanyo,tamanyo)\n",
    "    toc2=pc()\n",
    "    acumulado_numpy=toc2-tic2+acumulado_numpy\n",
    "    idea&=np.allclose(salida2_total_a_numpy, imagen_total_obtenida,rtol=1e-01, atol=1e-01)\n",
    "print(salida2_total_a_numpy)\n",
    "print(imagen_total_obtenida)\n",
    "print (\"tiempo en segundos con pytorch= \", acumulado_pytorch/count)\n",
    "print (\"tiempo en segundos con numpy= \", acumulado_numpy/count)\n",
    "print (\"pytorch==numpy, total:\",idea)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veamos ahora fire con opencl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vamos a hacer la medición con opencl definido por equipo de squezeenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step1: OpenCL preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OpenCL setup\n",
    "import pyopencl as cl\n",
    "import deviceinfo\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyopencl.Platform 'Intel(R) FPGA Emulation Platform for OpenCL(TM)' at 0x55b6f0890c40>\n"
     ]
    }
   ],
   "source": [
    "platform = cl.get_platforms()[2]\n",
    "print(platform)\n",
    "\n",
    "device = platform.get_devices()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose platform:\n",
      "[0] <pyopencl.Platform 'NVIDIA CUDA' at 0x55b6f0884da0>\n",
      "[1] <pyopencl.Platform 'Portable Computing Language' at 0x7fdb7ee86008>\n",
      "[2] <pyopencl.Platform 'Intel(R) FPGA Emulation Platform for OpenCL(TM)' at 0x55b6f0890c40>\n",
      "[3] <pyopencl.Platform 'Intel(R) FPGA SDK for OpenCL(TM)' at 0x7fd883072060>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choice [0]: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set the environment variable PYOPENCL_CTX='0' to avoid being asked again.\n",
      "Device is Tesla V100-PCIE-32GBGPU from NVIDIA Corporation with a max of 80 compute units\n"
     ]
    }
   ],
   "source": [
    "# Ask the user to select a platform/device on the CLI\n",
    "context = cl.create_some_context(platform)\n",
    "\n",
    "# Print out device info\n",
    "deviceinfo.output_device_info(context.devices[0])\n",
    "\n",
    "# Create a command queue\n",
    "queue = cl.CommandQueue(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanyo=55\n",
    "canales_iniciales=128\n",
    "canales_contraidos=16\n",
    "canales_finales=64\n",
    "imagen = np.random.randint(10,size=(1,canales_iniciales, tamanyo, tamanyo))\n",
    "\n",
    "weights1=np.random.randint(10,size=(canales_contraidos, canales_iniciales,1,1)).astype(np.float32)\n",
    "bias1=np.random.randint(10,size=(canales_contraidos,)).astype(np.float32)\n",
    "weights2a=np.random.randint(10,size=(canales_finales, canales_contraidos,1,1)).astype(np.float32)  \n",
    "bias2a=np.random.randint(10,size=(canales_finales,)).astype(np.float32)    \n",
    "weights2b=np.random.randint(10,size=(canales_finales, canales_contraidos,3,3)).astype(np.float32)    \n",
    "bias2b=np.random.randint(10,size=(canales_finales,)).astype(np.float32)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: import parameters from pytorch implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8. 6. 2. ... 4. 3. 1.]\n",
      "[3. 1. 0. 3. 4. 3. 3. 6. 3. 1. 0. 0. 1. 7. 8. 2.]\n"
     ]
    }
   ],
   "source": [
    "# params = model.state_dict() \n",
    "\n",
    "# #remove # to see the params index\n",
    "# for k,v in params.items():\n",
    "#     #print parameter name\n",
    "#     print(k,params[k].numpy().shape)\n",
    "\n",
    "# conv1_weight = params['features.0.weight'].numpy().reshape(-1)\n",
    "# conv1_bias = params['features.0.bias'].numpy()\n",
    "\n",
    "#fire - fire - maxpool block 1\n",
    "fire1_squeeze_weight = weights1.reshape(-1)\n",
    "print(fire1_squeeze_weight)\n",
    "fire1_squeeze_bias = bias1\n",
    "print(fire1_squeeze_bias)\n",
    "fire1_expand1x1_weight = weights2a.reshape(-1)\n",
    "fire1_expand1x1_bias = bias2a\n",
    "\n",
    "fire1_expand3x3_weight =weights2b.reshape(-1)\n",
    "fire1_expand3x3_bias = bias2b\n",
    "\n",
    "# fire2_squeeze_weight = params['features.4.squeeze.weight'].numpy().reshape(-1)\n",
    "# fire2_squeeze_bias = params['features.4.squeeze.bias'].numpy()\n",
    "\n",
    "# fire2_expand1x1_weight = params['features.4.expand1x1.weight'].numpy().reshape(-1)\n",
    "# fire2_expand1x1_bias = params['features.4.expand1x1.bias'].numpy()\n",
    "\n",
    "# fire2_expand3x3_weight = params['features.4.expand3x3.weight'].numpy().reshape(-1)\n",
    "# fire2_expand3x3_bias = params['features.4.expand3x3.bias'].numpy()\n",
    "\n",
    "# #fire - fire - maxpool block 2\n",
    "# fire3_squeeze_weight = params['features.6.squeeze.weight'].numpy().reshape(-1)\n",
    "# fire3_squeeze_bias = params['features.6.squeeze.bias'].numpy()\n",
    "\n",
    "# fire3_expand1x1_weight = params['features.6.expand1x1.weight'].numpy().reshape(-1)\n",
    "# fire3_expand1x1_bias = params['features.6.expand1x1.bias'].numpy()\n",
    "\n",
    "# fire3_expand3x3_weight = params['features.6.expand3x3.weight'].numpy().reshape(-1)\n",
    "# fire3_expand3x3_bias = params['features.6.expand3x3.bias'].numpy()\n",
    "\n",
    "# fire4_squeeze_weight = params['features.7.squeeze.weight'].numpy().reshape(-1)\n",
    "# fire4_squeeze_bias = params['features.7.squeeze.bias'].numpy()\n",
    "\n",
    "# fire4_expand1x1_weight = params['features.7.expand1x1.weight'].numpy().reshape(-1)\n",
    "# fire4_expand1x1_bias = params['features.7.expand1x1.bias'].numpy()\n",
    "\n",
    "# fire4_expand3x3_weight = params['features.7.expand3x3.weight'].numpy().reshape(-1)\n",
    "# fire4_expand3x3_bias = params['features.7.expand3x3.bias'].numpy()\n",
    "\n",
    "# #fire - fire - fire - fire block 3\n",
    "# fire5_squeeze_weight = params['features.9.squeeze.weight'].numpy().reshape(-1)\n",
    "# fire5_squeeze_bias = params['features.9.squeeze.bias'].numpy()\n",
    "\n",
    "# fire5_expand1x1_weight = params['features.9.expand1x1.weight'].numpy().reshape(-1)\n",
    "# fire5_expand1x1_bias = params['features.9.expand1x1.bias'].numpy()\n",
    "\n",
    "# fire5_expand3x3_weight = params['features.9.expand3x3.weight'].numpy().reshape(-1)\n",
    "# fire5_expand3x3_bias = params['features.9.expand3x3.bias'].numpy()\n",
    "\n",
    "# fire6_squeeze_weight = params['features.10.squeeze.weight'].numpy().reshape(-1)\n",
    "# fire6_squeeze_bias = params['features.10.squeeze.bias'].numpy()\n",
    "\n",
    "# fire6_expand1x1_weight = params['features.10.expand1x1.weight'].numpy().reshape(-1)\n",
    "# fire6_expand1x1_bias = params['features.10.expand1x1.bias'].numpy()\n",
    "\n",
    "# fire6_expand3x3_weight = params['features.10.expand3x3.weight'].numpy().reshape(-1)\n",
    "# fire6_expand3x3_bias = params['features.10.expand3x3.bias'].numpy()\n",
    "\n",
    "# fire7_squeeze_weight = params['features.11.squeeze.weight'].numpy().reshape(-1)\n",
    "# fire7_squeeze_bias = params['features.11.squeeze.bias'].numpy()\n",
    "\n",
    "# fire7_expand1x1_weight = params['features.11.expand1x1.weight'].numpy().reshape(-1)\n",
    "# fire7_expand1x1_bias = params['features.11.expand1x1.bias'].numpy()\n",
    "\n",
    "# fire7_expand3x3_weight = params['features.11.expand3x3.weight'].numpy().reshape(-1)\n",
    "# fire7_expand3x3_bias = params['features.11.expand3x3.bias'].numpy()\n",
    "\n",
    "# fire8_squeeze_weight = params['features.12.squeeze.weight'].numpy().reshape(-1)\n",
    "# fire8_squeeze_bias = params['features.12.squeeze.bias'].numpy()\n",
    "\n",
    "# fire8_expand1x1_weight = params['features.12.expand1x1.weight'].numpy().reshape(-1)\n",
    "# fire8_expand1x1_bias = params['features.12.expand1x1.bias'].numpy()\n",
    "\n",
    "# fire8_expand3x3_weight = params['features.12.expand3x3.weight'].numpy().reshape(-1)\n",
    "# fire8_expand3x3_bias = params['features.12.expand3x3.bias'].numpy()\n",
    "\n",
    "# classifier_conv_weight = params['classifier.1.weight'].numpy().reshape(-1)\n",
    "# classifier_conv_bias = params['classifier.1.bias'].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creat OpenCL memory object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 6 7 ... 7 1 9]\n",
      "(387200,)\n"
     ]
    }
   ],
   "source": [
    "h_sample = imagen.reshape(-1)\n",
    "print(h_sample)\n",
    "print(h_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyopencl._cl.Buffer object at 0x7fd9f026cdd0>\n"
     ]
    }
   ],
   "source": [
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "# h_result_conv = np.empty(1 * 64 * 111 * 111).astype(np.float32)\n",
    "# h_result_pool1 = np.empty(1 * 64 * 55 * 55).astype(np.float32)\n",
    "\n",
    "h_result_fire1_squeeze = np.empty(1 * canales_contraidos * tamanyo * tamanyo).astype(np.float32)\n",
    "h_result_fire1_expand = np.empty(1 * 2*canales_finales * tamanyo* tamanyo).astype(np.float32)\n",
    "\n",
    "# h_result_fire2_squeeze = np.empty(1 * 16 * 55 * 55).astype(np.float32)\n",
    "# h_result_fire2_expand = np.empty(1 * 128 * 55 * 55).astype(np.float32)\n",
    "# h_result_pool2 = np.empty(1 * 128 * 27 * 27).astype(np.float32)\n",
    "\n",
    "# h_result_fire3_squeeze = np.empty(1 * 32 * 27 * 27).astype(np.float32)\n",
    "# h_result_fire3_expand = np.empty(1 * 256 * 27 * 27).astype(np.float32)\n",
    "# h_result_fire4_squeeze = np.empty(1 * 32 * 27 * 27).astype(np.float32)\n",
    "# h_result_fire4_expand = np.empty(1 * 256 * 27 * 27).astype(np.float32)\n",
    "# h_result_pool3 = np.empty(1 * 256 * 13 * 13).astype(np.float32)\n",
    "\n",
    "# h_result_fire5_squeeze = np.empty(1 * 48 * 13 * 13).astype(np.float32)\n",
    "# h_result_fire5_expand = np.empty(1 * 384 * 13 * 13).astype(np.float32)\n",
    "# h_result_fire6_squeeze = np.empty(1 * 48 * 13 * 13).astype(np.float32)\n",
    "# h_result_fire6_expand = np.empty(1 * 384 * 13 * 13).astype(np.float32)\n",
    "# h_result_fire7_squeeze = np.empty(1 * 64 * 13 * 13).astype(np.float32)\n",
    "# h_result_fire7_expand = np.empty(1 * 512 * 13 * 13).astype(np.float32)\n",
    "# h_result_fire8_squeeze = np.empty(1 * 64 * 13 * 13).astype(np.float32)\n",
    "# h_result_fire8_expand = np.empty(1 * 512 * 13 * 13).astype(np.float32)\n",
    "\n",
    "# h_result_classifier_conv = np.empty(1 * 1000 * 13 * 13).astype(np.float32)\n",
    "# h_result_classifier = np.empty(1 * 1000).astype(np.float32)\n",
    "\n",
    "# device input buffer\n",
    "d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "# device conv1 buffers \n",
    "# d_conv1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=conv1_weight)\n",
    "# d_conv1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=conv1_bias)\n",
    "\n",
    "# d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=weights1)\n",
    "# d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=bias1)\n",
    "# d_fire1_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=weights2a)\n",
    "# d_fire1_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=bias2a)\n",
    "# d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=weights2b)\n",
    "# d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=bias2b)\n",
    "\n",
    "print(d_fire1_squeeze_weight)\n",
    "d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "d_fire1_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_weight)\n",
    "d_fire1_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_bias)\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "# d_fire2_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_weight)\n",
    "# d_fire2_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_bias)\n",
    "# d_fire2_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_weight)\n",
    "# d_fire2_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_bias)\n",
    "# d_fire2_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_weight)\n",
    "# d_fire2_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_bias)\n",
    "\n",
    "# d_fire3_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_squeeze_weight)\n",
    "# d_fire3_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_squeeze_bias)\n",
    "# d_fire3_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand1x1_weight)\n",
    "# d_fire3_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand1x1_bias)\n",
    "# d_fire3_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand3x3_weight)\n",
    "# d_fire3_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand3x3_bias)\n",
    "\n",
    "# d_fire4_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_squeeze_weight)\n",
    "# d_fire4_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_squeeze_bias)\n",
    "# d_fire4_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand1x1_weight)\n",
    "# d_fire4_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand1x1_bias)\n",
    "# d_fire4_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand3x3_weight)\n",
    "# d_fire4_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand3x3_bias)\n",
    "\n",
    "# d_fire5_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_squeeze_weight)\n",
    "# d_fire5_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_squeeze_bias)\n",
    "# d_fire5_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand1x1_weight)\n",
    "# d_fire5_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand1x1_bias)\n",
    "# d_fire5_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand3x3_weight)\n",
    "# d_fire5_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand3x3_bias)\n",
    "\n",
    "# d_fire6_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_squeeze_weight)\n",
    "# d_fire6_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_squeeze_bias)\n",
    "# d_fire6_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand1x1_weight)\n",
    "# d_fire6_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand1x1_bias)\n",
    "# d_fire6_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand3x3_weight)\n",
    "# d_fire6_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand3x3_bias)\n",
    "\n",
    "# d_fire7_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_squeeze_weight)\n",
    "# d_fire7_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_squeeze_bias)\n",
    "# d_fire7_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand1x1_weight)\n",
    "# d_fire7_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand1x1_bias)\n",
    "# d_fire7_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand3x3_weight)\n",
    "# d_fire7_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand3x3_bias)\n",
    "\n",
    "# d_fire8_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_squeeze_weight)\n",
    "# d_fire8_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_squeeze_bias)\n",
    "# d_fire8_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand1x1_weight)\n",
    "# d_fire8_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand1x1_bias)\n",
    "# d_fire8_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand3x3_weight)\n",
    "# d_fire8_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand3x3_bias)\n",
    "\n",
    "# d_classifier_conv_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=classifier_conv_weight)\n",
    "# d_classifier_conv_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=classifier_conv_bias)\n",
    "\n",
    "# d_result_conv = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_conv.nbytes)\n",
    "# d_result_pool1 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool1.nbytes)\n",
    "\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "# d_result_fire2_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_squeeze.nbytes)\n",
    "# d_result_fire2_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_expand.nbytes)\n",
    "# d_result_pool2 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool2.nbytes)\n",
    "\n",
    "# d_result_fire3_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire3_squeeze.nbytes)\n",
    "# d_result_fire3_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire3_expand.nbytes)\n",
    "# d_result_fire4_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire4_squeeze.nbytes)\n",
    "# d_result_fire4_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire4_expand.nbytes)\n",
    "# d_result_pool3 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool3.nbytes)\n",
    "\n",
    "# d_result_fire5_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire5_squeeze.nbytes)\n",
    "# d_result_fire5_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire5_expand.nbytes)\n",
    "# d_result_fire6_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire6_squeeze.nbytes)\n",
    "# d_result_fire6_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire6_expand.nbytes)\n",
    "# d_result_fire7_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire7_squeeze.nbytes)\n",
    "# d_result_fire7_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire7_expand.nbytes)\n",
    "# d_result_fire8_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire8_squeeze.nbytes)\n",
    "# d_result_fire8_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire8_expand.nbytes)\n",
    "\n",
    "# d_result_classifier_conv = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_classifier_conv.nbytes)\n",
    "# d_result_classifier = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_classifier.nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: creat kernels\n",
    "Creat & build program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "kernelSource = open(\"squeezenet.cl\").read()\n",
    "program = cl.Program(context, kernelSource).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creat kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv3x3 = program.conv2d3x3\n",
    "conv3x3.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, \\\n",
    "                               None, None, None, None])\n",
    "\n",
    "maxpool = program.maxpool2d\n",
    "maxpool.set_scalar_arg_dtypes([np.int32, np.int32, None, None])\n",
    "\n",
    "conv1x1 = program.conv2d1x1\n",
    "conv1x1.set_scalar_arg_dtypes([np.int32, np.int32, \\\n",
    "                               None, None, None, None])\n",
    "\n",
    "avgpool = program.avgpool2d\n",
    "avgpool.set_scalar_arg_dtypes([None, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenCL kernel: squeezenet.cl\n",
    "conv2d3x3: 2-D 3x3 convolution.  \n",
    "conv2d1x1: 2-D 1x1 convolution. kerner size 1, stride 1  \n",
    "maxpool2d: 2-D max pool. kerner size 3, stride 2  \n",
    "avgpool2d: 2-D average pool. kerner size 13\n",
    "```C\n",
    "//maxPool2d \n",
    "//kernel_size=3 stride=2\n",
    "//output one feature map per kernel\n",
    "__kernel void maxpool2d(\n",
    "\tconst int input_size,\n",
    "\tconst int output_size,\n",
    "\t__global float *input_im,\n",
    "    __global float *restrict output_im)\n",
    "{\n",
    "\tint channel = get_global_id(0);//get output channel index\n",
    "\t\n",
    "\tinput_im += channel * input_size * input_size;\n",
    "\toutput_im += channel * output_size * output_size;\n",
    "\n",
    "\t//loop over output feature map\n",
    "\tfor(int i = 0; i < output_size; i++)//row\n",
    "\t{\n",
    "\t\tfor(int j = 0; j < output_size; j++)//col\n",
    "\t\t{\n",
    "\t\t\t//find the max value in 3x3 reigon \n",
    "\t\t\t//to be one element in the output feature map\n",
    "\t\t\tfloat tmp = 0.0;\n",
    "\n",
    "\t\t\tfor(int k = 0; k < 3; k++)//row\n",
    "\t\t\t{\n",
    "\t\t\t\tfor(int l = 0; l < 3; l++)//col\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\tfloat value = input_im[(i * 2 + k) * input_size  + j * 2 + l ];\n",
    "\t\t\t\t\tif(value > tmp)\n",
    "\t\t\t\t\t\ttmp = value;\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t\t//store the result to output feature map\n",
    "\t\t\toutput_im[i * output_size + j] = tmp; \n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "//3x3 convolution layer\n",
    "//output one feature map per kernel\n",
    "__kernel void conv2d3x3(\n",
    "\tconst int input_channels, const int input_size,\n",
    "\tconst int pad, const int stride,\n",
    "\tconst int start_channel, //start_channel is for 1x1 feature map in fire layer\n",
    "\tconst int output_size,\n",
    "\t__global float *restrict input_im,\n",
    "\t__global const float *restrict  filter_weight,\n",
    "\t__global const float *restrict  filter_bias,\n",
    "\t__global float *restrict output_im\n",
    "\t)\n",
    "{\n",
    "\tint filter_index = get_global_id(0); //get output channel index\n",
    "\n",
    "\tfilter_weight += filter_index * input_channels * 9;\n",
    "\tfloat bias = filter_bias[filter_index];\n",
    "\toutput_im += (start_channel + filter_index) * output_size * output_size;\n",
    "\t\n",
    "\t//loop over output feature map\n",
    "\tfor(int i = 0; i < output_size; i++)\n",
    "\t{\n",
    "\t\tfor(int j = 0; j < output_size; j++)\n",
    "\t\t{\n",
    "\t\t\t//compute one element in the output feature map\n",
    "\t\t\tfloat tmp = bias;\n",
    "\t\t\t\n",
    "\t\t\t//compute dot product of 2 input_channels x 3 x 3 matrix\n",
    "\t\t\tfor(int k = 0; k < input_channels; k++)\n",
    "\t\t\t{\n",
    "\t\t\t\tfor(int l = 0; l < 3; l++)\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\tint h = i * stride + l - pad;\n",
    "\t\t\t\t\tfor(int m = 0; m < 3; m++)\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\tint w = j * stride + m - pad;\n",
    "\t\t\t\t\t\tif((h >= 0) && (h < input_size) && (w >= 0) && (w < input_size))\n",
    "\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\ttmp += input_im[k * input_size * input_size + (i * stride + l - pad) * input_size + j \n",
    "                                   * stride + m - pad] * filter_weight[9 * k + 3 * l + m];\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\t//add relu activation after conv\n",
    "\t\t\toutput_im[i * output_size + j] = (tmp > 0.0) ? tmp : 0.0;\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "//1x1 convolution layer\n",
    "//output one feature map per kernel\n",
    "__kernel void conv2d1x1(\n",
    "\tconst int input_channels, const int input_size,\n",
    "\t__global float *input_im,\n",
    "\t__global const float *restrict filter_weight,\n",
    "\t__global const float *restrict filter_bias,\n",
    "\t__global float *restrict output_im)\n",
    "{\n",
    "\tint filter_index = get_global_id(0); // 0 - (output_channels - 1)\n",
    "\n",
    "\tfilter_weight += filter_index * input_channels;\n",
    "\n",
    "\tfloat bias = filter_bias[filter_index];\n",
    "\t\n",
    "\toutput_im += filter_index * input_size * input_size;//start_channel is for 1x1 feature map in fire layer\n",
    "\n",
    "\t//loop over output feature map\n",
    "\t//out\n",
    "\tfor(int i = 0; i < input_size; i++)\n",
    "\t{\n",
    "\t\tfor(int j = 0; j < input_size; j++)\n",
    "\t\t{\n",
    "\t\t\tfloat tmp = bias;\n",
    "\t\t\tfor(int k = 0; k < input_channels; k++)\n",
    "\t\t\t{\n",
    "\t\t\t\ttmp += input_im[k * input_size * input_size + i * input_size + j] * filter_weight[k];\n",
    "\t\t\t}\n",
    "\t\t\t//add relu after conv\n",
    "\t\t\toutput_im[i * input_size + j] = (tmp > 0.0) ? tmp : 0.0;\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "//last layer use a 13 x 13 avgPool layer as classifier\n",
    "//one class score per kernel\n",
    "__kernel void avgpool2d(\n",
    "\t__global float *restrict input_im,\n",
    "\t__global float *restrict output_im)\n",
    "{\n",
    "\tint class_index = get_global_id(0);//get class score index\n",
    "\n",
    "\tinput_im += 169 * class_index;\n",
    "\t\n",
    "\tfloat tmp = 0.0f;\n",
    "\n",
    "\tfor(int i = 0; i < 169; i++)\n",
    "\t{\n",
    "\t\ttmp += input_im[i];\n",
    "\t}\n",
    "\n",
    "\toutput_im[class_index] = tmp / 169.0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run OpenCL implement  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo en segundos con pytorch=  0.01650763675570488\n",
      "tiempo en segundos con numpy=  0.09821171686053276\n",
      "tiempo en segundos con opencl= 0.10182949528098106\n",
      "comparativa (pytorch==numpy): True\n",
      "comparativa (pytorch==opencl): True\n"
     ]
    }
   ],
   "source": [
    "imagen = np.random.randint(10,size=(1,canales_iniciales, tamanyo, tamanyo))\n",
    "\n",
    "weights1=np.random.randint(10,size=(canales_contraidos, canales_iniciales,1,1)).astype(np.float32)\n",
    "bias1=np.random.randint(10,size=(canales_contraidos,)).astype(np.float32)\n",
    "weights2a=np.random.randint(10,size=(canales_finales, canales_contraidos,1,1)).astype(np.float32)  \n",
    "bias2a=np.random.randint(10,size=(canales_finales,)).astype(np.float32)    \n",
    "weights2b=np.random.randint(10,size=(canales_finales, canales_contraidos,3,3)).astype(np.float32)    \n",
    "bias2b=np.random.randint(10,size=(canales_finales,)).astype(np.float32)  \n",
    "\n",
    "tic=pc()\n",
    "squeeze1=nn.Conv2d(canales_iniciales, canales_contraidos, kernel_size=1, bias=False)\n",
    "squeeze1.weight = nn.Parameter(torch.from_numpy(weights1))\n",
    "squeeze1.bias = nn.Parameter(torch.from_numpy(bias1))\n",
    "\n",
    "squeeze2a=nn.Conv2d(canales_contraidos, canales_finales, kernel_size=1, bias=False)\n",
    "squeeze2a.weight = nn.Parameter(torch.from_numpy(weights2a))\n",
    "squeeze2a.bias = nn.Parameter(torch.from_numpy(bias2a))\n",
    "\n",
    "squeeze2b=nn.Conv2d(canales_contraidos, canales_finales, kernel_size=3, bias=False, padding=1)\n",
    "squeeze2b.weight = nn.Parameter(torch.from_numpy(weights2b))\n",
    "squeeze2b.bias = nn.Parameter(torch.from_numpy(bias2b))\n",
    "\n",
    "\n",
    "imagen1  = torch.from_numpy(imagen).float()\n",
    "\n",
    "salida1=squeeze1(imagen1)\n",
    "salida1_activation=squeeze_activation(salida1)\n",
    "\n",
    "salida2a=squeeze2a(salida1_activation)\n",
    "salida2a_activation=squeeze_activation(salida2a)\n",
    "salida2b=squeeze2b(salida1_activation)\n",
    "salida2b_activation=squeeze_activation(salida2b)    \n",
    "salida2_total=torch.cat([salida2a_activation,salida2b_activation], 1)\n",
    "salida2_total_a_numpy=salida2_total.detach().numpy()\n",
    "toc=pc()\n",
    "acumulado_pytorch=toc-tic+acumulado_pytorch\n",
    "\n",
    "\n",
    "tic2=pc()\n",
    "n_h=1\n",
    "n_w=1\n",
    "pesos1=np.transpose(weights1, axes=(1, 0, 2, 3)).reshape(canales_iniciales*n_h*n_w, -1)\n",
    "pesos2a=np.transpose(weights2a, axes=(1, 0, 2, 3)).reshape(canales_contraidos*n_h*n_w, -1)\n",
    "\n",
    "n_h=3\n",
    "n_w=3\n",
    "idea2b_pre=weights2b.reshape(-1,canales_contraidos*n_h*n_w)\n",
    "pesos2b=np.transpose(idea2b_pre)   \n",
    "bt, c_i = imagen.shape[0:2] \n",
    "s=1\n",
    "n_h=1\n",
    "n_w=1\n",
    "k=imagen.shape[2]-n_h+1\n",
    "col = np.zeros((bt, c_i , k,k, n_h, n_w))\n",
    "\n",
    "for i in range(k):\n",
    "    i_max = i + s*n_h\n",
    "    for j in range(k):\n",
    "        j_max = j + s*n_w\n",
    "        col[:, :, i, j, :, :] = imagen[:, :, i:i_max:s, j:j_max:s]\n",
    "# col = np.transpose(col, axes=(1, 4, 5, 0, 2, 3)).reshape(c_i*n_h*n_w, -1)\n",
    "col = col.reshape(c_i*n_h*n_w, -1)\n",
    "imagen1_numpy=np.transpose(col)\n",
    "salida1_obtenida= np.dot(imagen1_numpy,pesos1)+bias1\n",
    "salida1_obtenida_activacion=np.maximum(0,salida1_obtenida)\n",
    "imagen1_obtenida = np.transpose(salida1_obtenida_activacion, axes=(1,0)).reshape(canales_contraidos,tamanyo,tamanyo)\n",
    "imagen1_obtenida_ampliada=np.pad(imagen1_obtenida,((0,0),(1,1),(1,1)))\n",
    "salida2a_obtenida= np.dot(salida1_obtenida,pesos2a)+bias2a\n",
    "salida2a_obtenida_activacion=np.maximum(0,salida2a_obtenida)\n",
    "c_i = imagen1_obtenida_ampliada.shape[0] \n",
    "n_h=3\n",
    "n_w=3\n",
    "k=imagen1_obtenida_ampliada.shape[1]-n_h+1\n",
    "col = np.zeros(( c_i , k,k, n_h, n_w))\n",
    "\n",
    "for i in range(k):\n",
    "    i_max = i + s*n_h\n",
    "    for j in range(k):\n",
    "        j_max = j + s*n_w\n",
    "        col[ :, i, j, :, :] = imagen1_obtenida_ampliada[ :, i:i_max:s, j:j_max:s]\n",
    "col = np.transpose(col, axes=(0, 3, 4, 1, 2)).reshape(c_i*n_h*n_w, -1)\n",
    "#col = col.reshape(c_i*n_h*n_w, -1)\n",
    "salida_obtenida_2b=np.transpose(col)\n",
    "salida2b_obtenida= np.dot(salida_obtenida_2b,pesos2b)+bias2b\n",
    "salida2b_obtenida_activacion=np.maximum(0,salida2b_obtenida)\n",
    "salida2_total_numpy=np.concatenate((salida2a_obtenida_activacion,salida2b_obtenida_activacion), axis=1)\n",
    "imagen_total_obtenida = np.transpose(salida2_total_numpy, axes=(1,0)).reshape(canales_finales*2,tamanyo,tamanyo)\n",
    "toc2=pc()\n",
    "acumulado_numpy=toc2-tic2+acumulado_numpy\n",
    "idea&=np.allclose(salida2_total_a_numpy, imagen_total_obtenida,rtol=1e-01, atol=1e-01)\n",
    "\n",
    "\n",
    "# device conv1 buffers \n",
    "# d_conv1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=conv1_weight)\n",
    "# d_conv1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=conv1_bias)\n",
    "\n",
    "# d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=weights1)\n",
    "# d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=bias1)\n",
    "# d_fire1_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=weights2a)\n",
    "# d_fire1_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=bias2a)\n",
    "# d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=weights2b)\n",
    "# d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=bias2b)\n",
    "\n",
    "h_sample = imagen.reshape(-1).astype(np.float32)\n",
    "d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "fire1_squeeze_weight = weights1.reshape(-1)\n",
    "fire1_squeeze_bias = bias1\n",
    "fire1_expand1x1_weight = weights2a.reshape(-1)\n",
    "fire1_expand1x1_bias = bias2a\n",
    "fire1_expand3x3_weight =weights2b.reshape(-1)\n",
    "fire1_expand3x3_bias = bias2b\n",
    "\n",
    "d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "d_fire1_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_weight)\n",
    "d_fire1_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_bias)\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "tic3 = pc()\n",
    "#first conv layer\n",
    "# conv3x3(queue,(64,), None, 3, 224, 0, 2, 0, 111, d_sample, d_conv1_weight, d_conv1_bias, d_result_conv)\n",
    "# maxpool(queue,(64,), None, 111, 55, d_result_conv, d_result_pool1)\n",
    "\n",
    "#block1\n",
    "conv1x1(queue,(canales_contraidos,), None, canales_iniciales, tamanyo, d_sample, d_fire1_squeeze_weight, d_fire1_squeeze_bias, d_result_fire1_squeeze)\n",
    "conv1x1(queue,(canales_finales,), None, canales_contraidos, tamanyo, d_result_fire1_squeeze, d_fire1_expand1x1_weight, d_fire1_expand1x1_bias, d_result_fire1_expand)\n",
    "conv3x3(queue,(canales_finales,), None, canales_contraidos, tamanyo, 1, 1, canales_finales, tamanyo, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "\n",
    "# conv1x1(queue,(16,), None, 128, 55, d_result_fire1_expand, d_fire2_squeeze_weight, d_fire2_squeeze_bias, d_result_fire2_squeeze)\n",
    "# conv1x1(queue,(64,), None, 16, 55, d_result_fire2_squeeze, d_fire2_expand1x1_weight, d_fire2_expand1x1_bias, d_result_fire2_expand)\n",
    "# conv3x3(queue,(64,), None, 16, 55, 1, 1, 64, 55, d_result_fire2_squeeze, d_fire2_expand3x3_weight, d_fire2_expand3x3_bias, d_result_fire2_expand)\n",
    "\n",
    "# maxpool(queue,(128,), None, 55, 27, d_result_fire2_expand, d_result_pool2)\n",
    "\n",
    "# #block2\n",
    "# conv1x1(queue,(32,), None, 128, 27, d_result_pool2, d_fire3_squeeze_weight, d_fire3_squeeze_bias, d_result_fire3_squeeze)\n",
    "# conv1x1(queue,(128,), None, 32, 27, d_result_fire3_squeeze, d_fire3_expand1x1_weight, d_fire3_expand1x1_bias, d_result_fire3_expand)\n",
    "# conv3x3(queue,(128,), None, 32, 27, 1, 1, 128, 27, d_result_fire3_squeeze, d_fire3_expand3x3_weight, d_fire3_expand3x3_bias, d_result_fire3_expand)\n",
    "\n",
    "# conv1x1(queue,(32,), None, 256, 27, d_result_fire3_expand, d_fire4_squeeze_weight, d_fire4_squeeze_bias, d_result_fire4_squeeze)\n",
    "# conv1x1(queue,(128,), None, 32, 27, d_result_fire4_squeeze, d_fire4_expand1x1_weight, d_fire4_expand1x1_bias, d_result_fire4_expand)\n",
    "# conv3x3(queue,(128,), None, 32, 27, 1, 1, 128, 27, d_result_fire4_squeeze, d_fire4_expand3x3_weight, d_fire4_expand3x3_bias, d_result_fire4_expand)\n",
    "\n",
    "# maxpool(queue,(256,), None, 27, 13, d_result_fire4_expand, d_result_pool3)\n",
    "\n",
    "# #block3\n",
    "# conv1x1(queue,(48,), None, 256, 13, d_result_pool3, d_fire5_squeeze_weight, d_fire5_squeeze_bias, d_result_fire5_squeeze)\n",
    "# conv1x1(queue,(192,), None, 48, 13, d_result_fire5_squeeze, d_fire5_expand1x1_weight, d_fire5_expand1x1_bias, d_result_fire5_expand)\n",
    "# conv3x3(queue,(192,), None, 48, 13, 1, 1, 192, 13, d_result_fire5_squeeze, d_fire5_expand3x3_weight, d_fire5_expand3x3_bias, d_result_fire5_expand)\n",
    "\n",
    "# conv1x1(queue,(48,), None, 384, 13, d_result_fire5_expand, d_fire6_squeeze_weight, d_fire6_squeeze_bias, d_result_fire6_squeeze)\n",
    "# conv1x1(queue,(192,), None, 48, 13, d_result_fire6_squeeze, d_fire6_expand1x1_weight, d_fire6_expand1x1_bias, d_result_fire6_expand)\n",
    "# conv3x3(queue,(192,), None, 48, 13, 1, 1, 192, 13, d_result_fire6_squeeze, d_fire6_expand3x3_weight, d_fire6_expand3x3_bias, d_result_fire6_expand)\n",
    "\n",
    "# conv1x1(queue,(64,), None, 384, 13, d_result_fire6_expand, d_fire7_squeeze_weight, d_fire7_squeeze_bias, d_result_fire7_squeeze)\n",
    "# conv1x1(queue,(256,), None, 64, 13, d_result_fire7_squeeze, d_fire7_expand1x1_weight, d_fire7_expand1x1_bias, d_result_fire7_expand)\n",
    "# conv3x3(queue,(256,), None, 64, 13, 1, 1, 256, 13, d_result_fire7_squeeze, d_fire7_expand3x3_weight, d_fire7_expand3x3_bias, d_result_fire7_expand)\n",
    "\n",
    "# conv1x1(queue,(64,), None, 512, 13, d_result_fire7_expand, d_fire8_squeeze_weight, d_fire8_squeeze_bias, d_result_fire8_squeeze)\n",
    "# conv1x1(queue,(256,), None, 64, 13, d_result_fire8_squeeze, d_fire8_expand1x1_weight, d_fire8_expand1x1_bias, d_result_fire8_expand)\n",
    "# conv3x3(queue,(256,), None, 64, 13, 1, 1, 256, 13, d_result_fire8_squeeze, d_fire8_expand3x3_weight, d_fire8_expand3x3_bias, d_result_fire8_expand)\n",
    "\n",
    "# # classifier\n",
    "# conv1x1(queue,(1000,), None, 512, 13, d_result_fire8_expand, d_classifier_conv_weight, d_classifier_conv_bias, d_result_classifier_conv)\n",
    "# avgpool(queue,(1000,), None, d_result_classifier_conv, d_result_classifier)\n",
    "# # Wait for the commands to finish before reading back\n",
    "# event3.wait()\n",
    "queue.finish()\n",
    "#cl.enqueue_copy(queue, h_result_fire1_squeeze,  d_result_fire1_squeeze)\n",
    "cl.enqueue_copy(queue, h_result_fire1_expand, d_result_fire1_expand)\n",
    "queue.finish()\n",
    "veamos=h_result_fire1_expand.reshape(-1,tamanyo,tamanyo)\n",
    "#veamos2=h_result_fire1_squeeze.reshape(-1,tamanyo,tamanyo)\n",
    "rtime = pc() - tic3\n",
    "print (\"tiempo en segundos con pytorch= \", toc-tic)\n",
    "print (\"tiempo en segundos con numpy= \", toc2-tic2)\n",
    "print (\"tiempo en segundos con opencl=\",rtime)\n",
    "\n",
    "comparativa1=np.allclose(salida2_total_a_numpy, imagen_total_obtenida,rtol=1e-01, atol=1e-01)\n",
    "comparativa2=np.allclose(veamos, imagen_total_obtenida,rtol=1e-01, atol=1e-01)\n",
    "print(\"comparativa (pytorch==numpy):\",comparativa1)\n",
    "print(\"comparativa (pytorch==opencl):\",comparativa2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 55, 55)\n",
      "(128, 55, 55)\n"
     ]
    }
   ],
   "source": [
    "print(imagen_total_obtenida.shape)\n",
    "print(veamos.shape)\n",
    "# print(imagen)\n",
    "# print(weights1)\n",
    "# print(fire1_squeeze_weight)\n",
    "# print(bias1)\n",
    "# print(imagen1_obtenida)\n",
    "# print(veamos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
